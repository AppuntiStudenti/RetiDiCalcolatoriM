
\section{Qualità di servizio e nuovi protocolli per Internet}
Esistono diversi indicatori con cui poter valutare la QoS:
26
$\bullet$ Prontezza di risposta: viene indicata dal tempo di risposta, il jitter, o il
ritardo. Nel caso vi siano più servizi correlati fra di loro, la qualità viene
u
a
associata a più operazioni.
u
$\bullet$ La banda, cioè quanti bit/byte al secondo si riescono a trasmettere (dati
e
trasmessi con successo)
$\bullet$ L'adabilit` del sistema
a
$\bullet$ Lo throughput, ovvero il numero di servizi che si riescono ad erogare
nell'unit` di tempo.
a
Tuttavia, questi non sono gli unici indicatori, e probabilmente non sono neanche
quelli più interessanti per un utente che volesse pagare per un servizio. Vi sono
u
infatti degli altri parametri più qualitativi da considerare, perché requisiti dalu
e
l'utente (come la qualità dell'immagine, sincronizzazione audio/video,. . . ): sono
a
requisiti non funzionali, legati alla tipologia di servizio! Per poter quindi servire
un cliente, si deve anche poter interagire con lui, per avere un'idea di quale
qualità gli possa interessare: ciò però è contro la trasparenza! La negoziazione
a
o
oe
e l'accordo controllato con il cliente fanno in modo che i servizi moderni non
risultino trasparenti, proprio perché l'utente può (e spesso deve) specicare delle
e
o
preferenze! Il sistema deve essere dinamico, in grado di reagire all'evoluzione
delle richieste, in maniera da mantenere la QoS concordata: deve apportare
delle azioni correttive durante l'esecuzione! In generale, i parametri che un
utente ritiene fondamentali sono:
$\bullet$ Importanza
$\bullet$ La QoS percepita, che dipende dalla tipologia del servizio
$\bullet$ Il costo da dover sopportare
$\bullet$ La garanzia di avere degli adeguati supporti per la sicurezza (non ripudio
del servizio, autenticazione, . . . )
\subsection{Calcolare la QoS}
Oltre alla quantit` di dati trasmessi con successo (la banda), un altro parametro
a
fondamentale da tener da conto è il tempo di latenza: questo consiste nella
e
quantit` di tempo necessaria per trasmettere un'unit` di informazione. Questo
a
a
dipende da tre contributi:
TL = Tpropagazione segnale + Ttrasmissione + Tritardo
(14)
Il tempo di trasmissione dipende dalla dimensione del messaggio e dalla banda
disponibile, mentre il tempo di ritardo dipende dai tempi di accodamento che
si vengono a vericare. In particolare, è quest'ultimo a tener da conto gli overe
head presenti nel sistema (spesso è alto, e lo si può ridurre realizzando un buon
e
o
27
protocollo).
La qualità di servizio dipende da come si riescono a risolvere i colli di bottiglia
a
dell'applicazione, cioè su cosa è orientata (trasmettere tanti dati di dimensioni
e
e
molto limitate? Prevale il tempo di latenza. trasmettere diversi dati di di`
mensioni elevate? E necessaria una banda suciente). Spesso, si utilizza come
ulteriore indicatore il prodotto fra la latenza e la banda: riesce infatti a dare
un'idea del ritardo fra mittente e ricevente, e di quante informazioni sono state
inviate nel frattempo. Si rappresenta così il numero eettivo di bit trasmessi,
\i{}
perché non sarà mai uguale alla banda essendo presente proprio il tempo di
e
a
latenza! Su questi indicatori, una prima possibile strategia molto semplice `
e
quella di occupare sempre al massimo le pipe (e quindi la banda), per poter
garantire i tempi di risposta concordati: tuttavia, si deve tener conto anche
del tempo di latenza nel far ciò. . . Spesso quindi si incorpora un tempo per il
o
buering delle applicazioni.
Un altro parametro è il jitter, ovvero la variazione della latenza che si presene
ta in un usso: infatti, non è in realtà costante (sarebbe la situazione ideale. . . ).
e
a
Basti pensare per esempio che nella maggior parte delle comunicazioni vi sono
degli intermediari a supporto: a seconda del carico di lavoro presente su di loro,
`
il tempo di latenza può variare notevolmente! E quindi necessario pensare anche
o
a una QoS distribuita fra i vari nodi !
Lo skew rappresentalo sfasamento fra due ussi, che dovrebbero essere invece
percepiti come una singola entità dall'utente nale (per esempio, discrepanze
a
nella velocit` fra audio e video).
a
Spesso, in realtà, la QoS è un parametro che è trascurato in fase progeta
e
e
tuale, nonostante sia un obiettivo. Questo perché durante lo sviluppo si hanno
e
situazioni con traco molto limitato. Ciò però non è vero per tutti i servizi
o
o
e
(ad esempio, video streaming o qualunque altro usso di informazioni continuative): la QoS è fondamentale proprio per
poter erogare il servizio, per cui i
e
problemi della banda e della latenza son fondamentali. Per garantire la QoS, le
entità devono eettuare una negoziazione per decidere certi parametri (il ritara
do inziale per assorbire il jitter medio, il massimo ritardo accettabile per non
dover scartare un pacchetto. . . ). Per esempio, una prima idea per ottimizzare
la trasmissione è quella di introdurre delle risorse sul client, e di buerizzarla:
e
si trasmette quindi soltanto avendo un certo numero di frame a disposizione.
\subsection{QoS in Internet}
Il mondo di Internet si basa sul protocollo TCP/IP, che lavora best effort: ciò
o
signica che non può garantire QoS 6 . OSI è da sempre stato progettato con
o
e
6 Perch` ciò? Internet non prenota o mantiene le risorse, ma cerca di determinare un
e o
cammino fra C/S che quindi può variare. Non abbiamo garanzia del servizio. OSI invece
o
denisce la possibilità di definire gli intermediati e riservarli, in maniera da distribuire la
a
latenza totale del servizio su di loro, e in maniera da progettare i nodi intermedi con le risorse
28
l'idea di supportare QoS, ma risulta essere ancora lontana da essere realmente
implementata. Si tratta quindi di individuare tecniche per garantire QoS in Internet. Le idee principali riguardano
l'introduzione di nuovi protocolli e nuove
applicazioni
Le applicazioni classiche di Internet (tipo mail) sono elastiche, ovvero sono
in grado di adattarsi alla congurazione della rete, e non richiedono QoS al
supporto (possono tuttavia specicare un tempo di latenza per poter eseguire).
In queste applicazioni quindi l'utente non specica dei tempi rigidi per poter
eseguire.
Le applicazioni moderne invece sono non elastiche: questo perché presentano
e
dei vincoli temporali precisi, e quindi richiedono QoS. Di queste, quelle real-time
moderne sono tolleranti rispetto a problemi che si possono vericare, ovvero
possiamo avere che sono:
$\bullet$ Adattative in banda: il servizio è erogabile ma con una banda minore, e
e
quindi qualità diminuita: si parla per esempio di un video peggiore.
a
$\bullet$ Adattative per la latenza: il servizio è erogabile, ma con un ritardo mage
giore, riducendo la QoS: uno streaming audio che perde pacchetti, un video
che perde dei frame.7
Bisogna ricordare che in generale la latenza non è costante: potrebbe essere
e
conveniente quindi specicare la latenza su ogni frame.
Un servizio per Internet potrebbe quindi richiedere garanzie diverse:
$\bullet$ Il classico best-eort
$\bullet$ Un controlled load, ovvero la gestione di una latenza limitata. Spesso
questa è la scelta per i servizi elastici, trattandosi di una via di mezzo fra
e
il best-eort e la garanzia di determinati valori.
$\bullet$ Il guaranteed load, per cui si ha un limite temporale stretto al ritardo, ma
non limitato al jitter.
Per poter fornire servizi che si basino sulle ultime due opzioni, è necessario
e
far evolvere Internet da un sistema best-eort (dovuto all'uso di IP) elastico
(grazie a TCP) ad un sistema con QoS. Si parla quindi di una transizione da
una struttura a basso costo e senza garanzie ad una con costi dierenziati a
seconda delle prestazioni da erogare. Vi sono due proposte, incompatibili fra di
loro:
$\bullet$ Servizi integrati, RFC 2210: si ragiona per singolo servizio, e quindi si
cerca di definire per ogni singolo usso la QoS
necessarie per soddisfare la banda
7 Questo non si può fare con TCP,perché garantisce che si ricevano sempre i frame in ordine:
o
e
trasparente, ma non va bene se abbiamo un alto jitter!
29
$\bullet$ Servizi dierenziati, RFC 2475: si propone di introdurre QoS a livello di
rete, quindi la proposta è quella di lavorare contemporaneamente su più
e
u
ussi per migliorare in maniera globale il routing.
\subsection{Gestire la QoS}
Come gestire quindi la QoS? Il controllo della qualità dovrebbe essere fatto dua
rante l'esecuzione, e in generale abbiamo una fase iniziale (prima dell'erogazione,
azioni preventive o statiche), una fase durante il deployment (azioni reattive o
dinamiche). Tuttavia, in Internet non vi è n` la fase iniziale (detta anche proe e
visioning), e non vi è soprattutto il controllo della qualità durante l'esecuzione
e
a
(come controllare i diversi intermediari??), e soprattutto non esistono protocolli
standard! Va valutato caso per caso come strutturare la gestione della QoS.
Nella parte statica quindi client e server si devono mettere d'accordo prima
di erogare il servizio: è la fase di negoziazione della QoS. Questa fase cone
siste nel definire un Service Level Agreement fra le varie parti, che dovrà essere
a
descritto in una maniera opportuna, e quindi nel definire/riservare le risorse necessarie. La fase che precede
l'erogazione è senza costo, perché non vi è ancora
e
e
e
il monitoring ma solo la predisposizione del servizio.
La fase dinamica invece è caratterizzata dal monitoring dell'erogazione del
e
servizio, che è strettamente necessario per poter magari fare una rinegoziazione
e
nel caso sia necessaria (introduzione di nuovi intermediari, presenza di nodi
guasti, . . . ) per poter mantenere la QoS stabilitae garantire che ciò avvenga:
o
questa è la condizione necessaria perché un servizio venga retribuito. Questa `
e
e
e
la fase più costosa, perché i vari nodi si devono adattare alle situazioni che si
u
e
vengono a vericare, oppure devono essere estromessi se non adatti. L'idea `
e
quella di basarsi il più possibile sulla località : più le azioni sono locali, senza
u
a
u
dover far intervenire un agente esterno, un fruitore, minore è il costo; anche per
e
questa fase si deve cercare di progettare dei protocolli ottimizzati che costino
poco, sfruttando il principio della minima intrusione quindi ! Politiche poco
costose quindi, e limitare l'uso delle risorse necessarie al monitoring! In un
ipotetico sistema quindi il piano utente (quello della gestione del servizio) e
quello del management sono accoppiati, ma dovrebbero essere strutturati in
maniera tale da condividere il minor numero di risorse. Il problema di Internet
` che siamo sempre in piano utente, e quindi è dicile capire se ci sono problemi.
e
e
Il piano del management in realtà può essere scomposto in diverse sottoparti,
a o
a seconda di cosa si vuole gestire: vi è una parte per l'identicazione di fault
e
e recovery delle risorse, una parte per il controllo della performance (quindi
eventuali aggiustamenti del servizio per poter garantire la QoS). Altri settori
fondamentali riguardano l'accounting e la sicurezza dei servizi.
30
\subsection{Gestione dei sistemi: OSI e SNMP}
OSI ha denito un sistema per poter monitorare/gestire un insieme di risorse
mediante l'uso di risorse astratte 8 : l'idea è quella di utilizzare delle descrizioni
e
standard per poter definire risorse e azioni, necessarie per la gestione. Le informazioni che descrivono quindi il mondo
sono codicare utilizzando il CMIB,
Common Management Information Base. OSI quindi sarebbe in grado, mediante queste informazioni, di poter gestire i
singoli nodi di una rete (tipo, poter
specicare la banda erogabile presente su un nodo9 , . . . ). OSI struttura il management con l'idea che vi siano manager
in grado di comunicare con gli agenti,i
responsabili delle singole risorse: non vi è una specica precisa, permettendo
e
quindi di poter realizzare architetture più o meno complesse.
u
In realtà, il protocollo più diuso per la gestione di una rete è anche uno
a
u
e
dei più semplici, detto Simple Network Management Protocol, sviluppato dall'Iu
ETF, e per questo incompatibile con OSI : inizialmente non teneva conto della
sicurezza, e si trattava di pura e semplice comunicazione.
SNMP denisce (nella sua prima realizzazione) un unico manager centralizzato e diversi agenti non locali, quindi studiati
per un sistema distribuito. Il
manager si preoccupa quindi di fare delle richieste sugli agenti, i quali devono
rispondere, e possono anche avvisare di eventuali problemi/eventi mediante delle
trap. Il protocollo è molto sincrono, ovvero si attende sempre una risposta!
e
Un agente in realtà gestisce delle variabili standard (non se ne possono
a
introdurre di nuove), che sono descritte nel MIB: le operazioni sono quindi
semplicemente delle GET e SET su queste variabili.
Una prima reingegnerizzazione di SNMP ha portato alla possibilità di poter
a
definire il manager come una struttura gerarchica (sfruttando l'idea di realizzare
degli agenti proxy, una via di mezzo fra un agent e un master), in maniera da
ridurre i rischi di una congestione, suddividendo la responsabilità. Il costo `
a
e
quindi limitato dal numero di agenti presenti. Solo però con la terza versione si
o
` introdotto in SNMP anche il concetto di sicurezza.
e
SNMP presenta alcuni problemi: prima di tutto, la perdita/sostituzione di
un agente provoca la ricongurazione di tutto il sistema. Inoltre, si tratta sempre di variabili, che sono solo
rappresentazioni della risorsa: per esempio, con
SNMP non si può specicare la banda di un router, non la può controllare! Il
o
o
manager poi comunica con gli agent, ma sempre esternamente deve essere specicata come avviene la comunicazione (ogni
quanto interroga gli agent?). Inne,
gli agent forniscono informazioni strettamente locali alla risorsa che gestiscono:
per poter fornire delle informazioni più generali sullo stato della rete è necessario
u
e
aancare a SNMP un sistema di Remote MONitoring, per poter fornire all'utente maggiori possibilità. Si introducono quindi
dei monitor (probe), in grado
a
di lavorare in autonomia e comunicare con il manager, riportando informazioni
8 Non esistono speciche su come implementarle, quindi le varie realizzazioni sono standard
de facto
9 Attenzione, OSI è solo comunicazione!! La banda dovrà poi essere stabilita dal singolo
e
a
router, la tecnologia utilizzata deve essere indipendente da questa comunicazione!
31
ltrate. Anche RMON rappresenta una derivazione semplicata da OSI, quindi
incompatibile.
OSI permette di definire sistemi molto più complessi, grazie all'uso di un MIB
u
più organizzato. Si possono infatti realizzare gerarchie dinamiche fra manger e
u
agent, questi si possono quindi creare e distruggere a piacimento (senza dover
ricongurare l'intero sistema)! Il MIB è totalmente cancellabile, come anche le
e
singole operazioni come la GET: si ragiona quindi anche sulla durata dell'operazione, per cui se è oltre il limite
impostato, è annullata. Gli oggetti gestiti
e
e
possono essere anche molto complessi (non una singola risorsa come con SNMP).
\subsection{Evoluzione dei router}
L'idea alla base dell'introduzione di QoS in Internet è che sui nodi intermedi si
e
hanno delle informazioni sullo stato del servizio. Un router semplice prende e
rispedisce i pacchetti, in generale sfruttando la politica FIFO, senza sfruttare
tutte le possibilità per l'instradamento: garantisce best-eort, ma non QoS,
a
poich` i ussi sono limitati da altri ussi!
e
Lo sviluppo sarebbe quindi quello di realizzare un router che ragiona in termini dierenziati : deve essere in grado
quindi di marcare i ussi, e deve riuscire
a trattare la gestione dei ussi in maniera da favorire i ussi più prioritari (magu
ari scartando/ritardando i pacchetti dei ussi meno prioritari). Si ha che quindi
lo stato del router dipende dal singolo pacchetto, che a sua volta dipende dal
traco. In particolare, è da notare che il costo di una determinata politica
e
viene riesso su ogni usso/messaggio: per questo vuole l'intrusione minima,
per minimizzare il costo.
I router per la QoS si possono modellare mediante due modelli non reali, a
bucket:
$\bullet$ Leaky bucket: corrisponde a un secchio con perdita. L'idea è quella che
e
un router si comporti come un regolatore del usso in uscita. Si stabilisce
quindi una banda massima, corrispondente alla capacità del bucket: tutto
a
ciò che è oltre viene scartato dal router, i pacchetti troppo veloci vengono
o
e
rallentati. Ogni router di questo tipo è quindi pensato per favorire un
e
usso alla volta.
$\bullet$ Token bucket: si prevede la presenza di un token, che garantisce ai pacchetti del usso che lo possiede di
poter essere smistati dal router. Si associa
quindi uno stato al usso, e questo stato dipende proprio dal numero di
token presenti. In questo modello i pacchetti vengono solo ritardati, non
possono essere persi. A seconda della capacità del bucket, si possono avere
a
trasmissioni o rallentamenti. In particolare, un usso potrebbe non aver
sfruttato i token, e trovandosi quindi ad essere l'unico usso con tutti i
token può presentare dei burst. Spesso si attende infatti che un determio
nato usso abbia un numero congruo di token per poter trasmettere tutti
32
assieme un insieme di bit; si tratta quindi di un sistema di buerizzazione,
per cui son necessarie delle apposite risorse. I token vengono generati
mediante un'apposita legge lineare.
Spesso si utilizzano i due bucket in serie, per evitare proprio i burst del token
bucket (quindi prima il token, seguito a cascata dal leaky!).
Le politiche che un router per la QoS può presentare son diverse, tuttavia
o
l'idea è quella di realizzare delle politiche conservative del lavoro: se arriva un
e
datagramma e non vi sono condizioni per cui il usso è rallentato e le code son
e
libere, il router lavora alla Internet, reinstradando subito il pacchetto. Infatti,
per la legge di Kleinrock, il router non può essere in una condizione di idle se
o
vi sono dei pacchetti da portare in uscita. La legge di kleinrock stabilisce che,
dati n ussi, con traco $\lambda$n e tempo medio di servizio $\mu$n :
$\bullet$ Il prodotto $\rho$n = $\lambda$n · $\mu$n rappresenta l'utilizzo medio del router
$\bullet$ Denito qn il tempo medio di attesa si ha che
$\rho$n · qn = K
(15)
dove K è una costante
e
Questo signica che per favorire un usso (aumento della banda, riduzione del
ritardo) in realtà se ne deve per forza sfavorire un altro (diminuzione della bana
da, aumento del ritardo).
Si è sempre detto che le politiche vengono giudicate dal loro costo, e che
e
politiche più semplici sono meno costose. Tuttavia, nel caso di router, si deve
u
anche tener conto se la politica è fair o meno (vi sono ussi in condizione di
e
starving?10 ).
Un primo esempio, spesso implementato mediante politiche più semplici
u
perché non è realmente implementabile ma solo un modello a tendere, è la
e
e
e
min-max fairness. Si immagini di avere un numero di richieste superiore alle
risorse disponibili, e si devono quindi dividere le risorse in maniera fair. L'idea
` quella di classicare i ussi in base alle loro esigenze, privilegiando i ussi che
e
richiedono meno risorse, per poter così lasciare più risorse a chi ne ha maggior\i{}
u
mente bisogno; x1 $<$ x2 $<$ . . . $<$ xn indica quindi la priorit` con cui servire,
a
mentre C indica la capacità massima a disposizione del router. Si possono quina
di definire mn le risorse eettivamente allocate per il usso n-simo, e Mn le
risorse attualmente libere. Si ha quindi che:
mn = min(xn , Mn )
Mn =
n
i=1
C$-$
mi
N $-$n+1
(16)
(17)
10 Osservazione: le politiche dicono come i router possono trattare i ussi, ma tocca poi
all'utente specicare quali ussi debbano essere trattati in quale modo!
33
Un altro modello di scheduling, derivato proprio da come funziona quello del
singolo processore, è il general scheduling processor : l'idea è che mediante un
e
e
algoritmo di tipo round-robin si faccia passare un bit per ogni usso alla volta:
tale politica è sicuramente molto fair, ma non applicabile realmente visto che
e
si lavora a pacchetti e non a bit. Anche questo modello in realtà serve solo per
a
studiare le politiche pensate e confrontarle, per determinarne la fairness.
In realtà, fra le politiche realmente diuse ed implementate in router con
a
QoS vi sono:
1. Priorit` ai ussi : vi sono diversi livelli di priorit` con cui poter etichettare
a
a
un usso. Il router quindi si preoccupa di favorire prima i ussi a massima
priorit`. Questo però non è una politica fair ! Se continuano ad arrivare
a
o
e
pacchetti di questi ussi, quelli meno prioritari non verranno mai serviti
(non avranno mai banda a sucienza)!
2. Round robin: è una politica più fair, che garantisce comunque ad ogni
e
u
usso una propria share della banda, ed è una politica molto buona se i
e
datagrammi dei vari ussi sono circa delle stesse dimensioni (altrimenti,
si potrebbe usare un weighted round robin, per poter pesare diversamente
i datagrammi. Pi` un datagramma è pesato, maggiori risorse vi sono
u
e
associate. La normalizzazione è dicile da realizzare per ussi troppo
e
corti) Il round robin viene spesso implementata in quei router in cui non
si possono specicare delle priorit` speciche, ma in cui comunque i ussi
a
devono competere per delle risorse.
3. Decit round robin: si associa una storia ad ogni usso, perché si impone
e
un limite per ciascuno. Se un usso supera la soglia consentita, non viene
erogato dal router ma si memorizza tale decit. L'erogazione riprender`
a
solo quando gli altri ussi avranno superato tale limite.
4. Fair queueing: si tratta di round-robin fatto bit a bit. Si fa avanzare
sempre il usso con il pacchetto più indietro, ovvero quello che se si fosse
u
realmente fatta una comunicazione bit a bit, avrebbe terminato la comunicazione per primo! Questa è una delle politiche
maggiormente usate,
e
anche in ambienti Internet, perché si hanno dei calcoli in tempi accettabili.
e
Un problema di tutte le politiche è in realtà il fatto di non sapere cosa aspettarsi
e
a
all'arrivo, cioè cosa aspettarsi dai ussi che entrano nel router e che devono come
petere per le risorse. Una soluzione possibile è quindi quella di inviare insieme
e
al usso un'idea dello stato del usso, per vagliare quanto sia pesante o meno!
Perch` un router possa fornire QoS, deve essere dinamicamente ricongurae
bile (cioè deve poter ammettere/spegnere ussi in maniera dinamica). Questo
e
per esempio è un requisito fondamentale per risolvere il problema della cone
gestione, addirittura in certi casi prevenendolo. Invece che scartare i pacchetti
34
ricevuti in maniera silenziosa (alla Internet)11 , si scartano i pacchetti in maniera
visibile. Questo sistema è contro la trasparenza, ma è un'indicazione chiara per
e
e
le applicazioni e gli utenti che vi sono dei problemi. Si possono quindi mettere
in piedi delle politiche preventive, tipo la realizzazione di un'apposita nestra di
trasmissione sul canale.
Una politica sempre implementata, anche nei router a basso costo, è la Rane
dom Early Detection. Si tabilisce una coda per ciascuno usso, insieme a due
soglie:
$\bullet$ Se il usso fa in modo che la coda sia sempre al di sotto della soglia
minima, non si scarta nessun pacchetto
$\bullet$ Se il usso è oltre la soglia massima, tutti i nuovi pacchetti vengono
e
scartati.
$\bullet$ Altrimenti, si decide in maniera random su quale usso scartare i pacchetti, basandosi con una probabilità
crescente con la lunghezza della
a
coda!
Questa politica preventiva evita la congestione.
\subsection{Servizi integrati, RFC 2210}
L'idea alla base dei servizi integrati è quella di essere in grado di riconoscere i
e
singoli ussi, grazie al router, in modo da poter dierenziare l'uso delle risorse
a seconda del usso che si viene a presentare. Il Service Level Agreement `
e
quindi fatto a livello di singolo usso, e quindi si può decidere la QoS per ogni
o
usso. Si deve quindi stabilire la QoS fra mittente, ricevente e necessaria per
ogni nodo intermedio. Questi protocolli descrivono solo la comunicazione che
le varie parti devono sostenere: la politica locale sarà implementata a livelli
a
inferiori localmente dalle singole entità.
a
Nonostante il costo, i servizi integrati lavorano proprio al livello applicativo
(OSI), proprio perché a questo livello le risorse sono note e si possono valutare:
e
questo signica che su ogni nodo si lavorer` a livello applicativo, in maniera tale
a
da poter individuare fra i possibili cammini il cammino migliore, che divverr` ata
tivo. Per far ciò si utilizza un protocollo detto Reservation Protocol ; questo proo
tocollo infatti permette di specicare un cammino attivo in grado di rispettare
una determinata SLA, senza considerare il traco corrente, ovvero permette di
riservare delle risorse in maniera attiva per il servizio. L'idea è che si inviino
e
delle informazione dal ricevente al mittente (e viceversa) per poter valutare le
risorse (ovvero ogni risorsa dovrà provvedere con un opportuno messaggio da
a
inoltrare, per indicare la qualità di servizio che può orire). Si ha quindi una
a
o
propagazione della gestione, per indicare la disponibilità!
a
Si tratta di un protocollo con soft state, ovvero il ricevente, una volta accordato il servizio e le modalità, dovrà
preoccuparsi di rinnovare periodicamente
a
a
11 Vi è ICMP che prova ad avvertire l'utente che i pacchetti non son stati ricevuti, ma lavora
e
sempre a livello di IP, quindi rischia di essere coinvolto nella congestione!
35
la richiesta del servizio concordato. Si ha che quindi il protocollo è denito in
e
due passi:
1. Il cliente invia un messaggio di Resv per valutare la disponibilità
a
2. Un servitore che è disponibile risponde con un messaggio di tipo Path
e
3. Il cliente conferma il cammino scelto12 rinoltrando con un messaggio di
tipo Resv (solo con questo messaggio riserva le risorse).
Un cliente quindi dovrà rinnovare mediante gli stessi messaggi la richiesta di
a
servizio, tuttavia sono previsiti anche degli appositi messaggi (tear ) sia da parte
del cliente che del servitore, per poter interrompere l'erogazione del servizio,
e permettere una ricongurazione del servizio. Il protocollo stabilisce che si
possono richiedere risorse in esclusiva o in condivisione con altri ussi (particolarmente utile per ottimizzare la
comunicazione). Gli scambi di messaggi
ovviamente avvengono fra nodi vicini, cercando quindi di limitare il costo senza
eseguire un broadcast.
Questo è un sistema conveniente per reti locali e non globali (si ha un alto nue
mero di messaggi in circolazione): troppi clienti e si avrebbero errori nel riservare
le risorse perché prenotate prima da altri, e deve essere noto alle applicazioni
e
che lavorano che lo scambio di informazioni si basa su tale protocollo. Infatti,
al degradare delle prestazioni si può giungere ad una condizione di best-eort,
o
per cui è necessaria la rinegoziazione. Ogni ricevente deve quindi mantenere
e
uno stato per avere idea in che situazione si trova. Sicuramente conviene condividere ove possibile. Si possono anche
fare spesso delle supposizioni per limitare
l'overhead (il ricevitore sa a chi mandare per primo le richieste, il servitore sa
chi potrebbe essere interessato al servizio, . . . ).
Il problema di RSVP è che è un protocollo con una forte intrusione, perché si
e
e
e
ha una parte statica molto ben denita, ma che potrebbe essere solo ideale (non
funzionerebbe bene in presenza di nodi congestionati). Per questo, a supporto
di questo protocollo per la parte statica, sono stati sviluppati altri protocolli
per il supporto alla QoS a livello applicativo per la parte dinamica. Sono il Real
Time Protocol e il Real Time Control Protocol. Sono entrambi protocolli basati
su UDP, per il singolo usso, che si preoccupano di portare materialmente i
frame, incapsulandoli in maniera opportuna. Proprio per questo motivo non
la garantiscono ma sono solo di supporto! RTP per esempio si preoccupa di
marcare ed ordinare i singoli frame, in maniera di mandarli in ordine13 , mentre
RTCP gestisce la connessione astratta.
RTP non denisce una sincronizzazione verso un tempo assoluto (nel distribuito questo ha dei costi improponibili), ma ha
l'obiettivo di minimizzare il
jitter. Questi primi protocolli ragionano sul cammino attivo, per poter definire
correttamente i nodi intermedi. Sono protocolli IETF, con sempre l'obiettivo di
giungere ad una facile e veloce implementazione.
12 Il protocollo non spiega come scegliere il cammino (problema implementativo), ma solo
quali sono i messaggi di comunicazione che i diversi partecipanti devono scambiare
13 Attenzione: la decisione di come mandare però non è a carico del protocollo, che mette a
o
e
disposizione solo meccanismi ma non politiche
36
RTP è sempre accompagnato da RTCP. Il primo è un servizio fortemente
e
e
erogato dal servitore verso il ricevente (da chi sa poco a chi sa molto), mentre
il secondo serve per fornire al gestore informazioni di gestione, e quindi naviga
in entrambe le direzioni. Tuttavia, si devono specicare in maniera precisa entrambi perché utilizzano le stesse risorse,
e potrebbero aumentare l'intrusione;
e
si stabilisce per esempio quale è la banda che RTCP può sfruttare. RTP in
e
o
particolare consente ai singoli intermediari di intervenire sui singoli messaggi,
per poter comunque garantire il raggiungimento della QoS stabilita. RTCP permette, in particolare con il receiver e il
sender report, di poter stabilire lo stato
del cammino, per poter quindi far eseguire eventuali operazioni (tipo recovery
di un nodo); tuttavia, si deve sempre considerare che tutto ciò è particolarmente
oe
costoso.
Questi protocolli sono anche veicoli di informazioni applicative, cioè si pose
sono specicare nei datagrammi informazioni per le singole applicazioni: sono
protocolli hop-to-hop, che lavorano su tutti i nodi, per cui bisogna garantire che
i nodi intemedi non modichino le informazioni a livello applicativo. Le possono
vedere, ma non modicare.
Questi protocolli purtroppo non sono molto scalabili, e possono essere usati
solo in reti molto limitate. Il lettore RealPlayer per esempio sfrutta un altro
protocollo detto Real Time Streaming Protocol, in cui non si denisce un cammino attivo, ma una volta ottenute le
speciche dello stream, si utilizza UDP
o TCP e un sistema di buering per poter trasferire il usso dalla sorgente al
player. Infatti, inizialmente si parte mediante TCP che riempe il buer, ma se
un frame non arriva si sfrutta UDP proprio perché non garantisce che i messaggi
e
`
arrivino in ordine! E un modello push, in cui le informazioni arrivano dal server. Questo è un protocollo dal costo
minimo, proprio perché non riserva nulla:
e
e
`
lavora solo sugli end-point. E sempre possibile comunque tornare a RSVP nel
caso non fosse suciente.
\subsection{Servizi differenziati, RFC 2474}
L'approccio a servizi differenziati consiste nel cercare di fornire QoS non a livello
applicativo, ma a livello di rete. Facendo ciò, in realtà, si ha che si sono deniti
o
a
molti meno protocolli rispetto ai servizi integrati (risultando essere inoltre molto
più scalabili). I servizi dierenziati sono studiati per supportare le applicazioni
u
legacy e per domini specici (comunità di utenti). L'idea è quella che si devono
a
e
aggreggare i ussi in diverse categorie, e a seconda delle categorie si denisce la
QoS. Un pacchetto viene quindi classicato dal router in base al suo contenuto,
e viene associato ad una possibile classe, e quindi ad un possibile trattamento.
Si ha che quindi l'SLA è stipulato sulla classicazione dei ussi, e le garanzie
e
vengono fornite dalle politiche implementate dai router (la politica è concordata
e
solo fra l'utente e il server).
Possibili esempi di servizio sono:
$\bullet$ l'expedited forwarding, per cui ogni router dispone di due diverse code, per
37
cui si garantisce che almeno i pacchetti classicati come expedited saranno
consegnati con la qualità calcolata. Si possono pesare utilizzando una fair
a
queuing pesata.
$\bullet$ l'assured forwarding, in cui i pacchetti sono marcati a seconda della possibile congestione.
Vi è però un problema: come si possono definire queste classi, nel protocollo
e
o
IPv4 non vi è possibilità. L'idea migliore sarebbe quella di passare ad IPv6, che
e
a
grazie a 128 bit contro 32, garantisce la presenza di ancora molti nomi, ove `
e
presente un apposito campo dove si può classicare il singolo pacchetto!
o
IPv6 è stato pensato per essere compatibile con IPv4, ma gestisce gli ine
dirizzi in maniera diversa (il broadcast è stato eliminato, divenendo in realtà
e
a
e
multicast; sono stati aggiunti il P2P e l'anycast14 , ed è in grado di fornire un
suo supporto alla replicazione! IPv6 in particolare semplica l'header, facendo
in modo di puntare altri header per poterlo estendere! Un'altra caratteristica
` che IPv6 è stato progettato per essere mobile, ovvero: un indirizzo di questo
e
e
tipo si può spostare senza problema da una rete a quell'altra, grazie al fatto che
o
lo si memorizza in un'apposita struttura. IPv6 in realtà è stato studiato per
a e
essere di supporto anche ai servizi integrati, quindi potrebbe essere un'ottima
estensione per Internet.
Oltre a questi approcci, si sta cercando di sviluppare dei sistemi in grado
di far convivere (in maniera competitiva) servizi integrati e dierenziati, per
cercare di sfruttare i vantaggi di entrambi.
