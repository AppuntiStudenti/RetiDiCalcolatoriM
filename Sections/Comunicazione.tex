\section{Sistemi per la comunicazione e la sincronizzazione}
La maniera con cui due processi possono comunicare è molto variabile: si possono classificare le comunicazioni in
diversi modi (sincrone/asincrone, dirette/indirette, bloccanti/non bloccanti...). Di particolare interesse è
ovviamente la \textit{comunicazione a molti destinatari}: un tale sistema può essere alle volte molto costoso da
gestire, ma spesso è necessario (gestione a copie attive, sottoscrizione di consumer ad eventi, e così via...).
Nel modello di Internet erano stati studiati due sistemi: il broadcast (realmente inaffrontabile dal costo) e
il multicast (realizzabile su indirizzi di classe D). Tuttavia, questi sistemi risultano essere efficienti finché si
lavora comunque con una località. Se invece si dovesse lavorare su più gruppi, è necessario utilizzare come protocollo
IGMP (utilizzo quindi di un protocollo non locale), che permette a una o più reti di trasmettere in multicast,
realizzando una sorta di\footnote{Obiettivo: raggiungere un qualunque indirizzo della classe specificata, che sia il più
vicino o il più comodo} broadcast locale (comunque abbastanza costoso)\footnote{L'alternativa è peggiore: fare un
flooding globale! Ma per mandare un messaggio a tutti, i router dovrebbero avere uno stato, e vericare che il messaggio
non l'abbiano già ricevuto... quanto deve durare lo stato?}. Oltre al costo, queste comunicazioni mancano prima di 
tutto di QoS (IGMP non garantisce l'ordine dei messaggi!), ma hanno anche una debole capacità espressiva (non si riesce
per esempio a definire priorità nelle comunicazioni, oppure sincronismi...). Infatti, in Internet si ragiona utilizzando
il \textit{Time To Live} per poter dirigere e guidare una comunicazione multicast: se è progettato male, l'intero
sistema si ingolfa. 
IGMP è un protocollo che permette ai nodi di una rete di lavorare in gruppo (si registrano tutti a uno stesso indirizzo
multicast). Richiede quindi l'utilizzo di un router di supporto, in maniera tale da poter controllare sia il traffico in
entrata che in uscita; sfrutta infatti dei particolari messaggi IGMP, come le query, per vericare chi si sia registrato
a quell'indirizzo multicast mediante un messaggio di tipo report. Si cerca quindi di lavorare in un ambiente locale tale
da garantire che le azioni di multicast siano valide per quella rete.
Nella versione iniziale del protocollo, vi erano degli altri problemi di gestione, dovuti al fatto che vi fosse un
singolo router a dover gestire tutta l'infrastruttura IGMP. Con la versione 2, un router può in realtà controllare più
reti, perché diventa possibile utilizzare anche più router. La versione 2 inoltre introduce un messaggio di leave dal
gruppo che mancava: prima era comunque tutto a carico del router, che doveva inviare i messaggi query periodicamente
e attendere le risposte dai clienti.
\subsection{Realizzare il routing multicast}
Non esistono soluzioni standard per realizzare il routing multicast. Lo scenario studiato è quello di più utenti ma un
unico trasmettitore. Si realizza quindi una struttura ad albero dinamico (si possono inserire/togliere utenti/nodi):
\begin{itemize}
 \item La radice è il trasmettitore
 \item I clienti sono le foglie
 \item I nodi padre sono i router che rendono possibile il cammino.
\end{itemize}
La struttura ad albero è efficiente: evita infatti la presenza di cicli e maglie.
Tuttavia, la struttura dell'albero può influenzare notevolmente l'efficienza dell'architettura.
Il primo passo è quello di realizzare uno spanning tree per cui si manda in flooding un messaggio per ogni destinatario,
così che la radice riesca ad individuare i cammini possibili, sfruttando i messaggi del protocollo unicast. Il
problema è che questo protocollo ha un costo che cresce tantissimo all'aumentare del numero dei partecipanti.
Il secondo passo riguarda quello della ricerca dei \textit{cammini condivisi}, per cui dei router possono essere
sfruttati per realizzare un cammino più efficiente (spanning tree minimo). Si viene così a realizzare una bone o
backbone multicast.
Infine, la radice raccoglie le informazioni ricevute per determinare lo \textit{spanning tree minimo}.
Una soluzione alternativa è il \textit{Reverse Path Broadcast}, ovvero ora l'iniziativa è a carico dei clienti. Durante
il normale routing, i clienti provano a mandare un broadcast verso la radice, che può, in base a nuove informazioni,
cercare di ottimizzare/aggregare ulteriormente l'albero. Tale sistema presenta tuttavia dei costi ulteriori che devono
essere valutati; le tecnologie utilizzate sono infatti le stesse per determinare un cammino minimo di Dijkstra, cioè o
si sfrutta il Distance Vector (si deve lavorare sfruttando anche le informazioni del prossimo vicino per evitare cammini
troppo lunghi) oppure Link State (tanti alberi quanti i cammini minimi, poi si devono risolvere i tie break). Tuttavia,
questo sistema permette di ridurre il numero di messaggi scambiati e permette di poter definire la banda necessaria.
In realtà la maggior parte dei sistemi sfrutta come protocollo il Reverse Path Multicast per cercare di limitare
(anche se di poco) il costo: resta comunque tutto a carico della radice su come realizzare l'albero di routing.
Non esiste uno standard per queste tecnologie, ma diverse proposte: si hanno dei problemi simili a quelli dell'invio
della QoS con i servizi integrati di frame.
Infatti si lavora spesso con stati non permanenti (soft state dalla durata limitata: gli intervalli sono un parametro
critico della progettazione), alberi dinamici in grado di fare riorganizzazioni locali. Le operazioni di base riguardano
la potatura (eliminazione di un router superfluo) e il reinserimento o graft dinamico (reinserimento di router). Si deve
quindi spesso ricalcolare l'albero in caso di variazioni! Le varie proposte sono:
\begin{itemize}
 \item \textit{Distance Vector Multicast Routing Protocol}: è basato su una multicast bone, si attraversano le reti
 utilizzando un sistema di tunneling. Il risultato è che così si sfruttano solo alcuni nodi.
 \item \textit{Multicast Open Shortest Path First}: questo sistema invece si basa sull'altra tecnologia, e cerca di
 ottimizzare l'albero già ottenuto determinato i cammini minimi
 \item \textit{Core Based Trees}: si mantengono costanti dei nodi, venendo a definire quindi degli alberi sub-ottimi
 che non variano. In questo modo si limita il costo della variazione dell'albero.
\end{itemize}
Il problema però è tutti questi protocolli sono incompatibili fra di loro: non possono essere attivati
contemporaneamente, o se ne sceglie uno o l'altro!
\subsection{Semantica della comunicazione di gruppo}
Come realizzare la semantica della comunicazione di gruppo? Conviene fornire delle conferme positive (i riceventi
avvisano di aver ricevuto il messaggio) oppure quelle negative (chi non ha ricevuto avvisa)? Si ritrasmette a tutti o
solo a chi non ha ricevuto il messaggio?
In generale l'obiettivo che si prefissa è che una send multicast dovrebbe essere garantita come un'operazione atomica.
Per risolvere il problema, conviene suddividerlo in due sottoproblemi:
\begin{enumerate}
 \item Garantire la \textit{fault tolerance}: nessuno deve perdere dei messaggi! Le ritrasmissioni sono quindi un
 sistema da prevedere se si vuole affidabilità.
 Tuttavia, si potrebbe rimbalzare il problema a livello applicativo: per esempio Chorus effettua multicast mai 
 ripetuti, quindi unreliable, ma specifica agli sviluppatori di realizzare il sistema di ritrasmissione.
 \item Fornire l'\textit{atomicità della trasmissione}: per atomicità si intende l'ordine con cui i messaggi giungono
 al gruppo. Si dovrebbe fare in modo infatti che tutti i membri del gruppo li ricevano nello stesso ordine? Non è
 detto (solo letture si potrebbero fare in ordine diverso)! Può essere infatti che a seconda dell'ordine dei messaggi
 si debbano attuare politiche diverse. L'atomicità è lo studio di questo problema.
\end{enumerate}
Questi due aspetti \textit{devono essere tenuti separati}: in questo caso quindi si ha che l'atomicità fa l'ipotesi
che in ogni modo i messaggi giungano sempre a destinazione. Nel progetto di una comunicazione di gruppo non è quindi
solo importante la singola operazione, ma l'ordine con cui giungono al gruppo.
L'affidabilità viene a mancare se si perde un messaggio, oppure un crash delle due parti. In particolare, per poter
garantire l'affidabilità si deve fare in modo che i gruppi siano \textit{dinamici}: se una copia cade, in maniera
trasparente si deve proseguire. Per tutti i fault l'infrastruttura dovrebbe essere in grado di reagire: è ovvio quindi
che serve un sistema di monitoring dell'infrastruttura, per poter effettuare le possibili azioni correttive:
\begin{itemize}
 \item Ritrasmissione di eventuali messaggi persi
 \item Aggiustamento del gruppo dinamico.
\end{itemize}
Ovviamente, si deve cercare di minimizzare i costi che si vanno ad aggiungere, tenendo conto del principio di minima
intrusione.
L'idea è quindi quella di realizzare dei meccanismi molto semplici, in maniera da poter garantire un
controllo\footnote{Da non sottovalutare: e se fallisce il controllore? Chi controlla il controllore?} per
poter effettuare la ritrasmissione. Si deve quindi studiare come richiedere o meno la ritrasmissione: per esempio, se
avessimo una conferma positiva per ogni frame (si usa così un meccanismo di hold back, trattenendo i messaggi finché
non arriva la conferma che il precedente è stato ricevuto), il costo per il monitoring sarebbe elevato. Si riduce
utilizzando le conferme negative, dove si può indicare cosa si è perso (si hanno dei messaggi ordinati...). Un altro
problema riguarda l'intervallo di tempo per aspettare, che deve essere opportunatamente dimensionato.
\subsection{Ordinamenti}
L'atomicità è l'aspetto in cui l'utente dovrebbe essere maggiormente coinvolto.

Infatti, non lavorando nel concentrato, certe ipotesi d'ordine che si potevano fare non sono più valide in maniera
gratuita! Come devono lavorare le copie?
Se potessero lavorare in maniera indipendente, per cui ogni copia può processare i messaggi nell'ordine in cui le
arrivano, senza preoccuparsi dell'ordine delle altre, si avrebbe un'infrastruttura a costo minimo... tuttavia ciò non
è sempre possibile.
L'ordinamento classico è quello FIFO: l'ipotesi generale è che si abbia sempr eun emettitore (si estende anche a casi
con più emettitori, ma l'ordinamento FIFO riferisce sempre i messaggi provenienti dallo stesso emettitore). Questo
ordinamento stabilisce che se vengono inviati i messaggi in ordine m1, m2, tutte le copie devono ricevere i messaggi
nello stesso ordine! Nel caso di più emettitori, infatti, l'importante è che i messaggi provenienti dallo stesso
emettitore siano sempre nello stesso ordine, ma fra emettitori diversi no; se un emettitore emette m1, m2 e un altro 
m3, m4
\begin{itemize}
 \item m1, m2, m3, m4; m1, m3, m2, m4; m3, m1, m4, m2... \textbf{vanno bene}
 \item m2, m1, m3, m4 \textbf{no!}
\end{itemize}
Le copie devono quindi essere progettate in maniera tale da mantenere lo stato, ovvero da chi arriva la comunicazione?
Se vi sono omissioni, si può così attivare un procedimento di hold-back.
Tuttavia, l'ordinamento FIFO non è sempre quello desiderato, proprio perché non si possono imporre vincoli di 
precedenza fra messaggi provenienti da emettitori diversi. Basti pensare ai newsgroup: spesso succede che arrivi 
prima la risposta della domanda, perché non sono presenti degli orologi sincronizzati. Questo succede perché a livello
di supporto non si garantisce il rapporto di causa-effetto.
L'ordinamento causale tiene conto di questo problema, si basa proprio sulla presenza di emettitori diversi, che 
possono inviare messaggi in relazione di causa-effetto fra di loro. Questo vuol dire che se un messaggo m1 è causa di
un messaggio m3 da parte di un altro emettitore, la comunicazione sarà valida se e solo se m1 precederà m3 sempre (per
altri messaggi non è stabilito l'ordine).
Il problema del causale è che è di difficile realizzazione: non vi sono supporti che lo realizzano. Nel caso di un
singolo mittente, il causale è praticamente un FIFO, ed è di semplice realizzazione. Ma se si hanno gruppi dinamici, 
e quindi dipendenze dinamiche fra i messaggi, non è banale!
Inoltre, non tutto a questo mondo si può rappresentare con il rapporto di causa-effetto: per esempio, se si avessero
due multicast che sono rispettivamente un accredito e una valutazione degli interessi, l'ordine è fondamentale... ma
le due operazioni non dipendono l'una dall'altra! Resta che l'ordinamento su tutte le copie deve essere il medesimo,
altrimenti si avrebbero dei conti sballati!
Questo problema non si risolve neanche con il FIFO perché, come il causale, si tratta di un ordinamento parziale. Si
può pensare invece di risolverlo utilizzando un ordinamento atomico, che è globale. Questo perché è un ordinamento
deciso dal gruppo! Il gruppo può decidere una famiglia di ordinamenti che tutte le copie devono rispettare, fornendo
così anche implementazioni diverse. L'ordinamento atomico non è interessato infatti all'ordine specifico, ma al fatto
che tutti i componenti del gruppo ricevano i messaggi nello stesso ordine. L'ordinamento atomico può essere realizzato
in maniera da rispettare sia (o uno solo, o nessuno) l'ordinamento FIFO che quello causale.
Per poter realizzare l'ordinamento atomico, si deve pensare comunque alla presenza di un frontend, in grado di smistare
alle varie copie i messaggi che arrivano: ogni copia lavora in maniera indipendente, così che se manca un messaggio
ad una le altre non sono bloccate. Questo vuol dire che non sono sincrone fra di loro, ma l'obiettivo è solo il
raggiungimento di uno stato finale coeso. Il coordinamento quindi può non rispettare il FIFO, ed è tutto interno al
gruppo.
L'ordinamento è un costo aggiuntivo che si deve considerare, tuttavia i diversi ordinamenti hanno un costo diverso. 
In particolare, il causale è l'ordinamento maggiormente costoso in generale, anche se non vi è una risposta univoca,
dipendendo da caso a caso. Tuttavia, l'atomico vista la sua variabilità può presentare dei costi molto diversi.
In tutte le architetture per il multicast basato su ordinamento atomico in generale si pensa ad un frontend che possa
smistare i messaggi secondo l'ordinamento imposto: tuttavia, per garantire affidabilità, si deve considerare anche il
caso che il frontend non sia disponibile. Si deve trovare un modo di aggiungere qualità (per esempio, replicazione dei
frontend, con token per chi è effettivamente attivo...). Esistono altre architetture meno centralizzate, ma risultano
essere maggiormente complesse.
Inoltre, l'ordinamento atomico basato su frontend può essere unfair: clienti più vicini al front end sono favoriti.
Altre soluzioni si sono preoccupate di superare questo problema, introducendo però ulteriori costi.
\subsection{Il problema della sincronizzazione}
Per poter coordinare un insieme di copie, è necessario quindi che queste siano sincronizzate. La sincronizzazione non
è nient'altro che la \textit{sequenzializzazione di operazioni parallele}\footnote{Esempio, realizzazione della mutua
esclusione}, mediante la quale si \textit{impongono degli invarianti che devono essere rispettati}: si ha quindi un
ordine.
Tuttavia, la sincronizzazione è diversa dalla comunicazione: questa infatti è interessata ad un contenuto da
trasmettere, mentre la sincronizzazione è solo l'ordine. Nelle classiche architetture C/S i due aspetti sono accoppiati,
ma ciò non vale in altri casi.
Per poter sincronizzare non è necessario stabilire un ordinamento prescritto: si può scegliere quello più adatto a
seconda delle esigenze, in maniera anche molto indeterministica. In questo modo si hanno spazi di implementazione
molto variabili. In generale, essendo la sincronizzazione nel distribuito molto più costosa, si cerca di fornire un
ordine solo per gli eventi necessari.
Nel distribuito, i clock non sono sincronizzati. Si potrebbe pensare di realizzare un unico clock per tutti, ma è
impensabile (si pensi a derive nella comunicazione del tempo). Esistono standard per stabilire un formato univoco per
il tempo (UTC, Universal Coordinated Time), ma che funzionano solo se il numero dei partecipanti è limitato. Per
coordinarsi infatti i diversi client chiedono e ricevono il clock mediante uno scambio di messaggi, e quindi si cerca
di ottenere una mediazione, aggiustando di volta in volta il clock locale. Ma per far ciò serve un gestore continuo
che faccia monitoring!
Esiste anche un protocollo, Network Time Protocol, definito per il distribuito, in grado di basarsi su UTC per fornire
un tempo comune a tutti i partecipanti.
Si realizza una gerarchia di server, che coinvolge tutti i partecipanti: più si è vicini alla radice, maggiormente il
tempo sarà preciso. Allontanandosi invece si hanno delle derive. Ma se si guasta un server?
Questi protocolli son troppo complessi e costosi per garantire un tempo univoco. Il rischio è sempre che un evento venga
etichettato male, per via di derive nel clock locale rispetto a quello globale. L'idea è quindi quella di lasciar
perdere il tempo fisico, il clock, ma di realizzare una sincronizzazione solo sugli eventi d'interesse. È una
prospettiva più ottimista e molto meno costosa (infatti si riduce la comunicazione solo agli eventi signicativi,
evitando di dover tenere aggiornati gli orologi fisici).
Vi sono diversi sistemi per poter ordinare in base agli eventi di interesse. Quello meno importante è quello basato su
delle priorità definite in maniera statica. Infatti così si viene a realizzare una politica molto rigida, con rischio
di starvation (andrebbe bene se l'architettura prevede dei processi che debbano eseguire a scapito di altri).
I metodi più interessanti sono invece:
\begin{itemize}
 \item basati sull'ordinamento di Lamport, utilizzato soprattutto in US. Si realizzano dei clock logici da usare al
 posto dei clock fisici.
 \item basati sull'uso del sistema di token passing, utilizzato soprattutto in UE. Si realizza una struttura ad anello,
 e chi ha il token è il coordinatore.
\end{itemize}
\subsection{Ordinamento di Lamport}
L'ordinamento di Lamport si basa di avere diversi processi in grado di mantenere una propria storia interna (gli 
eventi su uno stesso processore sono già ordinati grazie alla storia), e in grado di comunicare fra di loro, in maniera
punto a punto con dei messaggi (non si usano multicast, non si possono mandare batch di messaggi !). L'idea è che il
numero degli eventi interessanti è sicuramente inferiore al clock fisico, e quindi si possono usare per ordinare.
L'ordinamento di Lamport si basa sulla relazione happened-before, per poter ordinare gli eventi, imponendo prima di
tutto un ordine locale. Si ha quindi che se l'evento a precede l'evento b sullo stesso processore, si ha che:
\begin{equation}
 a \rightarrow b 
\end{equation}
Ovviamente questa relazione vale anche per la comunicazione fra più processi, nel senso: se a è l'evento di invio di 
un messaggio, e b la sua ricezione da un altro processore, chiaramente sono in relazione di precedenza! Ovviamente,
questa relazione presenta anche la proprietà della transitività.
Tuttavia, questo ordinamento non è globale. Basta pensare a due processi che comunicano con gli eventi a e b, ed
entrambi presentano un evento che li precede localmente, k e q rispettivamente. Non esiste un ordinamento fra questi
due eventi, per cui si stabilisce un'altra relazione, ovvero quella sulla concorrenza; due eventi k e q sono
concorrenti se non si può imporre una relazione di happened before fra di loro:
\begin{equation}
 k \uparrow\uparrow q =!(k \rightarrow q)\land!(q \rightarrow k)
\end{equation}
In questo genere di relazione si può osservare che il ricevente ha sicuramente più vincoli rispetto al mittente,
trattandosi di una relazione fortemente orientata. In questo modo si hanno diversi orologi locali, ma non ancora un
unico orologio globale. In particolare, se si trattasse di un mondo asincrono, non si avrebbe nessuna ipotesi sulla
sincronicità fra i processi (i tempi di invio potrebbero essere molto lunghi, maggiori di qualunque tempo osservabile).
Si deve quindi trovare un modo per definire un orologio globale.

L'idea è che se $a \rightarrow b$, allora si ha che il tempo dell'evento a è minore del tempo dell'evento b:
\begin{equation}
a \rightarrow b \Rightarrow T S(a) < T S(b) 
\end{equation}
Questa è la condizione di clock logico, il quale può solo crescere. Si tratta di realizzare quindi una sorta di
timestamp, per identicare in maniera univoca gli eventi nel sistema!
Nel caso di una trasmissione, per cui $a \in P_i$ e $b \in P_j$ , si definisce la relazione di clock logico:
\begin{equation}
a \rightarrow b \Rightarrow LC_i (a) < LC_i (b) 
\end{equation}
Ogni processo incrementa il valore del clock logico fra due eventi, tuttavia l'aggiornamento del processo ricevente
deve tener conto anche del timestamp ricevuto insieme al messaggio per aggiornare correttamente l'orologio:
\begin{equation}
 LC_j = max(TS_{ricevuto} , LC_{i locale}) + 1
\end{equation}
Resta però il problema della relazione di concorrenza, per cui la relazione è ancora un ordine parziale! Per ovviare
a questo problema, si deve estendere la relazione di happend before:

Se $a \in P_i$ e $b \in P_j$ , si ha che $a \Rightarrow b$ se e solo se:
\begin{enumerate}
 \item $LC_i (a) < LC_j (b)$ oppure
 \item $LC_i (a) = LC_j (b)$ e $P_i < P_j$
\end{enumerate}
Ovvero, fondamentalmente si impone un ordine fra i processori stessi! Bisogna quindi considerare il problema dei 
sistemi dinamici, in cui il numero dei processori può variare dinamicamente. Servono quindi degli appositi gestori 
per gli indici.

La relazione di Lamport in genere tende ad aggiornare solo processi che \textit{ricevono messaggi da altri processi}:
chi li produce soltanto può avere anche dei timestamp molto bassi. Se tutti comunicano fra di loro (entrambe le
direzioni), allora tutti i processi saranno sincronizzati in maniera univoca. Esistono però dei casi in cui la relazione
di Lamport potrebbe avere dei problemi:
\begin{itemize}
 \item \textit{Problema del canale nascosto}: se ci fossero dei processi che usano dei canali preferenziali non noti,
 non si potrebbe sincronizzare correttamente (ma è un problema progettuale non reale!)
 \item \textit{Problema della causalità vera}: la relazione di Lamport è anche biettiva, cioè è valido anche la
 relazione opposta? In realtà no, due eventi che soddisfano la relazione di Lamport potrebbero non essere in rapporto
 di causa ed effetto!
\end{itemize}
Un sistema per realizzare l'architettura basata su Lamport è quella basata sui \textit{clock vettoriali}: ogni 
processo tiene conto in realtà anche dei clock logici degli altri processori. In questo modo però si hanno strutture
dati e protocolli più complessi! Tale sistema infatti non è scalabile:
\begin{enumerate}
 \item L'emettitore di un messaggio invia il proprio vector clock, aggiornandolo.\footnote{Non si incrementa in realtà
sempre, per il rischio di giungere velocmente ad overflow}
 \item Il ricevitore ottiene il vector clock, lo confronta con il proprio clock locale e quindi aggiorna quest'ultimo.
\end{enumerate}
Il vector clock garantisce di poter propagare le informazioni e di fornire una garanzia sul fatto che siano state
propagate. Tuttavia, a differenza dei normali clock logici, non si ha una relazione d'ordine globale! Si potrebbe
complicare ulteriormente realizzando delle matrici di clock.
La relazione di Lamport si può usare per sincronizzare, per esempio, l'accesso ad una risorsa condivisa. Permette di
garantire delle caratteristiche fondamentali che sono:
\begin{itemize}
 \item Correttezza (un solo processo accede alla volta)
 \item Liveness (Vi è un tempo limitato per accedere alla risorsa)
 \item Fairness (Non vi possono essere processi che rischiano starvation).\footnote{Un sistema basato su priorità non
 garantisce liveness e fairness}
\end{itemize}
Si può realizzare un sistema per accesso alle risorse che rispetti questi invarianti creando un processo
gestore\footnote{Soliti problemi per la QoS: se cade il gestore? Essendo un processo, avrà dei processi che
favorisce o meno in base alla vicinaza relativa...}, in grado di lavorare FIFO, e sfruttando un protocollo di tipo
``request-reply-release''. L'idea è quella di soddisfare prima le richieste arrivate per prime. Il gestore concede 
l'uso solo al processo con cui risponde con reply, il quale lo avviserà con il release una volta terminata
l'esecuzione. Il gestore potrà quindi fornire la risorsa al prossimo processo. Si ha un totale di 3 messaggi per ogni
accesso alla risorsa.
Per realizzare questo sistema invece con Lamport e senza uso di un gestore centrale, si deve supporre:
\begin{enumerate}
 \item Che tutti i processi siano in grado di comunicare l'uno con l'altro. Se quindi vi sono n processi, vi devono
 essere almeno
 \begin{equation}
  n \cdot (n - 1)
 \end{equation}
 canali per poter comunicare.
 \item Supposizione per la qualità: i canali sono FIFO, e non perdono messaggi.
 \item Ogni processo gestisce una propria coda per i messaggi. La sincronizzazione si basa propria sulla coda locale
 ad ogni processo.
 \item Il primo messaggio che ogni processo contiene è quello sull'indicazione locale del tempo, T0 : P0 , che
corrisponde ad un tempo sempre inferiore a quello che si potrà mai trasmettere.
\end{enumerate}
Il protocollo si basa sempre sull'idea di scambiare dei messaggi, e chi riceve tutti gli assensi può accedere alla
risorsa:
\begin{enumerate}
 \item Un processo che vuole accedre alla risorsa invia a tutti gli altri processi un messaggio con l'indicazione del
proprio tempo e di chi si tratta: Tm : Pi .
 \item Gli altri processi ricevono il messaggio, e devono mandare tutti un assenso: sono quindi $n - 1$ messaggi.
 \item Il processo richiedente può accedere alla risorsa solo se ha ricevuto tutti gli assensi, ma anche se nella sua
 coda non vi è una richiesta superiore alla propria (in base alla relazione di Lamport)!
 \item Una volta che un processo ha finito di lavorare sulla risorsa, elimina dalla propria coda il suo messaggio, e
 invia a tutti gli altri $n - 1$ avvisi, in modo che anche loro possano cancellare la richiesta completata.
\end{enumerate}
Si ha quindi che \underline{la coda deve essere mantenuta ordinata secondo timestamp}!
L'attesa che si ha per avere le risposte è proprio il sistema con cui si garantisce la fairness: i messaggi infatti
possono essere ritardati, ma comunque arrivano; se un altro processo aveva richiesto la risorsa prima ma il messaggio
è in ritardo su alcuni processi, verrà comunque servito prima.
Tale sistema però è molto costoso: richiede per ogni sincronizzazione $3(n-1)$ messaggi, e richiede garanzie
sull'affidabilità del sistema (se un nodo è guasto e non risponde mai?) e che il gruppo sia statico. Per ottimizzarlo,
ci dovrebbe pensare l'infrastruttura, magari sfruttando in maniera opportuna il broadcast/multicast per eseguire una
richiesta!
A differenza del protocollo centralizzato, se le copie sono studiate correttamente (con una giusta replicazione), la
responsabilità risulta essere ben distribuita, e non si dipende più da un unico gestore centralizzato. Tuttavia, si
deve tener conto dei guasti, su come escludere/ripristinare le copie e così via...

Un protocollo più efficiente ma sempre basato su Lamport è quello di Ricart e Agrawal: l'idea è quella di limitare il
numero dei messaggi in circolo, aggiungendo intelligenza ai processi. Infatti, adesso il reply viene fatto o da 
processi meno prioritari o che non hanno interesse alla risorsa. In questo modo, in realtà, solo un processo riceverà
gli $n - 1$ reply. Il rilascio costa uguale, ma il protocollo in totale viene a costare $2(n - 1)$ messaggi per accesso
alla risorsa. Il reply è invece ritardato nel caso che il processo che riceve la request sia proprio quello che la
sta usando.
Il problema in ciò è come si fa a definire il ritardo? E un'idea scivolosa/rischiosa, per cui si mescolano ai 
meccanismi di un protocollo meccanismi di supporto!
Come si fa a stabilire il ritardo, è dovuto a congestione o all'applicazione? Per quanto quindi questo sistema usi 
meno messaggi, è applicato ancora meno.
Vi sono esempi di implementazioni:
\begin{itemize}
 \item \textbf{CATOCS}, \textit{Causal Totally Ordered Comunication Operation Support}: è un sistema scalabile,
 mantenedo limitato il numero dei partecipanti. Si mantengono infatti continuamente dei gestori coordinati fra di loro,
 in grado di servire le richieste, si utilizza broadcast in casi specici.
 \item \textbf{ISIS}: è un sistema totalmente basato su gruppi e risorse di gruppo, per cui si necessita di coordinarsi
 fra le varie copie attive dotate di replicazione.
 Prevede l'utilizzo di diverse forme di multicast, distinte a seconda del tipo di ordinamento. Di base si hanno 
 infatti le multicast per i 3 ordinamenti specificati (FIFO, causal e atomic), ma inoltre è presente una particolare
 multicast, che serve proprio per la gestione del gruppo stesso. Utilizzando questa multicast, infatti, un gruppo può
 cambiare la propria granularità, eliminando copie non attive o reintroducendo quelle che hanno subito recovery.
 Caratteristica fondamentale è che il messaggio di gestione venga ricevuto solo dopo che tutti gli altri messaggi,
 dovuti agli altri tipi di multicast, siano stati ricevuti da ogni membro del gruppo. Riesce a fornire un sistema di
 monitoring (basandosi anche su delle tabelle che vengono aggiornate da questi multicast).
 L'atomic multicast di ISIS in particolare utilizza Lamport e le code locali ai processi per poter decidere con una
 politica di gruppo l'ordine dei messaggi. Ogni messaggio ricevuto quindi da una copia deve essere spedito a
 tutte le altre copie, con un'indicazione di timestamp. Ogni copia lo marca con il proprio timestamp, e lo rispedisce
 indietro al primo mittente, il quale lo marca definitivamente con il timestamp maggiore e lo rispedisce a tutti gli
 altri (costo di Lamport).
 Il causal multicast aggiunge un costo visto che la dipendenza di relazione è al di fuori del gruppo: si tratta di un
 ordine parziale, però richiede che comunque vi sia un coordinamento fra i clock logici dei mittenti, per poi
 far arrivare l'informazione in maniera corretta anche ai riceventi.
\end{itemize}
\subsection{Sincronizzazione a token}
Si tratta di un altro modello per superare il problema del gestore centralizzato. L'idea è quella di avere un anello
totalmente ideale, per cui i processi si conoscano solo in maniera limitata (prossimo ed antecedente). I vari processi
si passano un unico, sempre presente token, che stabilisce la sincronizzazione (chi ce l'ha è il gestore dinamico della
risorsa, ovvero vi può accedere se ne ha bisogno). Si tratta di una soluzione molto proattiva, poiché il token gira
lungo l'anello anche senza la presenza di richieste di sincronizzazione. Rispetto a Lamport il costo è inferiore, 
$n-1$ messaggi sempre.
In questo sistema si deve però pensare anche all'affidabilità del token: se non arriva? Si dovrà rigenerarlo, facendo
in modo però che vi sia sempre e solo un unico token in giro per l'anello. Si hanno quindi delle situazioni di elezione,
per cui più partecipanti vorrebbero eseguire l'azione di recovery, ma deve essere sempre uno solo! L'idea alla base è
che vi sia un time-out per cui scaduto, un processo può leggittimamente pensare che il nodo che aveva il token sia
guasto.
Questo processo allora crea un token d'elezione, che deve essere approvato da tutti i nodi perché diventi il nuovo 
token dell'anello. Questo significa che però ogni nodo deve avere una conoscenza migliore dell'anello (per esempio, non
solo il prossimo ma anche il nodo ancora successivo, e così via). Se il token d'elezione giunge quindi di nuovo a chi
lo ha generato, diviene il nuovo token\footnote{Se si fosse ripresentato il vecchio token, quello d’elezione sarebbe
stato eliminato}. Visto che più processi possono mandare il token d'elezione, si ha che si decide in maniera
statica quale è il più prioritario, numerando i processi.
Un protocollo di elezione molto semplice da fare ed efficiente è Bully: l'idea è che un processo di priorità superiore
zittisca le richieste di processi inferiori, per divenire lui il gestore. Si ha quindi che un processo di basso livello
manda verso l'alto un messaggio d'elezione. Se un processo di priorità superiore può assumere il compito di gestore,
manda un Answer verso il basso, e propaga verso l'alto la sua elezione. Se non riceve nessun Answer entro un certo
tempo, assume di essere diventato il gestore. Questo protocollo rischia di presentare molte fasi in base alla
disponibilità relativa dei processi, ma in realtà si risolve abbastanza velocemente. I protocolli di elezione sono
strutture tipiche delle infrastrutture dove le entità possono cambiare ruolo.
\subsection{Snapshot distribuiti}
Come si definisce uno stato nel distribuito? Si vuole uno stato globale, ma non è sempre possibile salvarsi tutta la
memoria sul disco, specialmente con un'alta replicazione. L'idea è quindi quella di realizzare un sistema in cui i
processi si scambino dei messaggi, mediante dei canali fortemente orientati, per poter salvare in maniera opportuna
delle foto del sistema. Si tratta quindi di effettuare dei tagli, in maniera tale da determinare gli stati signicativi 
e quelli no, per poter inglobare i primi per poter formare uno snapshot globale! Lo stato infatti è la composizione 
dei singoli stati di ogni processo.
Come si decide quali tagli vanno bene e quali no? I tagli realizzano degli snapshot numerati (ovvero sono ordinati), 
per cui un taglio che faccia in modo che un messaggio che inzia nello snapshot x e termini nello snapshot x + 1 deve
essere salvato per poter mantenere il sistema consistente, mentre l'opposto non va bene! Non garantirebbe la 
consistenza (come si fa a capire nello stato x chi è il sender del messaggio? E noto solo nello stato successivo!)
Ogni nodo è tenuto a salvare il proprio stato locale, così da avere inizialmente almeno consistenza locale. Questa è 
la base per fare uno snapshot globale distribuito. L'idea è che si utilizzi un protocollo che indichi quando fare la
foto locale e quando terminarla. Si sfrutta un apposito messaggio, detto marker, per cui ogni nodo può presentare due
stati:
\begin{itemize}
 \item bianco per indicare lo stato iniziale, prima dello snapshot.
 \item rosso per indicare lo stato successivo.
\end{itemize}
Una transizione dal bianco al rosso è una richiesta sul nodo perché esegua uno snapshot, e come una catena ordina 
anche agli altri nodi di eseguire uno snapshot: l'idea è quindi che ognuno salvi il proprio stato e poi rimandi il
marker. Quindi un nodo o riceve un marker rosso o diventa rosso per fare lo snapshot: salva lo stato, e poi invia il
marker su tutti i suoi canali d'uscita. Continua a salvare i messaggi che riceve e a restare rosso fino a quando
non riceve su tutti i suoi canali di input il marker rosso (ovvero le risposte dagli altri nodi!). A tale evento, si
ferma e salva lo snapshot. Si potrebbe anche sviluppare protocolli più complessi, per cui il marker viene inviato solo
su determinati canali. Da osservare che quindi un processo in stato rosso non potrà mai mandare un messaggio a un
processo in stato bianco, altrimenti non si salva correttamente!
Ma fino a quando si salva? Fino al prossimo marker! Questo è un sistema assolutamente scalabile! Il problema è che il
marker tiene un'indicazione del nodo che ha iniziato lo snapshot, per cui se si volesse che 2 nodi distinti facessero
lo snapshot, si dovrebbe estendere la politica, magari estendendo in maniera semplice le informazioni del marker, che
indichi a quale snapshot è riferito quello stato. A chi si manda poi lo stato in ogni modo? E una politica da decidere,
o un nodo che fa da repository oppure a chi ha iniziato lo snapshot...