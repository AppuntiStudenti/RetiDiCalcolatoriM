%% ================================================================================
%% This LaTeX file was created by AbiWord.                                         
%% AbiWord is a free, Open Source word processor.                                  
%% More information about AbiWord is available at http://www.abisource.com/        
%% ================================================================================
\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{calc}
\usepackage{setspace}
\usepackage{fixltx2e}
\usepackage{graphicx}
\usepackage{multicol}
\usepackage[normalem]{ulem}
%% Please revise the following command, if your babel
%% package does not support it-IT
\usepackage[italian]{babel}
\usepackage{color}
\usepackage{hyperref}
\title{Riassunto di studio per Reti di Calcolatori LS}
\author{Daniele Tiles}
\date{7 ottobre 2007}
\begin{document}
\maketitle
\newpage
\tableofcontents
\newpage
L'obiettivo del corso è introdurre modelli e tecnologie per poter superare il modello Client/Server (C/S), in modo 
da poter:
\begin{itemize}
 \item Migliorare la gestione
 \item Introdurre un supporto alla \textit{qualità del servizio, QoS}: questo è fondamentale, perché solo se un sistema
 presenta QoS, allora si può pensare ad un sistema di retribuzione (Internet, mail e gli altri servizi
lavorano best-effort): vi sono sistemi ``più standard'', importanti per i sistemi molto carichi.
\item Sviluppare sistemi in grado di far fronte anche ad alta mobilita`, l'integrazione di sistemi legacy.
\end{itemize}
Si tratta quindi di un corso per poter descrivere le tecnologie di sviluppo possibili per poter creare un
\textit{sistema distribuito}: cosa conviene scegliere, quando usare una tecnologia invece che un'altra? Ha senso cercare
di realizzare una nuova tecnologia, un middleware\footnote{Un middleware è un qualcosa che si interpone fra
l'applicazione e i livelli più bassi: fornisce servizi di aiuto per lo sviluppatore, mette a disposizione meccanismi per
poter implementare diverse politiche} proprio? Per fare qualche esempio, non ha senso usare CORBA
se il sistema necessita di un unico nodo, dove si deve interagire con componenti Java, oppure si devono usare agenti
mobili dove è necessaria la mobilità! Vi è un particolare interesse per il progetto e testing (soprattutto per
l'esecuzione e il deployment).

\section{Modelli di computazione}
Per poter sviluppare un sistema distribuito, è utile definire diversi modelli per l'esecuzione, in modo da poter
classificarli (modelli diversi possono avere vantaggi/svantaggi a seconda del sistema che si deve andare a realizzare).
La maggior parte dei modelli purtroppo sono troppo astratti per poter essere realmente utili da un punto di vista
ingegneristico, cioè non riescono a comprendere in toto la \textit{complessità} reale.
\newline

Le prime distinzioni che si possono fare sono su come si possono prendere le decisioni:
\begin{itemize}
 \item modelli \textit{statici}: le decisioni vengono prese prima dell'esecuzione. Risulta quindi essere meno
flessibile, e non si può variare nel corso dell'esecuzione, fornendo quindi poca qualità di servizio.
\item modelli \textit{dinamici}: in questo modello le decisioni risultano essere maggiormente costose, proprio perché 
si prendono mentre il modello è in esecuzione.
\end{itemize}
Per fare un esempio, il collegamento fra un client e un Name Server come deve essere stabilito? In maniera statica o
dinamica? E fra il client e server? Si tratta di problematiche da risolvere in fase di progettazione, tenendo conto 
dei costi. Un middleware introduce questi costi, fornendo possibilità statiche/dinamiche (non esiste un sistema
totalmente dinamico, realmente totalmente aperto).
Una seconda distinzione riguarda sulla reazione in caso di errori o concorrenza:
\begin{itemize}
 \item modelli \textit{preventivi}: si fornisce un comportamento garantito, oppure si previene/evitano determinati
errori. E quindi un sistema rigido, che presenta dei costi fissi.
\item modelli \textit{reattivi}: il modello reagisce in maniera dinamica alle situazioni che si presentano: non `
prevista quindi una politica di default, non si stabiliscono risorse a priori come nel caso precedente, fornendo un
comportamento più flessibile. I costi risultano essere variabili, a seconda della complessità del sistema (al crescere
degli attori, aumenta il numero necessario di lock/semafori da utilizzare, per esempio). Il costo può quindi essere
limitato a seconda delle esigenze. 
\end{itemize}
Esempio: una serie di clienti vogliono accedere in maniera univoca ad una risorsa unica: si tratta quindi di un problema
di sincronizzazione e mutua esclusione.
Si potrebbe risolvere fornendo dei quanti di tempo decisi a priori per ogni singolo cliente, oppure si fornisce un
token, per cui chi lo possiede è l'unico a poter accedere alla risorsa.

È da osservare che un sistema distribuito in generale offre un insieme di politiche diverse, che si possono mescolare a
seconda delle esigenze: un sistema moderno infatti deve essere in grado di seguire l'evoluzione dei servizi per poter
sopravvivere (es CORBA: in versioni successive aggiunge supporto al Web).
Un ulteriore modello semplice da descrivere riguarda in che modo le risorse
sono associate alle applicazioni:
$\bullet$ Siamo in monoutenza se le risorse sono tutte dedicate all'applicazione
descritta
$\bullet$ Altrimenti si parla di multiutenza: più complessa, ma decisamente più
u
u
diusa. Infatti, un numero superiore di applicazioni può portare ad un
o
uso più eciente delle risorse.
u
A seguito, si può ragionare quindi come sono disponibili le risorse:
o
$\bullet$ Modello workstation: le risorse sono concentrate su un unico nodo.
$\bullet$ Modello processor pool : le risorse sono distribuite, e vengono associate in
maniera trasparente al servizio.
6
\subsection{Processi o oggetti?}
Un'ulteriore distinzione riguarda su cosa basarsi per descrivere eettivamente
come avviene l'esecuzione.
Un primo modello si basa sull'idea del processo, che incarna la capacità di
a
esecuzione della macchina. Si specicano quindi delle operazioni, e si tratta di
modelli che tengono conto della macchina su cui si lavora, e funzionano molto
bene con risorse locali e stato locali. Vi sono più modelli:
u
$\bullet$ Processi alla Unix: si tratta di processi pesanti, ognuno dotato di un
proprio stato locale. In questo modello interessa solo in che modo i processi
possono comunicare, essendo lo stato non condivisibile.
$\bullet$ Processi alla Java: i processi son leggeri, hanno uno stato condiviso che
può essere usato anche per comunicare. Risulta essere più facile fare anche
o
u
dei cambi di contesto, ma si possono presentare delle interferenze.
I thread di una JVM, proprio perché dotati di uno stato condiviso, si possono
e
rapportare con un'altra JVM. I thread leggeri utilizzano lo stato comune per
comunicare.
`
Un'altra idea riguarda la modellazione basata sul paradigma ad oggetti. E
importante ricordarsi che questi son sempre delle astrazioni, e quindi necessitano
di una concretizzazione successiva. Anche qui si possono supporre due diversi
modelli:
$\bullet$ Oggetti passivi : i classici oggetti alla Java. Rappresentazione l'astrazione
di dati su cui delle entit` esterne possono lavorare. Non sono quindi
a
dotati di capacità propria d'esecuzione. Si può quindi avere concorrenza
a
o
fra diversi processi che vogliono accedere allo stesso oggetto, non si ha un
buon connamento e si ha scarsa protezione.
$\bullet$ Oggetti attivi : sono oggetti dotati di propria capacità d'esecuzione. I
a
processi quindi non entrano nell'oggetto, perché vi ` gi` all'interno dele
e a
l'oggetto una propria logica di gestione (si ha quindi un modello a request/response: un processo richiede di poter
usare l'oggetto mediante i
{`}metodi' forniti da questo, e questo in base alla sua schedulazione risponde
`
alla richiesta E sempre da osservare che un oggetto attivo ha comunque
un proprio stato interno, descritto da una parte sequenziale, ma a cui
non vi si accede con dei metodi, proprio grazie a questa logica interna: i
metodi veri e propri sono utilizzati solo internamente!). Un oggetto attivo
` quindi dotato di una coda delle richieste che si sono presentate, e una
e
sua politica di scheduling. Si supera in questo modo il problema degli
oggetti passivi, proteggendo del tutto l'oggetto e determinandolo completamente. Un oggetto attivo quindi, massimizzando
la parte sequenziale,
si può spostare più facilmente. Rappresent lo stesso modello dei servitori
o
u
paralleli, e, per esempio, degli agenti mobili. Un oggetto attivo quindi
7
si preoccupa di tutta la gestione dell'esecuzione internamente (richieste,
attività, errori, processi interni. . . :si forniscono meccanismi, mediante il
a
quale si possono specicare delle politiche diverse!
Come mai in Java tale modello non ` stato implementato? Si tratta di un mode
ello molto costoso, che non presenta delle scorciatoie utili se si lavorasse solo in
ambito locale!
Nei sistemi moderni, in realt` si parla di classi che contengono le denizioni
a
degli oggetti, e deniscono lo stato interno e i metodi con cui accedere. In particolare, in generale si parla di
semantica per riferimento, che per` ` in grado
oe
di funzionare solo in un ambito locale. Per riferire in remoto, serve un supporto
esterno. Per esempio, si parla di utilizzare socket, protocolli standard de facto
come TCP/IP. . .
Tuttavia, ` proprio questo il motivo per cui si vengono a definire dei mide
dleware, ovvero delle strutture in grado di fornire un supporto completo alla
comunicazione in remoto. Per esempio, Java Remot Method Invocation ` un
e
sistema in grado di estendere la semantica per riferimento locale, al remoto,
cercando di fornire un sistema omogeneo per poter accedere sia ad oggetti locali
che remoti. Nel caso specico di RMI, per esempio, si utilizza un classico pattern dei middleware, il proxy come delegato
per la comunicazione. Si realizzano
infatti uno stub lato cliente e uno skeleton lato server, che riescono a garantire
un qualcosa di simile alla normale comunicazione locale. Si cerca di presentare
un sistema trasparente per l'utente!
`
Perch` quindi non realizzare tutti i riferimenti come riferimenti remoti? E
e
sempre una questione di costo, sarebbe inaccettabile. Basta pensare a cosa
succede ad un oggetto passato via RMI: deve essere serializzabile, e cos` tutti
\i{}
i suoi componenti, in maniera che si possa fare marshalling e unmarshalling.
Ci` non ` sempre possibile in Java RMI (si pensi ad un oggetto che riferisce un
o
e
oggetto di tipo File, una risorsa strettamente locale). Vi sono poi altri problemi
da considerare:
$\bullet$ Un oggetto remoto viene registrato in un apposito registry, ma se viene
deattivato? Come viene gestita quindi la persistenza? E lo stato remoto?
$\bullet$ Due stub diversi possono riferire lo stesso oggetto remoto? Se s` come si
\i{},
gestisce la concorrenza?
$\bullet$ Come risolvere i nomi? Si può usare un riferimento sso, ma l'oggetto può
o
o
essere diverso (ma non ` il caso di Java).
e
$\bullet$ Si deve anche passare l'indicatore della classe, perché si possa realmente
e
utilizzare l'oggetto: cosa succede se la classe ` gi` presente? Java per
e a
esempio controlla mediante l'hash se la classe ` eettivamente quella core
retta.
8
\subsection{Deployment dell'applicazione}

Un'applicazione distribuita spesso necessita che sia suddivisa in diversi componenti, anche allocati su nodi diversi! Un
componente ` un'entit` con una
e
a
granularit` superiore all'oggetto, ovvero introduce comportamento e interazione,
a
estendo l'idea dell'oggetto.
Se si hanno quindi diversi componenti, che devono dialogare fra di loro, non
` detto che il deployment su una singola macchina sia la soluzione ideale: infate
ti, su un solo processore si ha una sequenzializzazione delle operazioni, e quindi
dell'applicazione stessa.
Spesso e volentieri, un middleware non si occupa del deployment, ma deve
essere realizzato da chi gestisce l'interazione fra i componenti. L'allocazione
può essere statica, cio` decisa prima dell'esecuzione, oppure dinamica, quindi
o
e
durante; quest'ultimo modello permette di poter spostare le risorse a seconda
delle esigenze durante l'esecuzione. Spesso e volentieri, l'allocazione viene realizzata utilizzando dei semplici le
batch, rendendola semi-manuale (certe congurazioni devono poi essere sistemate a seconda dei casi dall'operatore).
L'approccio misto ` quello più usato, essendo una via di mezzo fra l'allocazione esplicita
e
u
(tutta a carico dell'utente) e quella implicita (decisa in toto dal sistema).
\subsection{Altri modelli oltre il C/S}
Esistono diversi altri modelli oltre il classico C/S:
$\bullet$ Push: il servitore fornisce il servizio al cliente
$\bullet$ Pull: il cliente recupera il servizio che necessita in maniera diretta.
$\bullet$ Modello a delega: il cliente delega un altro agente per attendere il risultato,
e poi lo recupera da questo.
$\bullet$ Modello a notica: simile al precedente, solo che il delegato notica al
cliente la disponibilit` del risultato.
a
$\bullet$ Modello ad eventi: il tipico modello consumer/provider, in cui chi ` intere
essato si registra a chi produce gli eventi.
$\bullet$ Modello a provisioning: oltre agli end-point, vi sono intermediari interessati al risultato.
Di particolare interesse ` la classicazione dei modelli a scambio di messaggi :
e
$\bullet$ In fase di progettazione, si parla di sistemi sincroni se si ` interessati al
e
risultati, altrimenti asincroni.
$\bullet$ In fase implementativa, si parla di comunicazione bloccante se il richiedente
si blocca in attesa del risultato, altrimenti non bloccante
9
Oltre alla classicazioni principali, altre caratteristiche con cui si possono classicare i modelli a scambio di
messaggi:
$\bullet$ In fase di progettazione si parla di
-- un sistema simmetrico se mittente e ricevente si conoscono (rarissimo) oppure asimmetrico (caso tipico:C/S).
-- un sistem diretto (cio` se avviene una comunicazione diretta fra i
e
processi), oppure indiretto (se si utilizzano strutture tipo le socket)
$\bullet$ In fase di implemtazione si parla di
-- un sistema buerizzato se la comunicazione richiede un certo numero
di messaggi prima di poter trasmettere
-- Sistemi reliable se possono fornire QoS, senza perdere messaggi.
Nel caso si introduca un terzo oggetto che faccia da mediatore, si può quindi
o
lavorare in maniera sincrona ma non bloccante: ` il mediatore che resta in
e
attesa, sganciando il ricevente. Si possono avere due diverse modalit`:
a
1. Oggetti poll : ` un contenitore per la risposta alla richiesta, che viene
e
periodicamente interrogato dal ricevente con un sistema a polling. Si ha
cos` una comunicazione a 3 entit`. In questo modello, il ricevente deve
\i{}
a
sapere dove si trova l'oggetto poll, e vi deve essere un oggetto per ogni
`
risultato. E conveniente se si hanno operazioni corte, e attese brevi.
2. Oggetti callback : ` sempre un oggetto che conterr` il risultato, ma dotato
e
a
di una sua vita indipendente, e dotato di codice particolare da eseguire
`
quando giunge il risultato. E lui quindi a dover fornire il risultato al
richiedente, svincolandolo del tutto da questo! Conveniente in caso di
operazioni lunghe, indipendenti dal chiamante.
Spesso e volentieri, questi intermediari vengono realizzati da proxy, che sono in
grado di ridurre la complessit` logica della soluzione, integrando diverse funa
zionalit`.
a
In un modello basato sugli eventi, si ha un fortissimo disaccoppiamento (non
vuol dire che non si conoscono, ma che non ` necessario che siano attivi conteme
poraneamente per poter fare la comunicazione; ` una caratteristica fondamene
tale per i middleware) fra le entit` interessate al risultato, e quelle che forniscono
a
i servizi. In questo modello si ha quindi un'interazione molti a molti, per cui si
può facilmente mappare il multicast. In generale gli eventi non sono persistenti,
o
tuttavia non ` l'unico modello possibile.
e
10
\subsection{Spazi di tuple}
Un modello che deriva dall'astrazione della memoria condivisa e della comunicazione, e che garantisce il
disaccoppiamento fra le varie entit` ` lo spazio di
a e
`
tuple. E un meccanismo generale per la comunicazione e la sincronizzazione, in
cui si specica uno spazio di informazioni fortemente tipato. (Una tipica informazione può essere $<$ mittente,
destinatario, data $>$, per cui tutti i dati devono
o
essere diversi perché possa essere inserita)
e
Si hanno quindi due operazioni principali: la out consiste nell'inserire nello
spazio delle tuple un nuovo messaggio, mentre la in (bloccante) estrae la prima
tupla che fa match (in caso di più tuple che facciano match, ` una scelta non
u
e
deterministica). Ovviamente, si avrà sempre un numero inferiore di in rispetto
a
alle out. Se la in ` completamente specicata, si parla di sincronizzazione e non
e
di comunicazione. Uno spazio di tuple permette anche l'introduzione di QoS,
grazie alla persistenza della tupla nello spazio.
Gerlenter, con Linda, presenta due diversi modelli:
$\bullet$ A ring: si partiziona lo spazio delle tuple, per cui ogni nodo conosce
precedente e successivo: si ha una conoscenza locale, quindi limitata. Un
produttore può fare una out su un qualsiasi nodo, e il messaggio fa un
o
ciclo per vericare che non sia gi` presente su un qualche nodo. Lo stesso
a
discorso vale per la in, che fa un giro no a trovare un messaggio che fa
match. In Linda sono state considerate ovviamente delle problematiche
di replicazione (il messaggio deve essere ripetuto? Ma quindi lo si deve
togliere da tutti i nodi che lo contengono), sfruttando gli hash dei messaggi
$\bullet$ A matrice: le out vengono eseguite sulle righe, mentre le in si fanno sulle
colonne.
\subsection{Modelli a contenimento}
Si tratta di supporti presenti in ogni middleware: sono funzionalit` che aga
gregano diverse attività utili, che si possono replicare. In questo modo, uno
a
sviluppatore si concentra soltanto sullo sviluppo della business logic vera e
propria, utilizzando le politiche di default fornite dal middleware per quanto
riguarda il supporto al tempo di vita, il gestore della concorrenza, fornire la
QoS, sistemi di nomi. . . Fondamentalmente, un container ` un delegato che si
e
comporta come supervisore di certe attività.
a
\subsection{Il problema della trasparenza}
Esistono diversi signicati per la trasparenza: per esempio, si intende per l'allocazione l'indipendenza dalla localit`
delle risorse. In generale, per trasparenza si
a
intende un sistema in grado di fornire all'utente nale un comportamento omogeneo, anche se ai livelli sottostanti sta
lavorando con oggetti/servizi diversi
(remoti/locali, server principale/copia, . . . ).
11
Non ` sempre un elemento positivo, perché in molti casi i sistemi son cos`
e
e
\i{}
complessi, che non si possono gestire in maniera totalmente trasparente: si
richiede l'intervento dell'utente. Un esempio ` nella trasparenza dell'allocazione:
e
se non sappiamo dove si trova l'utente, come facciamo a dargli il servizio desiderato? La trasparenza non ` corretta a
livello di infrastruttura in questo caso;
e
l'utente infatti ` sempre più coinvolto.
e
u
Per esempio, TINA-C2 prevede sia un sistema trasparente, che un sistema
non trasparente in cui si possano definire le risorse inizialmente, e quindi introdurre la trasparenza.
\subsection{Le macchine astratte}
Son stati sviluppati diversi modelli per l'esecuzione, ma alla base vi ` la Rane
dom Access Machine: ` una macchina special purpose, con codice inalterabile,
e
in grado di eseguire istruzioni in sequenza (tutte le istruzioni hanno la stessa
durata), memoria limitata e un sistema di input e uno di output.
Un primo modello per la comunicazione ` la Parallel RAM, in cui simmagina
e
diversi programmi da eseguire contemporaneamente. Una PRAM ` costituita
e
quindi da P macchina RAM, ognuna delle quali esegue un programma, e ad ogni
clock vengono eseguite P istruzioni. Alla base vi ` una memoria condivisa, per
e
tutte le macchine, dove scrivere e leggere i risultati (anche i dispositivi di I/O
sono unici per tutte le macchine). Si tratta di un modello MIMD sincrono, per
cui quando tutti i programmi niscono, anche la macchina termina. Essendo
dotata di un'unica memoria, come devino essere strutturate le operazioni? La
concorrenza ` un requisito dicile da realizzare, in confronto al mettere le opere
azioni in sequenza. Le diverse PRAM si possono quindi categorizzare a seconda
della tipologia delle operazioni (in generale si hanno letture concorrenti e scritture sequenziali; la concorrenza `
invece utilizzata per il sistema di I/O, per
e
limitarne il collo di bottiglia). Un PRAM ` dicile da realizzare perché non `
e
e
e
scalabile.
Un secondo modello ` il Message Passing RAM, che ` sempre una collezione
e
e
di RAM, ma ognuna con la sua memoria dedicata (i sistemi di I/O son sempre
condivisi). Si ha quindi che le diverse macchine comunicano mediante dei canali
prestabiliti (vi devono essere almeno P-1 connessioni). Si hanno istruzioni ad
hoc, cio` delle send e receive con rendez-vous, una semantica sincrona: questo
e
vuol dire che un'operazione sblocca la sua duale. Una MP-RAM ` più facilmente
e u
realizzabile, e rappresenta meglio un modello locale. Se per esempio si volesse
eseguire un broadcast, servono almeno P-1 istruzioni, mentre una PRAM, per
quanto più dicile da realizzare, richiederebbe una sola operazione: ` un modu
e
ello con maggiore capacità espressiva. Restano comunque entrambi dei modelli
a
troppo astratti per poter essere implementati realmente. Aggiungendo vincoli
2 Si tratta di un consorzio di aziende per le telecomunicazioni, con l'obiettivo di andare
oltre OSI: l'idea ` quella di immaginare anche i possibili servizi, fornendo un modello più
e
u
coordinato, e un'infrastruttura con molti provider: si denisce un accordo/negoziazione fra i
fornitori dei servizi e i clienti, per poter per esempio stabilire la QoS, e quindi si fornisce il
servizio con i parametri indicati
12
e limitandoci quindi ad un'ipotesi di localit`, il progetto risulta più facilmente
a
u
realizzabile.
\subsection{Indicatori dell'efficienza}
In generale, ci si limita alla complessit` temporale, TP (N ), dove P ` il numero
a
e
di processori considerati: se ` pari ad 1, siamo in un ambiente sequenziale.
e
Un primo indicatore ` lo speed-up, che indica l'incremento di prestazioni se si
e
introducessero P processori:
SP (N ) =
T1 (N )
$>$1
TP (N )
(1)
Tuttavia, bisogna sempre tener presente che non tutti i programmi si possono
parallelizzare: ci` dipende se vi sono troppe dipendenze fra le sotto parti.
o
Un altro indicatore ` l'ecienza nell'uso delle risorse:
e
SP (N )
P
(2)
T1 (N ) 1
·
TP (N ) P
(3)
EP (N ) =
Ma quindi, ci` corrisponde a dire:
o
EP (N ) =
Possiamo quindi definire lo speed-up massimo:
SP (N ) = P
(4)
EP (N ) = 1
(5)
E l'ecienza massima:
Sotto queste condizioni si avrebbe che tutti i processori lavorano al massimo,
ovvero non abbiamo processori idle che possono risultare inutili. Questi sono
coecienti statistici, validi per tutto l'algoritmo. Quello che si può osservare `
o
e
che la situazione ideale la si avrebbe se lo speed-up dipendesse in maniera lineare dal numero dei processori. Una
soluzione ideale non interessante sarebbe
se si distribuisse i compiti ai processi in maniera uguale (un programma totalmente parallelo!), raccogliendo solo alla
ne il risultato. In realt`, i casi più
a
u
interessanti sono quelli dove si presentano delle dipendenze, per cui necessariamente vi deve essere una parte
sequenziale: questo caso presenta quindi una
comunicazione intrinseca, indipendente dal deployment che si viene a realizzare.
Si possono quindi studiare diversi casi basandosi sui fattori di interesse N e
P . In particolare, si può definire come fattore di carico, o loading factor:
o
N
(6)
P
che denisce la complessit` come viene suddivisa su ogni nodo. Vi possono
a
essere diversi casi:
L=
13
$\bullet$ N uguale a P : su ogni processore viene posta una parte molto semplice
del problema. Si dice ipotesi di identit`.
a
$\bullet$ Dipendenza di N da P
$\bullet$ Indipendenza, interessante al crescere di N
La legge di Grosh stabilisce che la soluzione migliore risulta essere quella di lavorare sempre nel concentrato. . . Ma
ci` non ` sempre possibile! Se per esempio
o
e
vi sono risorse limitate? Oppure, oltre un certo valore di N , non si riesce più
u
a lavorare nel concentrato, e la legge ` sicuramente inutile nel caso di vincoli,
e
tipo la presenza di risorse distribuite.
La legge di Amdhal stabilisce che vi ` un limite alla possibile parallelize
zazione, dato che ogni programma ` costituito da una parte parallela e una
e
parte sequenziale, e quest'ultima limita lo speed-up: si ha quindi che non cresce
linearmente, ma tende a un valore asintotico! Nella situazione migliore immaginabile, con le risorse correttamente
allocate, si ha quindi che si avrà uno speeda
up sso, mentre sar` l'ecienza a variare a seconda dell'architettura del sistema!
a
Come calcolare quindi lo speed-up massimo? Si vuole avere il numero di
processori tali che si abbia la minore complessit` del problema, realizzando un
a
sistema fortemente caricato: si denite quindi l'heavily loaded limit:
THL (N ) = infP (TP (N ))
(7)
Infatti, si lavora bene caricando molto ogni processore, i quali quindi lavorano
per tutto il tempo necessario: abbiamo quindi in questomodo un buon uso delle
risorse.
Tuttavia, per la legge di Amdhal, dobbiamo ricordare che vi ` anche una
e
parte sequenziale in ogni programma. . . che ` proprio la parte di comunicazione
e
fra i diversi processori! Al crescere del numero dei processori, si ha quindi
che lo speed-up diminuisce, allontanandosi dal valore massimo; questo degrado
delle prestazioni ` dovuto proprio al peso crescente della comunicazione fra i
e
processori, che diventa fondamentale.
\subsection{Caso di studio: somma di N numeri}
Una possibile soluzione, imponendo la condizione d'identit`, ` quella di utilizzare
a e
un albero binario per fare la sommma: le radici sommano i numeri, che passano
il risultato al padre, e cos` via. Supponendo quindi un albero con profondit` H,
\i{}
a
possiamo osservare che N = 2H+1 e P = 2H+1 $-$ 1, per cui P ` simile a N . Si
e
ha che quindi:
TP (N ) = O(H)
= O(log2 (N ))
= 2 · log2 (N )
14
Perch` 2? Perch` abbiamo 2 comunicazioni in ogni nodo. Possiamo quindi
e
e
valutare l'ecienza di questa architettura:
1
log2 (N )
EP (N ) = O
Ma quindi, al crescere di N, l'ecienza tende a 0! Per quanto riguarda lo speedup, si ha che non lavorano tutti i nodi,
ovvero più si risale l'albero e meno i
u
processori lavorano (il processore radice deve attendere, ovvero tempo di idle,
che tutti gli altri abbiano nito!). Se invece avessimo un usso di dati, i processori risulterebbero tutti sempre
impegnati (potremmo risolvere un insieme di
problemi).
Come si possono quindi mantenere sempre impegnati i processori? Si deve
incrementare il lavoro sul singolo processore, per cui:
L=
N
$>$$>$ 1
P
(8)
e quindi la complessit` deve essere superiore al numero dei processori: su ogni
a
nodo si ha quindi un certo numero di valori da sommare. Ci` si può ottenere
o
o
per esempio con un albero sso, ovvero un numero di processori ssi. Infatti:
TP (N ) = O (L + log2 (P ))
I due componenti rappresentano rispettivamente il tempo di computazione e
quello di comunicazione.
SP (N ) =
T1 (N )
TP (N )
=O
=O
N
P
N
+ log2 (P )
P
P
+
1
N · log2 (P )
Per cui, lo speed-up tende eettivamente a P
SP (N )
P
1
1
=O
+
1 N · log2 (P )
EP (N ) =
E l'ecienza tende ad 1. Quindi, caricando al massimo i processori ed usandoli
correttamente, si ottiene speed-up ed ecienza massimi.
\subsection{Considerare l'I/O}
In questi indicatori si ` tuttavia lasciato da parte il problema dell'I/O, che
e
spesos ` il vero collo di bottiglia in diverse architetture. Inoltre, vi son diversi
e
15
fattori che possono inuenzare l'ecienza e lo speed-up dell'architettura, come
il deployment reale. Si possono quindi estendere gli indicatori considerando
l'eetto generale dell'overhead, T0 (N ), che rappresenta le risorse e il tempo
realmente utilizzato per la comunicazione (caso ideale di deployment):
T0 (N ) = |T1 (N ) $-$ P · TP (N )|
(9)
Ma quindi, si ha che:
T0 (N ) + T1 (N )
P
E si ha che che lo speed-up risulta essere:
TP (N ) =
SP (N ) =
P · T1 (N )
T0 (N ) + T1 (N )
(10)
(11)
E che l'ecienza risulta essere:
EP (N ) =
1
1+
T0 (N )
T1 (N )
(12)
Per cui l'ecienza non sembra dipendere dal numero dei processori. . . in realt`,
a
` proprio T0 (N ) a dipendere dal numero dei processori : l'overhead dipende dal
e
numero di processori impegnati.
Supponiamo quindi di avere come obiettivo per l'architettura di mantenere
costante l'ecienza:
1
E=
1+
E+E·
T0 (N )
T1 (N )
T0 (N )
=1
T1 (N )
1$-$E
T0 (N )
=
T1 (N )
E
(1 $-$ E)
T0 (N ) =
· T1 (N )
E
T0 (N ) = K · T1 (N )
Se K fosse veramente una costante, saremmo in isoecienza. Un sistema isoeciente indica che, se manteniamo costante la
complessit` e aumentiamo il
a
numero dei processori, l'ecienza non varia. Il valore di K quindi determina se
il sistema ha un buon comportamento. In particolare:
$\bullet$ K piccolo: il sistema ` altamente scalabile. Al crescere di K quindi la
e
scalabilit` del sistema decresce
a
$\bullet$ Se non ` costante ma funzione dei processori, allora il sistema non `
e
e
scalabile.
I sistemi reali sono scarsamente scalabili.
16
\subsection{Conclusioni}
Un progetto deve essere valutato attentamente, per cercare di dimensionarlo in maniera corretta: nel caso di una
macchina singola l'heavily loaded limit è un ragionamento corretto, ma bisogna ricordarsi che si deve sempre cercare di
parallelizzare (non utilizzare la legge di Grosh). Per esempio, qual è il numero ideale di processi da realizzare? Si
può ben pensare che avere meno processi di processori risulti in processori che non lavorano, e quindi in un sistema 
non efficiente: il limite superiore quindi è che il numero dei processi sia lo stesso del numero dei processori. Un
processore è idle quando comunica, quindi si dovrebbe limitare la comunicazione, e quindi troppi processi comunicano
troppo.
In realtà, statisticamente si ha che un processore che lavora con 20 processi presenta ancora lo stato di idle: un
centinaio di processi per processore è un numero adeguato.

\section{Modelli per la replicazione}
Un obiettivo per poter fornire della qualit` di servizio ` ovviamente quello di
a
e
poter orire un servizio continuativo, stabile: se il servizio non viene erogato,
non si ` remunerati (anzi, in determinati ambiti ` proprio un danno economico
e
e
perché si possono presentare anche delle richieste di risarcimento; in certi ambiti
e
si parla anche di rischi umani). L'obiettivo ` quindi quello di realizzare un
e
sistema fault tolerant, resistente ai guasti. Sono invarianti che devono essere
comunque garantiti.
\subsection{Definire i comportamenti errati del sistema: cause ed effetti}
I possibili guasti si possono catalogare in maniera logica:
$\bullet$ Si parla di failure quando il sistema presenta un comportamento diverso
dagli invarianti di sistema previsti: ci` ` dovuto a un sistema progettato
oe
male. Il failure ` l'eetto visibile, riscontrabile dall'utente.
e
$\bullet$ Un errore ` invece il difetto che genera un failure del sistema, la causa
e
concreta che ha portato il sistema in uno stato non corretto.
$\bullet$ Un fault inne ` proprio il comportamento che si ` venuto a vericare che
e
e
ha portato il sistema a generare un failure: corrisponde quindi proprio alla
causa a monte.
I fault si possono classicare a seconda di quanto si ripetono:
`
$\bullet$ E permanente se si ripresenta in maniera periodica: sono quindi facili
da individuare, e facili da risolvere. Si parla di Bohrbug per errori che
si ripetono facilmente, riproducibili, che si possono quindi osservare e
correggere facilmente.
17
$\bullet$ Se invece ` transiente, sono più dicili da notare. Si parla di errori di tipo
e
u
Eisenbug, e sono molto dicili da eliminare.
\subsection{Ipotizzare il guasto}
Esistono diversi parametri per poter giudicare la disponibilit` di un servizio/sistema.
a
Un sistema ` fault tolerant se garantisce la dependability, ovvero si ha condenza
e
per qualunque aspetto progettuale. Ci` comporta che il sistema debba garantire:
o
$\bullet$ Reliability: deve essere adabile, in ogni modo il sistema si comporta
`
correttamente rispetto agli invarianti che sono stati imposti. E quindi un
sistema corretto.
$\bullet$ Availability: indica la disponibilit` nel tempo del sistema. La risposta da
a
parte del sistema deve arrivare entro una certa deadline prestabilita.
Per poter garantire la disponibilit` del sistema a fronte di guasti, si devono fare
a
delle ipotesi sul guasto. In generale, la procedura di ripristino consiste infatti
prima nell'identicazione del tipo di guasto, e ina base a ci` si cerca di riattivare
o
con la corretta procedura il servizio (fase di recovery).
In generale, si utilizza l'ipotesi delfault singolo, ovvero nel sistema si può
o
presentare un singolo guasto: solo quando il sistema torna operativo, si ha che
si potrebbe presentare un ulteriore fault. Quest'ipotesi ` necessaria per poter
e
semplicare il trattamento del recovery. Per poter definire ci`, ` necessario
o e
conoscere:
$\bullet$ Il Time To Repair, TTR, che ` il tempo necessario per accorgersi e per
e
poter correggereil guasto
$\bullet$ Il Time Between Failure, ovvero il tempo che intercorre fra due failure
(oppure la media)
L'obiettivo ` quindi che il TTR sia inferiore in maniera stretta al (M)TBF.
e
Mediante l'ipotesi del guasto singolo, si può osservare che se abbiamo più copie
o
u
in grado di fornire il servizio, si puòspecicare il numero di fault tollerabili e
o
identicabili. Se avessimo solo due copie, non possiamo tollerare un guasto,
ma possiamo identicarne uno. Con gi` 3 copie, un guasto si può tollerare,
a
o
perché comunque restano due macchine con cui identicare i guasti successivi:
e
si riescono cos` ad identicare no 2 guasti. La generalizzazione ` che se si
\i{}
e
hanno 3t copie, si tollerano massimo t guasti.3 Si possono quindi ridefinire le
propriet` precedenti in base a questi valori:
a
$\bullet$ La reliability ` il valor medio sulla disponibilit`/indisponibilit` della risore
a
a
sa considerata
3 Non
si fanno ipotesi sul tipo di guasto, ma solo sul fatto che ` singolo
e
18
$\bullet$ L'availability si può esprimere come la percentuale utile di lavoro che il
o
sistema riesce ad orire:
A=
M T BF
M T BF + M T T R
(13)
In particolare, si possono distinguere i casi di lettura e scrittua: infatti, la lettura
non modica lo stato, per cui si può fornire un servizio di lettura anche se vi
o
sono diverse copie non funzionanti. Viceversa, per garantire uno stato coeso fra
tutte le copie, la scrittura richiede che tutte siano disponibili.
La reliability si può anche vedere come la probabilit` che un servizio sia
o
a
disponibile per un certo intervallo di tempo (a 0 deve corrispondere con l'availability).
Esistono altre propriet` fondamentali, come la correttezza e la vitalit` : la
a
a
prima denisce che comunque sia, il risultato fornito dal sistema sar` corretto,
a
la seconda invece stabilisce che comunque si raggiunger` l'obiettivo. L'ideale
a
sarebbe disporre di entrambe le propriet`, cos` da poter mascherare i fault: si
a
\i{}
può ottenere mediante oppurtune tecniche di replicazione spaziali e/o temporali:
o
$\bullet$ Se si hanno diverse macchine, che eseguono ognuna un algoritmo diverso
ma forniscono lo stesso risultato, garantiamo la massima correttezza
$\bullet$ Se si hanno invece diverse macchine ognuna con un compito specico, si
ottimizzalo throughput del sistema
Una singola macchina non basta per identicare e correggereun guasto! La
replicazione ` fondamentale, almeno per fare monitoring (utilizzo di cluster per
e
fare il controllo di una risorsa): si potrebbero utilizzare delle speciche parti
per controllare e correggere l'architettura, ma ` necessario rispettare sempre il
e
principio della minima intrusione: il rischio sarebbe che troppe risorse sono
allocate solo per vericare che il sistema funzioni correttamente, riducendone l'
ecienza! La replicazione ` un costo che si va ad aggiungere al sistema: ma in
e
generale si tratta di un costo sso, a fronte di possibili costi molto peggiori in
caso di fallimento del sistema!
\subsection{Possibili guasti}
I guasti si possono anche classicare in base alla loro riconoscibilit` da un sistema
a
(processore esterno):
$\bullet$ Fail-stop: un processore si ferma perché non rispetta un invariante, e
e
questo viene identicato dagli altri processori
$\bullet$ Fail-safe: come il precedente, tranne che gli altri processori non se ne
accorgono: in questo caso quindi non ` identicato, ma potrebbe essere
e
tollerato (dipende dall'architettura stessa).
19
$\bullet$ Fallimento di tipo bizantino: il processore termina presentando per` como
portamenti assolutamente casuali.
Nelle reti di calcolatori si possono poi presentare ulteriori generi di guasti, dovuti
alla mancata totale ricezione/trasmissione di messaggi(send/receive omissions),
oppure anche al fatto che un processore si blocca. Le reti poi possono aggiungere
problemi (se un router per esempio non rispone più, si potrebbe avere che la
u
rete risulta partizionata in due sottoreti, incapaci di comunicare fra di loro).
\subsection{Architetture per garantire la fault-tolerance}
Nel corso del tempo sono state pensate e realizzate diverse tipologie di architetture in grado di fornire questo genere
di servizio.
Una prima ipotesi operativa ` quella di realizzare un sistema con vera e
e
propria replicazione hardware, per cui si hanno due possibilità:
a
1. O si realizza un'architettura in cui vi ` una sola macchina a lavorare,
e
mentre un'altra ne controlla il corretto funzionamento, per cui interviene
solo in caso di guasto. Per esempio, per avere la correttezza si potrebbe
avere che a una determinata richiesta rispondano tutte le macchine, ma
la risposta viene controllata prima di essere fornita.
2. Oppure si realizza un sistema con cluster, dove si aggiunge una logica di
controllo che ` in grado di stabilire se una risorsa ` disponibile o meno,
e
e
e quindi ` in grado di escluderla dal sistema. Al crescere delle risorse
e
aumenta la probabilit` di guasti, quindi si devono utilizzare algoritmi
a
ecienti per identicarli correttamente: si vuole un metalivello eciente!
Un'ipotesi spesso comune ` quella della memoria stabile 4 : si vuole realizzare
e
un sistema per cui la memoria persistente dell'architettura non fallisca mai
(sempre disponibile, sempre corretta). Una possibilità per realizzare ci` consiste
a
o
nell'utilizzare due dischi, e fare in modo che ogni blocco sia replicato in maniera
uguale su entrambi, con probabilit` d'errore congiunta nulla (caso dell'errore
a
singolo). Si ha che quindi i singoli blocchi possono indicare la presenza di errori
o meno (omissions), con l'uso di appositi codici di controllo. Mediante questi
indicatori infatti si ha il controllo se le copie sono uguali o meno:
1. Sulla seconda copia potrei avere dei valori non corretti
2. Sulla seconda copia potrei avere dei valori corretti ma diversi dalla prima
copia
4 Si potrebbe realizzare mediante la tecnologia RAID, Redundant Array of Inexpensive
Disks; ` un sistema a basso costo, inizialmente realizzato per poter velocizzare la lettura e
e
quindi per poter fornire un semplice supporto alla replicazione. Le operazioni sui dischi son
quindi coordinate. In realt`, quando un disco si guastava, essendoci problemi nel sistema di
a
gestione non si aveva mai una replicazione veramente buona
20
Il secondo caso in real` ` il peggiore, dovuto magari a problemi di aggiornamenae
to sulla seconda copia5 : clienti che accedono alla seconda copia prima della fase
di recovery non potrebbero accorgersi che il dato ` stale. Ogni operazione deve
e
procedere su tutte le copie quindi per poter garantire risultati corretti! Tale
sistema ` sicuramente costoso e dicile da realizzare.
e
Un'ulteriore aspetto riguarda un sistema software per fare il monitoraggio
delle risorse, necessario e conveniente da mettere in parallelo al sistema di recovery hardware: si tratta quindi di
progettare degli appositi protocolli e sistemi in
grado di permettere all'applicazione di ripartire con il minimo costo e nel minimo
tempo. Il problema di ci` ` che un sistema software del genere sfrutta le stesse
oe
risorse dell'applicazione (CPU, RAm,. . . ), riducendone l'ecienza: si deve quindi progettare il tutto rispettando il
principio della minima intrusione, limitando
il più possibile quindi le risorse allocate al metalivello di monitoring/supporto
u
dell'applicazione. La replicazione presenta dei costi elevati in termine di realizzazione, ma anche di progettazione ed
uso delle risorse, quindi deve essere
attentamente studiata. Ipotizzare guasti singoli semplica la realizzazione dei
protocolli, per esempio.
Una possibile realizzazione ` un sistema tandem, cio` in cui tutto ` raddoppie
e
e
ato: l'idea ` quella di realizzare un sistema fail-safe, per cui una CPU identica
e
l'errore. Ovviamente, un sistema del genere ` complesso e costoso.
e
\subsection{Copie calde e copie fredde}
Vi sono due possibili modelli per la replicazione, e dipendono dal comportamento
delle copie:
$\bullet$ Copie fredde: vi ` un'unica copia attiva che funziona, più diverse copie
e
u
dormienti. Deve essere quindi presente anche un manager del sistema, in
grado di attivare in caso di necessit` una delle copie dormienti (ovvero se
a
la copia principale presenta un fault e smette di lavorare correttamente).
Il manager si preoccupa quindi di attivare una nuova istanza dell'oggetto
solo quando la precedente non funziona. Questo sistema presenta un alto
tempo di congurazione, e ha il problema che lo stato non ` direttamente
e
salvato sugli oggetti in standby (si dovrebbe recuperare in un qualche altro
modo. . . ).
$\bullet$ Copie calde: in questo caso vi sono diversi oggetti pronti, pronti a sostituire una copia che non funziona:
l'idea ` che in questo caso vi sia invece
e
un protocollo di ruolo, in grado di indicare ad ogni copia che comportamento deve assumere (` la principale o meno):
infatti, la copia principale
e
` attiva, ovvero in grado di salvare lo stato, mentre le altre son passive,
e
che vengono sempre aggiornate ad ogni modica sulla copia attiva. Se
5 Osservazione: ` sicuramente conveniente un'indicazione di tempo per la scrittura, in
e
maniera tale da poter aggiornare tutte le copie al dato più recente eettivamente presente
u
21
fallissero anche tutte le copie calde, si può ripiegare su un sistema a copie
o
fredde, in grado di inizializzare una nuova copia.
\subsection{Gestione delle risorse}
La replicazione delle risorse ` necessaria per un sistema distribuito, perché si
e
e
introduce replicazione, e si può garantire la fruizione del servizio. In un progetto
o
quindi si deve considerare come allocare le risorse sui vari nodi, e con che grado di replicazione: risorse replicate
signica quindi che si hanno copie multiple
delle risorse su nodi diversi! Maggiore ` l'importanza della risorsa, maggiore
e
deve essere il suo grado di replicazione.
Si possono ipotizzare sempre due modelli base:
$\bullet$ Modello passivo: una sola risorsa lavora, e le altre sono in attesa pronte
a sostituirla in caso di failure. Il modello generale ` quindi quello di
e
un master con una serie di slave, organizzati in maniera gerarchica. Se
il numero di partecipanti ` limitato non ` costoso, ed ` il modello più
e
e
e
u
facile da implementare (ha un protocollo chiaro e semplice). Il grado di
replicazione ` quindi indicato dal numero di copie passive disponibili.
e
$\bullet$ Modello attivo: tutte le copie eseguono assieme per ottenere il risultato
desiderato. Sono quindi tutte e attive, ed ` necessario predisporre una
e
parte di controllo abbastanza complessa, quindi la modellazione e l'implementazione sono più costose (tutte le copie
devono avere l'input, e tutti
u
gli output devono essere confrontati).
In entrambi i modelli non si lavora in maniera sequenziale, ma parallela: le
copie possono comunque svolgere anche altri compiti, eseguire più operazioni
u
contemporaneamente!
Nel primo modello si deve pensare ad un sistema per tenere aggiornate le
copie fredde: si utilizzano quindi dei checkpoint, per cui lo stato viene trasferito
e replicato sulle copie fredde. . . ma quando farlo?
$\bullet$ Se lo si fa prima di fornire la risposta al cliente, si garantisce un'alta
ecienza a scapito della correttezza (se gli slave presentano un guasto,
non saranno aggiornati correttamente)
$\bullet$ Se invece si attende che tutte le copie garantiscano di aver ricevuto l'aggiornamento prima di spedire la
risposta, il sistema ` corretto, ma la
e
risposta avrà un tempo molto lungo.
a
L'aggiornamento può essere eseguito periodicamente (time-driven) oppure ad
o
ogni volta che si presenta un nuovo evento (event driven). Quest'ultima politica
risulta essere maggiormente dinamica e complessa da realizzare. Per esempio,
22
un evento potrebbe essere scatenato dall'inizio del servizio della richiesta (estrazione dalla coda delle richieste), e
terminare alla ne per poter fare il checkpoint.
Le operazioni poi possono correlate o meno, e quindi anche il checkpoint
potrebbe essere correlato! In questo caso, servono delle informazioni dall'utente
su quando conviene fare il checkpoint (tipicamente, si attende che si giunga ad
uno stato stabile e poi lo si esegue).
Serve quindi la trasparenza? Il cliente deve sapere chi contattare se il master
non ` raggiungibile, quindi no! Deve avere idea che non sta interagendo con la
e
copia principale, per poter sfruttare le risorse per potersi collegare alla risorsa
secondaria mediante un opportuno sistema di nomi. Inoltre, a seconda della
complessit` del master, potrebbe essere conveniente farlo ritornare direttamente
a
come master, invece che come slave. Si può comunque realizzare cos` una sorta
o
\i{}
di fault-transparency, per cui dall'esterno la risorsa sembra reggere diversi fault
e riesce a fornire un servizio con continuità.
a
Infatti, sarebbe meglio che all'esterno non si sapesse il grado di replicazione
di una risorsa, perché altrimenti sarebbe una decisione distribuita mediante il
e
deployment: ` in realt` il middleware ad accorgersi e a fare da supporto, cone
a
tattando la nuova copia: per il client ` tutto trasparente!
e
Nel caso di copie attive, il client come le deve conoscere? Se le conosce in
maniera esplicita, non abbiamo trasparenza e fornisce visibilit` alla replicazione:
a
viene utilizzato solo in appositi sistemi ad-hoc. In realt`, vi ` sempre un sistema
a
e
`
implicito a garantire la comunicazione fra il client e le copie attive. E quindi necessario pensare ad un frontend che
si preoccupi di smistare opportunatamente le
richieste: potrebbe essere statico (in grado quindi di smistare qualunque richiesta) oppure dinamico (specializzato per
una determinata richiesta). Ma nel caso
di oggetto singolo, questo diventa un collo di bottiglia, perché se viene a mancare
e
l'architettura non si regge più in piedi! Deve garantire un'alta adabilit`.
u
a
Il secondo modello ` realizzabile facendo in modo che ogni client diventi il
e
gestore di quel tipo di richiesta, ma ci` necessita che le varie copie si mettano
o
d'accordo: vi ` un problema di sincronismo. Si può risolvere in diversi modi
e
o
(sfruttando una politica ad anello, utilizzando un token univoco, in modo da
simulare cos` un gestore unico fra tutte le copie attive), ma utilizzando delle
\i{}
approssimazioni per la sincronia, si possono ottenere dei protocolli più semplici
u
da implementare (si possono presentare dei problemi dal punto di vista semantico, ovvero come devono essere ordinate le
operazioni), risultando meno costose
e più veloci. Infatti, in caso di richieste indipendenti fra di loro, la perfetta
u
sincronia ` soltanto un costo aggiuntivo! La sincronicit` deve quindi essere stue
a
diata a seconda del tipo di operazioni che si devono svolgere (letture sincrone,
scritture sequenziali). Per altre operazioni, si deve tener conto dell'architettura
e del signicato dell'operazione: si potrebbero eseguire in maniera indipendente,
e procedere quindi successivamente ad una riconciliazione fra le copie per avere
`
uno stato univoco coeso. E importante per` nel caso di copie attive che l'ago
23
giornamento delle copie preceda la consegna del risultato al cliente.
`
E quindi necessario pensare ad un gestore delle copie attive, in grado di escludere correttamente le copie non
funzionanti (altrimenti si avrebbero tempi
di attesa altissimi per avere conferma degli aggiornamenti; se un'operazione si
guasta, deve esserci comunque un modo per poter fornire una risposta all'esterno) e quindi di poter essere in grado di
coordinare le diverse copie attive. Per
esempio, invece che utilizzare un sistema per cui tutte le copie garantiscono la
conferma dell'azione, si potrebbe utilizzare una forma di voting: solo la maggioranza delle copie in concordanza fra di
loro proseguono l'esecuzione, mentre le
altre dovranno essere sospese e si dovr` procedere con il recovery (identicazione
a
e recupero dal gestore o da chi altro: dovr` essere deciso in fase progettuale).
a
Questo protocollo sgravia la risposta verso l'esterno, che può essere fornita più
o
u
`
velocemente! E evidente la necessit` di un gestore per il monitoraggio, controla
lo delle copie. In generale, in un sistema reale, il numero di copie ` limitato:
e
studiando opportunatamente il protocollo si riduce l'overhead al minimo.
\subsection{Modelli per la replicazione, copie attive}
L'ipotesi ` che vi ` un insieme di copie che devono produrre un risultato per
e
e
un insieme di clienti. Si deve quindi pensare a delle opportune fasi di coordinamento sia prima che dopo l'esecuzione,
per poter organizzare le copie e
fornire il risultato deciso. Si possono quindi pensare modelli in cui le copie lavorano s` in maniera indipendente, ma
all'occorrenza sarebbero in grado di fare
\i{}
da supporto a copie non funzionanti, ottenendo cos` un bilanciamento del carico.
\i{}
Nel caso delle copie attive, vi sono 5 passaggi che si devono fare in ordine:
1. All'arrivo di una richiesta, come deve essere smistata? Vi sono due possibilità: o arriva ad un'unica copia che poi
deve fornirla anche alle altre,
a
oppure viene mandata dal client direttamente a tutti. Per avere maggiore
trasparenza, ` ovviamente preferibile il primo modello. La copia quindi
e
può avere un comportamento dinamico o statico.
o
2. Vi ` poi la fase di coordinamento fra le copie: dipende nuovamente dale
l'architettura che si vuole realizzare. Si potrebbe avere un unico master
gestore, oppure tutte le copie possono eseguire o in maniera paritaria o
sono pesate a seconda della loro importanza. Questa fase può servire per
o
bilanciare correttamente il carico fra le varie copie attive.
3. Quindi vi ` la vera esecuzione. In generale tutte le copie devono eseguire,
e
ma non devono farlo in contemporanea. Tutte hanno stato, e devono
fornire un risultato. Per certi servizi vi potrebbe essere una copia dedicata
che può fornire subito la risposta.
o
4. Seconda fase di coordinamento: il master (oppure le copie con un sistema
di voting) determina il risultato nale basandosi sulle risposte ottenute
24
da tutte le copie. Questa ` anche la fase in cui si possono individuare i
e
guasti. Questa fase può essere utile nel caso si fossero ricevute più richieste
o
u
correlate fra di loro, e quindi si potrebbe evidenziare un ordine non corretto
d'esecuzione. Ci` per` non ` sempre possibile, quindi bisogna pensare alla
o
o
e
prima fase di coordinazione mediante l'uso di un'operazione atomica, cos`
\i{}
da evitare un eventuale undo. In base quindi all'ordine delle richieste, le
varie copie sanno come eseguire.
5. Presentazione del risultato al cliente, che deve essere univoco.
Il protocollo ` molto più complesso di quello a master/server, tuttavia per grae
u
di di replicazione limitati, ovvero con poche copie e un protocollo denito in
maniera eciente si ha un tempo di risposta piccolo.
Un'architettura basata su master/slave (copie passive) riduce di moltoi costi,
visto che vi ` un'unica macchina a lavorare: produce il risultato e si preoccupa
e
di fare l'operazione di checkpoint su tutte le altre copie, e quindi lo fornisce al
cliente. La gestione ` maggiormente semplicata.
e
\subsection{Politiche di aggiornamento}
Esistono diverse possibilità per eettuare l'aggiornamento delle copie. Vi potrebbe
a
essere una copia primaria che si preoccupa di aggiornare le altre, oppure tutte
le copie possono assumere questo compito. Si deve poi decidere se privilegiare
la correttezza (situazione eager o pessimista, si prevede di aggiornare tutte le
copie prima di fornire la risposta al cliente, quindi a scapito della prontezza della risposta), oppure il tempo di
risposta (situazione lazy o ottimista, aggiorno
prima il client e poi le altre copie).
$\bullet$ Copia primaria eager : una copia esegue, si preoccupa di aggiornare tutte
le altre copie, e quindi fornisce il risultato al cliente. Esegue quindi
un'operazione alla volta
$\bullet$ Copia primaria lazy: aggiorna prima il cliente poi le altre copie. Pu`
o
`
quindi eseguire più operazioni alla volta. E compito del gestore controllare
u
gli aggiornamenti e vericare che siano stati recepiti da tutte le copie in
maniera corretta, coordinandole.
$\bullet$ Aggiornamento di tutte eager : tutte le copie devono eseguire, mettesi d'accordo (two-phase commit) e quindi
fornire il risultato: ` in questo caso
e
che si potrebbero avere undo costosi. Un'altra soluzione sarebbe che una
copia, ricevuta la richiesta, la propaga a tutte utilizzando un'operazione
multicast atomica.
Il problema del coordinamento ` che ` costoso: tuttavia, ` anche lo strumento
e
e
e
che ci fornisce le maggiori garanzie di correttezza. Vi possono essere dei rilassamenti, per esempio: si parla di copie
tiepide quando i checkpoint sono fatti a
determinati intervalli, per ridurre il costo dell'operazione.
25
\subsection{Clustering}
L'idea del cluster ` quella di realizzare un insieme di risorse replicate sempre
e
disponibili (high availability), cercando di snellire il tutto per non avere un tempo di risposta troppo alto. L'idea
quindi sarebbe avere un protocollo semplice
e le soluzioni sempre disponibili (ma spesso ` solo un bello slogan).
e
Per realizzare ci` si utilizzano componenti o the shelf, a basso costo e facilo
mente reperibili e sostituibili (alla Google). Si può cercare anche di bilanciare
o
il carico: all'arrivo di una richiesta, una sola copia lavora, possibilmente quella
più libera (esecuzione dinamica quindi). In generale quindi:
u
$\bullet$ Si riceve la richiesta
$\bullet$ La si smista alla macchina meno carica
$\bullet$ Esecuzione
$\bullet$ Viene fornito il risultato al client.
`
Per decidere quale copia debba eseguire, come si fa? E necessario un sistema
di monitoring (necessario per la QoS), uno scheduler (in generale strutturato
master/slave). Questo sistema deve anche essere in grado di identicare eventuali copie guaste, e quindi di escluderle
per mantenere delle buone prestazioni,
possibilmente facendo migrare i servizi sulle macchine al momento migliori. Per
determinare se una copia ` attiva, si usano degli heartbeat, ovvero si mandano
e
dei messaggi per vericare se la copia ` viva: se non risponde, si suppone che
e
ci siano problemi. Questo sistema deve essere correttamente dimensionato (ogni quanto si manda l'impulso? Qual'` il
tempo di comunicazione? Il massimo
e
ritardo accettabile? In generale vi ` una macchina apposita per questo compito).
e
Nel caso di fail-over, vi sono due diverse politiche da attuare:
$\bullet$ O si attiva una macchina che era passiva
$\bullet$ Oppure si sfrutta una macchina che era gi` attiva per un altro servizio,
a
caricandola ulteriormente. Ci` può essere costoso alle volte
o o
Se l'heartbeat non ` progettato correttamente, potrebbe causare fail-over!
e
Se si partizionano le risorse (abbiamo per esempio due sottoreti) cosa succede? Pu` essere problematico, il cluster
dovrebbe lavorare comunque! Si deve
o
ripristinare la rete globale. Il servizio deve funzionare anche se vi sono problemi
di coordinamento, quindi in realt` si prosegue lo stesso, e si rinvia l'aggiornaa
mento ad un secondo momento. Le due sotto-reti quindi si coordineranno più
u
avanti!

\section{Sistemi per la comunicazione e la sincronizzazione}
La maniera con cui due processi possono comunicare ` molto variabile: si
e
possono classicare le comunicazioni in diversi modi (sincrone/asincrone, dirette/indirette, bloccanti/non bloccanti . .
. ). Di particolare interesse riguarda
ovviamente la comunicazione a molti destinatari : un tale sistema può essere alle
o
volte molto costoso da gestire, ma spesso ` necessario (gestione a copie attive;
e
sottoscrizione di consumer ad eventi; e cos` via. . . ).
\i{}
Nel modello di Internet erano stati studiati due sistemi: il broadcast (realmente inarontabile dal costo) e il multicast
(realizzabile su indirizzi di classe
D). Tuttavia, questi sistemi risultano essere ecienti nch` si lavora comunque
e
con una localit`. Se invece si dovesse lavorare su più gruppi, ` necessario utia
u
e
lizzare come protocollo IGMP (utilizzo quindi di un protocollo non locale), che
permette a una o più reti di trasmettere in multicast, realizzando una sorta di
u
14 Obiettivo: raggiungere un qualunque indirizzo della classe specicata, che sia il più vicino
u
o il più comodo
u
38
broadcast locale (comunque abbastanza costoso)15 . Oltre al costo, queste comunicazioni mancano prima di tutto di QoS
(IGMP non garantisce l'ordine dei
messaggi!), ma hanno anche una debole capacità espressiva (non si riesce per
a
esempio a definire priorit` nelle comunicazioni, oppure sincronismi. . . ). Infatti,
a
in Internet si ragiona utilizzando il Time To Live per poter dirigere e guidare
una comunicazione multicast: se ` progettato male, l'intero sistema si ingolfa.
e
IGMP ` un protocollo che permette ai nodi di una rete di lavorare in gruppo
e
(si registrano tutti a uno stesso indirizzo multicast). Richiede quindi l'utilizzo
di un router di supporto, in maniera tale da poter controllare sia il traco in
entrata che in uscita; sfrutta infatti dei particolari messaggi IGMP, come le
query, per vericare chi si sia registrato a quell'indirizzo multicast mediante un
messaggio di tipo report. Si cerca quindi di lavorare in un ambiente locale tale
da garantire che le azioni di multicast siano valide per quella rete.
Nella versione iniziale del protocollo, vi erano degli altri problemi di gestione,
dovuti al fatto che vi fosse un singolo router a dover gestire tutta l'infrastruttura
IGMP. Con la versione 2, un router può in realt` controllare più reti, perché
o
a
u
e
diventa possibile utilizzare anche più router. La versione 2 inoltre introduce un
u
messaggio di leave dal gruppo che mancava: prima era comunque tutto a carico
del router, che doveva inviare i messaggi query periodicamente e attendere le
risposte dai clienti.
\subsection{Realizzare il routing multicast}
Non esistono soluzioni standard per realizzare il routing multicast. Lo scenario
studiato ` quello di più utenti ma un unico trasmettitore. Si realizza quindi una
e
u
struttura ad albero dinamico (si possono inserire/togliere utenti/nodi):
$\bullet$ La radice ` il trasmettitore
e
$\bullet$ I clienti sono le foglie
$\bullet$ I nodi padre sono i router che rendono possibile il cammino.
La struttura ad albero ` eciente: evita infatti la presenza di cicli e maglie.
e
Tuttavia, la struttura dell'albero può inuenzare notevolmente l'ecienza delo
l'architettura.
Il primo passo ` quello di realizzare uno spanning tree per cui si manda
e
in ooding un messaggio per ogni destinatario, cos` che la radice riesca ad in\i{}
dividuare i cammini possibili, sfruttando i messaggi del protocollo unicast. Il
problema ` che questo protocollo ha un costo che cresce tantissimo all'aumentare
e
del numero dei partecipanti.
Il secondo passo riguarda quello della ricerca dei cammini condivisi, per cui
dei router possono essere sfruttati per realizzare un cammino più eciente (spanu
ning tree minimo). Si viene cos` a realizzare una bone o backbone multicast.
\i{}
15 L'alternativa ` peggiore: fare un ooding globale! Ma per mandare un messaggio a
e
tutti,i router dovrebbero avere uno stato, e vericare che il messaggio non l'abbiano gi`
a
ricevuto. . . quanto deve durare lo stato?
39
Inne, la radice raccoglie le informazioni ricevute per determinare lo spanning
tree minimo.
Una soluzione alternativa ` il Reverse Path Broadcast, ovvero ora l'iniziativa
e
` a carico dei clienti. Durante il normale routing, i clienti provano a mandare
e
un broadcast verso la radice, che può, in base a nuove informazioni, cercare
o
di ottimizzare/aggregare ulteriormente l'albero. Tale sistema presenta tuttavia
dei costi ulteriori che devono essere valutati; le tecnologie utilizzate sono infatti
le stesse per determinare un cammino minimo di Dijkstra, cio` o si sfrutta il
e
Distance Vector (si deve lavorare sfruttando anche le informazioni del prossimo
vicino per evitare cammini troppo lunghi) oppure Link State (tanti alberi quanti
i cammini minimi, poi si devono risolvere i tie break). Tuttavia, questo sistema
permette di ridurre il numero di messaggi scambiati e permette di poter definire
la banda necessaria.
In realt` la maggior parte dei sistemi sfrutta come protocollo il Reverse Path
a
Multicast per cercare di limitare (anche se di poco) il costo: resta comunque
tutto a carico della radice su come realizzare l'albero di routing.
Non esiste uno standard per queste tecnologie, ma diverse proposte: si hanno
dei problemi simili a quelli dell'invio della QoS con i servizi integrati di frame.
Infatti si lavora spesso con stati non permanenti(soft state dalla durata limitata:
gli intervalli sono un parametro critico della progettazione), alberi dinamici
in grado di fare riorganizzazioni locali. Le operazioni di base riguardano la
potatura (eliminazione di un router superuo) e il reinserimento o graft dinamico
(reinserimento di router). Si deve quindi spesso ricalcolare l'albero in caso di
variazioni! Le varie proposte sono:
$\bullet$ Distance Vector Multicast Routing Protocol : ` basato su una multicast
e
bone, si attraversano le reti utilizzando un sistema di tunneling. Il risultato
` che cos` si sfruttano solo alcuni nodi.
e
\i{}
$\bullet$ Multicast Open Shortest Path First: questo sistema invece si basa sull'altra tecnologia, e cerca di
ottimizzare l'albero gi` ottenuto determinato i
a
cammini minimi
$\bullet$ Core Based Trees: si mantengono costanti dei nodi, venendo a definire
quindi degli alberi sub-ottimi che non variano. In questo modo si limita il
costo della variazione dell'albero.
Il problema per` ` tutti questi protocolli sono incompatibili fra di loro: non
o e
possono essere attivati contemporaneamente, o se ne sceglie uno o l'altro!
\subsection{Semantica della comunicazione di gruppo}
Come realizzare la semantica della comunicazione di gruppo? Conviene fornire
delle conferme positive (i riceventi avvisano di aver ricevuto il messaggio) oppure
quelle negative (chi non ha ricevuto avvisa)? Si ritrasmette a tutti o solo a chi
non ha ricevuto il messaggio?
40
In generale l'obiettivo che si pressa ` che una send multicast dovrebbe
e
essere garantita come un'operazione atomica. Per risolvere il problema, conviene
suddividerlo in due sottoproblemi:
1. Garantire la fault tolerance: nessuno deve perdere dei messaggi! Le ritrasmissioni sono quindi un sistema da
prevedere se si vuole adabilit`.
a
Tuttavia, si potrebbe rimbalzare il problema a livello applicativo: per
esempio Chorus eettua multicast mai ripetuti, quindi unreliable, ma
specica agli sviluppatori di realizzare il sistema di ritrasmissione.
2. Fornire l'atomicit` della trasmissione: per atomicit` si intende l'ordine
a
a
con cui i messaggi giungono al gruppo. Si dovrebbe fare in modo infatti
che tutti i membri del gruppo li ricevano nello stesso ordine?Non ` detto
e
(solo letture si potrebbero fare in ordine diverso)! Pu` essere infatti che
o
a seconda dell'ordine dei messaggi si debbano attuare politiche diverse.
L'atomicit` ` lo studio di questo problema.
ae
Questi due aspetti devono essere tenuti separati : in questo caso quindi si ha
che l'atomicit` fa l'ipotesi che in ogni modo i messaggi giungano sempre a desa
tinazione. Nel progetto di una comunicazione di gruppo non ` quindi solo ime
portante la singola operazione, ma l'ordine con cui giungono al gruppo.
L'adabilit` viene a mancare se si perde un messaggio, oppure un crash
a
delle due parti. In particolare, per poter garantire l'adabilit` si deve fare in
a
modo che i gruppi siano dinamici : se una copia cade, in maniera trasparente
si deve proseguire. Per tutti i fault l'infrastruttura dovrebbe essere in grado di
reagire: ` ovvio quindi che serve un sistema di monitoring dell'infrastruttura,
e
per poter eettuare le possibili azioni correttive:
$\bullet$ Ritrasmissione di eventuali messaggi persi
$\bullet$ Aggiustamento del gruppo dinamico.
Ovviamente, si deve cercare di minimizzare i costi che si vengono aggiungere,
tenendo conto del principio di minima intrusione.
L'idea ` quindi quella di realizzare dei meccanismi molto semplici, in maniera
e
da poter garantire un controllo16 per poter eettuare la ritrasmissione. Si deve
quindi studiare come richiedere o meno la ritrasmissione: per esempio, se avessimo una conferma positiva per ogni frame
(si usa cos` un meccanismo di hold\i{}
back, trattenendo i messaggi nch` non arriva la conferma che il precedente `
e
e
stato ricevuto), il costo per il monitoring sarebbe elevato. Si riduce utilizzando
le conferme negative, dove si può indicare cosa si ` perso (si hanno dei messaggi
o
e
ordinati . . . ). Un altro problema riguarda l'intervallo di tempo per aspettare,
che deve essere opportunatamente dimensionato.
16 Da
non sottovalutare: e se fallisce il controllore? Chi controlla il controllore?
41
\subsection{Ordinamenti}
L'atomicità è l'aspetto in cui l'utente dovrebbe essere maggiormente coinvolto.

Infatti, non lavorando nel concentrato, certe ipotesi d'ordine che si potevano
fare non sono più valide in maniera gratuita! Come devono lavorare le copie?
u
Se potessero lavorare in maniera indipendente, per cui ogni copia può proo
cessare i messaggi nell'ordine in cui le arrivano, senza preoccuparsi dell'ordine
delle altre, si avrebbe un'infrastruttura a costo minimo. . . tuttavia ci` non `
o
e
sempre possibile.
L'ordinamento classico ` quello FIFO: l'ipotesi generale ` che si abbia seme
e
preun emettitore (si estende anche a casi con più emettitori, ma l'ordinamento
u
FIFO riferisce sempre i messaggi provenienti dallo stesso emettitore). Questo
ordinamento stabilisce che se vengono inviati i messaggi in ordine m1, m2, tutte
le copie devono ricevere i messaggi nello stesso ordine! Nel caso di più emetu
titori, infatti, l'importante ` che i messaggi provenienti dallo stesso emettitore
e
siano sempre nello stesso ordine, ma fra emettitori diversi no; se un emettitore
emette m1, m2 e un altro m3, m4
$\bullet$ m1, m2, m3, m4, m1, m3, m2, m4, m3, m1, m4, m2,. . . vanno bene
$\bullet$ m2, m1, m3, m4 no!
Le copie devono quindi essere progettate in maniera tale da mantenere lo stato,
ovvero da chi arriva la comunicazione? Se vi sono omissioni, si può cos` attivare
o
\i{}
un procedimento di hold-back.
Tuttavia, l'ordinamento FIFO non ` sempre quello desiderato, proprio perché
e
e
non si possono imporre vincoli di precedenza fra messaggi provenienti da emettitori diversi. Basti pensare ai newsgroup:
spesso succede che arrivi prima
la risposta della domanda, perché non sono presenti degli orologi sincronizzae
ti. Questo succede perché a livello di supporto non si garantisce il rapporto di
e
causa-eetto
L'ordinamento causale tiene conto di questo problema, si basa proprio sulla
presenza di emettitori diversi, che possono inviare messaggi in relazione di causaeetto fra di loro. Questo vuol dire
che se un messaggo m1 ` causa di un
e
messaggio m3 da parte di un altro emettitore, la comunicazione sar` valida se
a
e solo se m1 preceder` m3 sempre (per altri messaggi non ` stabilito l'ordine).
a
e
Il problema del causale ` che ` di dicile realizzazione: non vi sono supporti
e
e
che lo realizzano. Nel caso di un singolo mittente, il causale ` praticamente un
e
FIFO, ed ` di semplice realizzazione. Ma se si hanno gruppi dinamici, e quindi
e
dipendenze dinamiche fra i messaggi, non ` banale!
e
Inoltre, non tutto a questo mondo si può rappresentare con il rapporto di
o
causa-eetto: per esempio, se si avessero due multicast che sono rispettivamente
un accredito e una valutazione degli interessi, l'ordine ` fondamentale. . . ma le
e
due operazioni non dipendono l'una dall'altra! Resta che l'ordinamento su tutte
le copie deve essere il medesimo, altrimenti si avrebbero dei conti sballati!
42
Questo problema non si risolve neanche con il FIFO perché, come il causale,
e
si tratta di un ordinamento parziale. Si può pensare invece di risolverlo utilizo
zando un ordinamento atomico, che ` globale. Questo perché ` un ordinamento
e
ee
deciso dal gruppo! Il gruppo può decidere una famiglia di ordinamenti che tutte
o
le copie devono rispettare, fornendo cos` anche implementazioni diverse. L'or\i{}
dinamento atomico non ` interessato infatti all'ordine specico, ma al fatto che
e
tutti i componenti del gruppo ricevano i messaggi nello stesso ordine. L'ordinamento atomico può essere realizzato in
maniera da rispettare sia (o uno solo, o
o
nessuno) l'ordinamento FIFO che quello causale.
Per poter realizzare l'ordinamento atomico, si deve pensare comunque alla
presenza di un frontend, in grado di smistare alle varie copie i messaggi che
arrivano: ogni copia lavora in maniera indipendente, cos` che se manca un mes\i{}
saggio ad una le altre non sono bloccate. Questo vuol dire che non sono sincrone
fra di loro, ma l'obiettivo ` solo il raggiungimento di uno stato nale coeso. Il
e
coordinamento quindi può non rispettare il FIFO, ed ` tutto interno al gruppo.
o
e
L'ordinamento ` un costo aggiuntivo che si deve considerare, tuttavia i divere
si ordinamenti hanno un costo diverso. In particolare, il causale ` l'ordinamento
e
maggiormente costoso in generale, anche se non vi ` una risposta univoca, dipene
dendo da caso a caso. Tuttavia, l'atomico vista la sua variabilit` può presentare
a o
dei costi molto diversi.
In tutte le architetture per il multicast basato su ordinamento atomico in
generale si pensa ad un frontend che possa smistare i messaggi secondo l'ordinamento imposto: tuttavia, per garantire
adabilit`, si deve considerare anche il
a
caso che il frontend non sia disponibile. Si deve trovare un modo di aggiungere
qualit` (per esempio, replicazione dei frontend, con token per chi ` eettivaa
e
mente attivo. . . ). Esistono altre architetture meno centralizzate, ma risultano
essere maggiormente complesse.
Inoltre, l'ordinamento atomico basato su frontend può essere unfair: clienti
o
più vicini al front end sono favoriti. Altre soluzioni si sono preoccupate di suu
perare questo problema, introducendo per` ulteriori costi.
o
\subsection{Il problema della sincronizzazione}
Per poter coordinare un insieme di copie, ` necessario quindi che queste siano
e
sincronizzate. La sincronizzazione non ` nient'altro che la sequenzializzazione
e
di operazioni parallele 17 , mediante la quale si impongono degli invarianti che
devono essere rispettati : si ha quindi un ordine.
Tuttavia, la sincronizzazione ` diversa dalla comunicazione: questa infatti
e
` interessata ad un contenuto da trasmettere, mentre la sincronizzazione ` solo
e
e
l'ordine. Nelle classiche architetture C/S i due aspetti sono accoppiati, ma ci`
o
non vale in altri casi.
17 Esempio,
realizzazione della mutua esclusione
43
Per poter sincronizzare non ` necessario stabilire un ordinamento prescritto:
e
si può scegliere quello più adatto a seconda delle esigenze, in maniera anche
o
u
molto indeterministica. In questo modo si hanno spazi di implementazione
molto variabili. In generale, essendo la sincronizzazione nel distribuito molto
più costosa, si cerca di fornire un ordine solo per gli eventi necessari.
u
Nel distribuito, i clock non sono sincronizzati. Si potrebbe pensare di realizzare un unico clock per tutti, ma `
impensabile (si pensi a derive nella
e
comunicazione del tempo). Esistono standard per stabilire un formato univoco per il tempo (UTC, Universal Coordinated
Time), ma che funzionano solo
se il numero dei partecipanti ` limitato. Per coordinarsi infatti i diversi client
e
chiedono e ricevono il clock mediante uno scambio di messaggi, e quindi si cerca
di ottenere una mediazione, aggiustando di volta in volta il clock locale. Ma per
far ci` serve un gestore continuo che faccia monitoring!
o
Esiste anche un protocollo, Network Time Protocol, denito per il distribuito,
in grado di basarsi su UTC per fornire un tempo comune a tutti i partecipanti.
Si realizza una gerarchia di server, che coinvolge tutti i partecipanti: più si `
u e
vicini alla radice, maggiormente il tempo sar` preciso. Allontanandosi invece si
a
hanno delle derive. Ma se si guasta un server?
Questi protocolli son troppo complessi e costosi per garantire un tempo univoco. Il rischio ` sempre che un evento venga
etichettato male, per via di derive
e
nel clock locale rispetto a quello globale. L'idea ` quindi quella di lasciar perdere
e
il tempo sico, il clock, ma di realizzare una sincronizzazione solo sugli eventi
`
d'interesse. E una prospettiva più ottimista e molto meno costosa (infatti si
u
riduce la comunicazione solo agli eventi signicativi, evitando di dover tenere
aggiornati gli orologi sici).
Vi sono diversi sistemi per poter ordinare in base agli eventi di interesse.
Quello meno importante ` quello basato su delle priorit` denite in maniera
e
a
statica. Infatti cos` si viene a realizzare una politica molto rigida, con rischio
\i{}
di starvation (andrebbe bene se l'architettura prevede dei processi che debbano
eseguire a scapito di altri).
I metodi più interessanti sono invece:
u
$\bullet$ basati sull'ordinamento di Lamport, utilizzato soprattutto in US. Si realizzano dei clock logici da usare al
posto dei clock sici.
$\bullet$ basati sull'uso del sistema di token passing, utilizzato soprattutto in UE.
Si realizza una struttura ad anello, e chi ha il token ` il coordinatore.
e
\subsection{Ordinamento di Lamport}
L'ordinamento di Lamport si basa di avere diversi processi in grado di mantenere
una propria storia interna (gli eventi su uno stesso processore sono gi` ordinati
a
grazie alla storia), e in grado di comunicare fra di loro, in maniera punto a
punto con dei messaggi (non si usano multicast, non si possono mandare batch
44
di messaggi !). L'idea ` che il numero degli eventi interessanti ` sicuramente
e
e
inferiore al clock sico, e quindi si possono usare per ordinare.
L'ordinamento di Lamport si basa sulla relazione happened-before, per poter
ordinare gli eventi, imponendo prima di tutto un ordine locale. Si ha quindi che
se l'evento a precede l'evento b sullo stesso processore, si ha che:
a$\rightarrow$b
(18)
Ovviamente questa relazione vale anche per la comunicazione fra più processi,
u
nel senso: se a ` l'evento di invio di un messaggio, e b la sua ricezione da un altro
e
processore, chiaramente sono in relazione di precedenza! Ovviamente, questa
relazione presenta anche la propriet` della transitivit`.
a
a
Tuttavia, questo ordinamento non ` globale. Basta pensare a due processi che
e
comunicano con gli eventi a e b, ed entrambi presentano un evento che li precede
localmente, k e q rispettivamente. Non esiste un ordinamento fra questi due
eventi, per cui si stabilisce un'altra relazione, ovvero quella sulla concorrenza;
due eventi k e q son concorrenti se non si può imporre una relazione di happened
o
before fra di loro:
k $\uparrow$$\uparrow$ q =!(k $\rightarrow$ q)$\land$!(q $\rightarrow$ k)
(19)
In questo genere di relazione si può osservare che il ricevente ha sicuramente più
o
u
vincoli rispetto al mittente, trattandosi di una relazione fortemente orientata.
In questo modo si hanno diversi orologi locali, ma non ancora un unico orologio globale. In particolare, se si trattasse
di un mondo asincrono, non si avrebbe
nessuna ipotesi sulla sincronicit` fra i processi (i tempi di invio potrebbero esa
sere molto lunghi, maggiori di qualunque tempo osservabile). Si deve quindi
trovare un modo per definire un orologio globale.
L'idea ` che se a $\rightarrow$ b, allora si ha che il tempo dell'evento a ` minore del
e
e
tempo dell'evento b:
a $\rightarrow$ b $\Rightarrow$ T S(a) $<$ T S(b)
(20)
Questa ` la condizione di clock logico, il quale può solo crescere. Si tratta di
e
o
realizzare quindi una sorta di timestamp, per identicare in maniera univoca gli
eventi nel sistema!
Nel caso di una trasmissione, per cui a $\in$ Pi e b $\in$ Pj , si denisce la relazione
di clock logico:
a $\rightarrow$ b $\Rightarrow$ LCi (a) $<$ LCi (b)
(21)
Ogni processo incrementa il valore del clock logico fra due eventi, tuttavia
l'aggiornamento del processo ricevente deve tener conto anche del timestamp
ricevuto insieme al messaggio per aggiornare correttamente l'orologio:
LCj = max(T Sricevuto , LCilocale ) + 1
(22)
Resta per` il problema della relazione di concorrenza, per cui la relazione `
o
e
ancora un ordine parziale! Per ovviare a questo problema, si deve estendere la
relazione di happend before:
Se a $\in$ Pi e b $\in$ Pj , si ha che a $\Rightarrow$ b se e solo se:
45
1. LCi (a) $<$ LCj (b) oppure
2. LCi (a) = LCj (b) e Pi $<$ Pj
Ovvero, fondamentalmente si impone un ordine fra i processori stessi! Bisogna
quindi considerare il problema dei sistemi dinamici, in cui il numero dei processori può variare dinamicamente. Servono
quindi degli appositi gestori per gli
o
indici.
La relazione di Lamport in genere tende ad aggiornare solo processi che
ricevono messaggi da altri processi : chi li produce soltanto può avere anche dei
o
timestamp molto bassi. Se tutti comunicano fra di loro (entrambe le direzioni),
allora tutti i processi saranno sincronizzati in maniera univoca. Esistono per`
o
dei casi in cui la relazione di Lamport potrebbe avere dei problemi:
$\bullet$ Problema del canale nascosto: se ci fossero dei processi che usano dei
canali preferenziali non noti, non si potrebbe sincronizzare correttamente
(ma ` un problema progettuale non reale!)
e
$\bullet$ Problema della causalit` vera: la relazione di Lamport ` anche biettiva,
a
e
cio` ` valido anche la relazione opposta? In realt` no, due eventi che
e e
a
soddisfano la relazione di Lamport potrebbero non essere in rapporto di
causa ed eetto!
Un sistema per realizzare l'architettura basata su Lamport ` quella basata sui
e
clock vettoriali : ogni processo tiene conto in realt` anche dei clock logici degli
a
altri processori. In questo modo per` si hanno strutture dati e protocolli più
o
u
complessi! Tale sistema infatti non ` scalabile:
e
1. L'emettitore di un messaggio invia il proprio vector clock, aggiornandolo.18
2. Il ricevitore ottiene il vector clock, lo confronta con il proprio clock locale
e quindi aggiorna quest'ultimo.
Il vector clock garantisce di poter propagare le informazioni e di fornire una
garanzia sul fatto che siano state propagate. Tuttavia, a dierenza dei normali
clock logici, non si ha una relazione d'ordine globale! Si potrebbe complicare
ulteriormente realizzando delle matrici di clock.
La relazione di Lamport si può usare per sincronizzare, per esempio, l'accesso
o
ad una risorsa condivisa. Permette di garantire delle caratteristiche fondamentali che sono:
$\bullet$ Correttezza (un solo processo accede alla volta)
$\bullet$ Liveness (Vi ` un tempo limitato per accedere alla risorsa)
e
$\bullet$ Fairness (Non vi possono essere processi che rischiano starvation).19
18 Non
19 Un
si incrementa in realt` sempre, per il rischio di giungere velocemente ad overow
a
sistema basato su priorit` non garantisce liveness e fairness
a
46
Si può realizzare un sistema per accesso alle risorse che rispetti questi invario
anti creando un processo gestore20 , in grado di lavorare FIFO, e sfruttando un
protocollo di tipo {`}request-reply-release'. L'idea ` quella di soddisfare prima le
e
richieste arrivate per prime. Il gestore concede l'uso solo al processo con cui
risponde con reply, il quale lo avviser` con il release una volta terminata l'esea
cuzione. Il gestore potr` quindi fornire la risorsa al prossimo processo. Si ha un
a
totale di 3 messaggi per ogni accesso alla risorsa.
Per realizzare questo sistema invece con Lamport e senza uso di un gestore
centrale, si deve supporre:
1. Che tutti i processi siano in grado di comunicare l'uno con l'altro. Se
quindi vi sono n processi, vi devono essere almeno
n · (n $-$ 1)
2
(23)
canali per poter comunicare.
2. Supposizione per la qualit`: i canali sono FIFO, e non perdono messaggi.
a
3. Ogni processo gestisce una propria coda per i messaggi. La sincronizzazione si basa propria sulla coda locale ad ogni
processo.
4. Il primo messaggio che ogni processo contiene ` quello sull'indicazione
e
locale del tempo, T0 : P0 , che corrisponde ad un tempo sempre inferiore
a quello che si potr` mai trasmettere.
a
Il protocollo si basa sempre sull'idea di scambiare dei messaggi, e chi riceve tutti
gli assensi può accedere alla risorsa:
o
1. Un processo che vuole accedre alla risorsa invia a tutti gli altri processi un
messaggio con l'indicazione del proprio tempo e di chi si tratta: Tm : Pi .
2. Gli altri processi ricevono il messaggio, e devono mandare tutti un assenso:
sono quindi n $-$ 1 messaggi.
3. Il processo richiedente può accedere alla risorsa solo se ha ricevuto tutti
o
gli assensi, ma anche se nella sua coda non vi ` una richiesta superiore
e
alla propria (in base alla relazione di Lamport)!
4. Una volta che un processo ha nito di lavorare sulla risorsa, elimina dalla
propria coda ilsuo messaggio, e invia a tutti gli altri n $-$ 1 avvisi, in modo
che anche loro possano cancellare la richiesta completata.
Si ha quindi che la coda deve essere mantenuta ordinata secondo timestamp!
L'attesa che si ha per avere le risposte ` proprio il sistema con cui si garantisce
e
la fairness: i messaggi infatti possono essere ritardati, ma comunque arrivano;
20 Soliti problemi per la QoS: se cade il gestore? Essendo un processo, avrà dei processi che
a
favorisce o meno in base alla vicinaza relativa. . .
47
se un altro processo aveva richiesto la risorsa prima ma il messaggio ` in ritardo
e
su alcuni processi, verr` comunque servito prima.
a
Tale sistema per` ` molto costoso: richiede per ogni sincronizzazione 3(n$-$1)
oe
messaggi, e richiede garanzie sull'aaidabilit` del sistema (se un nodo ` guasa
e
to e non risponde mai?) e che il gruppo sia statico. Per ottimizzarlo, ci
dovrebbe pensare l'infrastruttura, magari sfruttando in maniera opportuna il
broadcast/multicast per eseguire una richiesta!
A dierenza del protocollo centralizzato, se le copie sono studiate correttamente (con una giusta replicazione), la
responsabilit` risulta essere ben disa
tribuita, e non si dipende più da un unico gestore centralizzato. Tuttavia, si
u
deve tener conto dei guasti, su come escludere/ripristinare le copie e cos` via. . .
\i{}
Un protocollo più eciente ma sempre basato su Lamport ` quello di Ricart
u
e
e Agrawal: l'idea ` quella di limitare il numero dei messaggi in circolo, aggiune
gendo intelligenza ai processi. Infatti, adesso il reply viene fatto o da processi
meno prioritari o che non hanno interesse alla risorsa. In questo modo, in realt`,
a
solo un processo ricever` gli n $-$ 1 reply. Il rilascio costa uguale, ma il protocollo
a
in tot viene a costare 2(n $-$ 1) messaggi per accesso alla risorsa. Il reply ` invece
e
ritardato nel caso che il processo che riceve la request sia proprio quello che la
sta usando.
`
Il problema in ci` ` come si fa a definire il ritardo? E un'idea scivolosa/rischiosa,
oe
per cui si mescolano ai meccanismi di un protocollo meccanismi di supporto!
Come si fa a stabilireil ritardo, ` dovuto a congestione o all'applicazione? Per
e
quanto quindi questo sistema usi meno messaggi, ` applicato ancora meno.
e
Vi sono esempi di implementazioni:
$\bullet$ CATOCS,Causal Totally Ordered Comunication Operation Support: `
e
un sistema scalabile, mantenedo limitato il numero dei partecipanti. Si
mantengono infatti continuamente dei gestori coordinati fra di loro, in
grado di servire le richieste, si utilizza broadcast in casi specici.
$\bullet$ ISIS: ` un sistema totalmente basato su gruppi e risorse di gruppo, per cui
e
si necessita di coordinarsi fra le varie copie attive dotate di replicazione.
Prevede l'utilizzo di diverse forme di multicast, distinte a seconda del tipo
di ordinamento. Di base si hanno infatti le multicast per i 3 ordinamenti
specicati (FIFO, causal e atomic), ma inoltre ` presente una particolare
e
multicast, che serve proprio per la gestione del gruppo stesso. Utilizzando
questa multicast, infatti, un gruppo può cambiare la propria granularit`,
o
a
eliminando copie non attive o reintroducendo quelle che hanno subito recovery. Caratteristica fondamentale ` che il
messaggio di gestione venga
e
ricevuto solo dopo che tutti gli altri messaggi, dovuti agli altri tipi di multicast, siano stati ricevuti da ogni
membro del gruppo. Riesce a fornire
un sistema di monitoring (basandosi anche su delle tabelle che vengono
aggiornate da questi multicast).
L'atomic multicast di ISIS in particolare utilizza Lamport e le code locali
ai processi per poter decidere con una politica di gruppo l'ordine dei mes-
48
saggi. Ogni messaggio ricevuto quindi da una copia deve essere spedito a
tutte le altre copie, con un'indicazione di timestamp. Ogni copia lo marca con il proprio timestamp, e lo rispedisce
indietro al primo mittente, il
quale lo marca denitivamente con il timestamp maggiore e lo rispedisce
a tutti gli altri (costo di Lamport).
Il causal multicast aggiunge un costo visto che la dipendenza di relazione
` al di fuori del gruppo: si tratta di un ordine parziale, per` richiede che
e
o
comunque vi sia un coordinamento fra i clock logici dei mittenti, per poi
far arrivare l'informazione in maniera corretta anche ai riceventi.
\subsection{Sincronizzazione a token}
Si tratta di un altro modello per superare il problema del gestore centralizzato. L'idea ` quella di avere un anello
totalmente ideale, per cui i processi si
e
conoscano solo in maniera limitata (prossimo ed antecedente). I vari processi
si passano un unico, sempre presente token, che stabilisce la sincronizzazione
(chi ce l'ha ` il gestore dinamico della risorsa, ovvero vi può accedere se ne
e
o
ha bisogno). Si tratta di una soluzione molto pro attiva, poich` il token gira
e
lungo l'anello anche senza la presenza di richieste di sincronizzazione. Rispetto
a Lamport il costo ` inferiore, n $-$ 1 messaggi sempre.
e
In questo sistema si deve per` pensare anche all'adabilit` del token: se
o
a
non arriva? Si dovr` rigenerarlo, facendo in modo per` che vi sia sempre e solo
a
o
un unico token in giro per l'anello. Si hanno quindi delle situazioni di elezione,
per cui più partecipanti vorrebbero eseguire l'azione di recovery, ma deve essere
u
sempre uno solo! L'idea alla base ` che vi sia un time-out per cui scaduto, un
e
processo può leggittimamente pensare che il nodo che aveva il token sia guasto.
o
Questo processo allora crea un token d'elezione, che deve essere approvato da
tutti i nodi perché diventi il nuovo token dell'anello. Questo signica che per`
e
o
ogni nodo deve avere una conoscenza migliore dell'anello (per esempio, non solo
il prossimo ma anche il nodo ancora successivo, e cos` via). Se il token d'elezione
\i{}
giunge quindi di nuovo a chi lo ha generato, diviene il nuovo token21 . Visto che
più processi possono mandare il token d'elezione, si ha che si decide in maniera
u
statica quale ` il più prioritario, numerando i processi.
e
u
Un protocollo di elezione molto semplice da fare ed eciente ` Bully: l'idea
e
` che un processo di priorit` superiore zittisca le richieste di processi inferiori,
e
a
per divenire lui il gestore. Si ha quindi che un processo di basso livello manda
verso l'alto un messaggio d'elezione. Se un processo di priorit` superiore può
a
o
assumere il compito di gestore, manda un Answer verso il basso, e propaga verso
l'alto la sua elezione. Se non riceve nessun Answer entro un certo tempo, assume
di essere diventato il gestore. Questo protocollo rischi di presentare molte fasi
in base alla disponibilit` relativa dei processi, ma in realt` si risolve abbastanza
a
a
velocemente. I protocolli di elezione sono strutture tipiche delle infrastrutture
dove le entit` possono cambiare ruolo.
a
21 Se
si fosse ripresentato il vecchio token, quello d'elezione sarebbe stato eliminato
49
\subsection{Snapshot distribuiti}
Come si denisce uno stato nel distribuito? Si vuole uno stato globale, ma
non ` sempre possibile salvarsi tutta la memoria sul disco, specialmente con
e
un'alta replicazione. L'idea ` quindi quella di realizzare un sistema in cui i
e
processi si scambino dei messaggi, mediante dei canali fortemente orientati, per
poter salvare in maniera opportuna delle foto del sistema. Si tratta quindi di
eettuare dei tagli, in maniera tale da determinare gli stati signicativi e quelli
no, per poter inglobare i primi per poter formare uno snapshot globale! Lo stato
infatti ` la composizione dei singoli stati di ogni processo.
e
Come si decide quali tagli vanno bene e quali no? I tagli realizzano degli
snapshot numerati (ovvero sono ordinati), per cui un taglio che faccia in modo
che un messaggio che inzia nello snapshot x e termini nello snapshot x + 1 deve
essere salvato per poter mantenere il sistema consistente, mentre l'opposto non
va bene! Non garantirebbe la consistenza (come si fa a capire nello stato x chi
`
` il sender del messaggio? E noto solo nello stato successivo!)
e
Ogni nodo ` tenuto a salvare il proprio stato locale, cos` da avere inizialmente
e
\i{}
almeno consistenza locale. Questa ` la base per fare uno snapshot globale dise
tribuito. L'idea ` che si utilizzi un protocollo che indichi quando fare la foto
e
locale e quando terminarla. Si sfrutta un apposito messaggio, detto marker, per
cui ogni nodo può presentare due stati:
o
$\bullet$ bianco per indicare lo stato iniziale, prima dello snapshot.
$\bullet$ rosso per indicare lo stato successivo.
Una transizione dal bianco al rosso `una richiesta sul nodo perché esegua uno
e
e
snapshot, e come una catena ordina anche agli altri nodi di eseguire uno snapshot: l'idea ` quindi che ognuno salvi il
proprio stato e poi rimandi il marker.
e
L'idea ` quindi che un nodo o riceve un marker rosso o diventa rosso per
e
fare lo snapshot: salva lo stato, e poi invia il marker su tutti i suoi canali
d'uscita. Continua a salvare i messaggi che riceve e a restare rosso no a quando
non riceve su tutti i suoi canali di input il marker rosso (ovvero le risposte
dagli altri nodi!). A tale evento, si ferma e salva lo snapshot. Si potrebbe
anche sviluppare protocolli più complessi, per cui il marker viene inviato solo
u
su determinati canali. Da osservare che quindi un processo in stato rosso non
potr` mai mandare un messaggio a un processo in stato bianco, altrimenti non
a
si salva correttamente!
Ma no a quando si salva? Fino al prossimo marker! Questo ` un sistema
e
assolutamente scalabile! Il problema ` che il marker tiene un'indicazione del
e
nodo che ha iniziato lo snapshot, per cui se si volesse che 2 nodi distinti facessero
lo snapshot, si dovrebbe estendere la politica, magari estendendo in maniera
semplice le informazioni del marker, che indichi a quale snapshot ` riferito quello
e
`
stato. A chi si manda poi lo stato in ogni modo? E una politica da decidere, o
a un nodo che fa da repository oppure a chi ha iniziato lo snapshot. . .
50

\section{Qualità di servizio e nuovi protocolli per Internet}
Esistono diversi indicatori con cui poter valutare la QoS:
26
$\bullet$ Prontezza di risposta: viene indicata dal tempo di risposta, il jitter, o il
ritardo. Nel caso vi siano più servizi correlati fra di loro, la qualit` viene
u
a
associata a più operazioni.
u
$\bullet$ La banda, cio` quanti bit/byte al secondo si riescono a trasmettere (dati
e
trasmessi con successo)
$\bullet$ L'adabilit` del sistema
a
$\bullet$ Lo throughput, ovvero il numero di servizi che si riescono ad erogare
nell'unit` di tempo.
a
Tuttavia, questi non sono gli unici indicatori, e probabilmente non sono neanche
quelli più interessanti per un utente che volesse pagare per un servizio. Vi sono
u
infatti degli altri parametri più qualitativi da considerare, perché requisiti dalu
e
l'utente (come la qualit` dell'immagine, sincronizzazione audio/video,. . . ): sono
a
requisiti non funzionali, legati alla tipologia di servizio! Per poter quindi servire
un cliente, si deve anche poter interagire con lui, per avere un'idea di quale
qualit` gli possa interessare: ci` per` ` contro la trasparenza! La negoziazione
a
o
oe
e l'accordo controllato con il cliente fanno in modo che i servizi moderni non
risultino trasparenti, proprio perché l'utente può (e spesso deve) specicare delle
e
o
preferenze! Il sistema deve essere dinamico, in grado di reagire all'evoluzione
delle richieste, in maniera da mantenere la QoS concordata: deve apportare
delle azioni correttive durante l'esecuzione! In generale, i parametri che un
utente ritiene fondamentali sono:
$\bullet$ Importanza
$\bullet$ La QoS percepita, che dipende dalla tipologia del servizio
$\bullet$ Il costo da dover sopportare
$\bullet$ La garanzia di avere degli adeguati supporti per la sicurezza (non ripudio
del servizio, autenticazione, . . . )
\subsection{Calcolare la QoS}
Oltre alla quantit` di dati trasmessi con successo (la banda), un altro parametro
a
fondamentale da tener da conto ` il tempo di latenza: questo consiste nella
e
quantit` di tempo necessaria per trasmettere un'unit` di informazione. Questo
a
a
dipende da tre contributi:
TL = Tpropagazione segnale + Ttrasmissione + Tritardo
(14)
Il tempo di trasmissione dipende dalla dimensione del messaggio e dalla banda
disponibile, mentre il tempo di ritardo dipende dai tempi di accodamento che
si vengono a vericare. In particolare, ` quest'ultimo a tener da conto gli overe
head presenti nel sistema (spesso ` alto, e lo si può ridurre realizzando un buon
e
o
27
protocollo).
La qualit` di servizio dipende da come si riescono a risolvere i colli di bottiglia
a
dell'applicazione, cio` su cosa ` orientata (trasmettere tanti dati di dimensioni
e
e
molto limitate? Prevale il tempo di latenza. trasmettere diversi dati di di`
mensioni elevate? E necessaria una banda suciente). Spesso, si utilizza come
ulteriore indicatore il prodotto fra la latenza e la banda: riesce infatti a dare
un'idea del ritardo fra mittente e ricevente, e di quante informazioni sono state
inviate nel frattempo. Si rappresenta cos` il numero eettivo di bit trasmessi,
\i{}
perché non sar` mai uguale alla banda essendo presente proprio il tempo di
e
a
latenza! Su questi indicatori, una prima possibile strategia molto semplice `
e
quella di occupare sempre al massimo le pipe (e quindi la banda), per poter
garantire i tempi di risposta concordati: tuttavia, si deve tener conto anche
del tempo di latenza nel far ci`. . . Spesso quindi si incorpora un tempo per il
o
buering delle applicazioni.
Un altro parametro ` il jitter, ovvero la variazione della latenza che si presene
ta in un usso: infatti, non ` in realt` costante (sarebbe la situazione ideale. . . ).
e
a
Basti pensare per esempio che nella maggior parte delle comunicazioni vi sono
degli intermediari a supporto: a seconda del carico di lavoro presente su di loro,
`
il tempo di latenza può variare notevolmente! E quindi necessario pensare anche
o
a una QoS distribuita fra i vari nodi !
Lo skew rappresentalo sfasamento fra due ussi, che dovrebbero essere invece
percepiti come una singola entit` dall'utente nale (per esempio, discrepanze
a
nella velocit` fra audio e video).
a
Spesso, in realt`, la QoS ` un parametro che ` trascurato in fase progeta
e
e
tuale, nonostante sia un obiettivo. Questo perché durante lo sviluppo si hanno
e
situazioni con traco molto limitato. Ci` per` non ` vero per tutti i servizi
o
o
e
(ad esempio, video streaming o qualunque altro usso di informazioni continuative): la QoS ` fondamentale proprio per
poter erogare il servizio, per cui i
e
problemi della banda e della latenza son fondamentali. Per garantire la QoS, le
entit` devono eettuare una negoziazione per decidere certi parametri (il ritara
do inziale per assorbire il jitter medio, il massimo ritardo accettabile per non
dover scartare un pacchetto. . . ). Per esempio, una prima idea per ottimizzare
la trasmissione ` quella di introdurre delle risorse sul client, e di buerizzarla:
e
si trasmette quindi soltanto avendo un certo numero di frame a disposizione.
\subsection{QoS in Internet}
Il mondo di Internet si basa sul protocollo TCP/IP, che lavora best eort: ci`
o
signica che non può garantire QoS 6 . OSI ` da sempre stato progettato con
o
e
6 Perch` ci`? Internet non prenota o mantiene le risorse, ma cerca di determinare un
e o
cammino fra C/S che quindi può variare. Non abbiamo garanzia del servizio. OSI invece
o
denisce la possibilità di definire gli intermediati e riservarli, in maniera da distribuire la
a
latenza totale del servizio su di loro, e in maniera da progettare i nodi intermedi con le risorse
28
l'idea di supportare QoS, ma risulta essere ancora lontana da essere realmente
implementata. Si tratta quindi di individuare tecniche per garantire QoS in Internet. Le idee principali riguardano
l'introduzione di nuovi protocolli e nuove
applicazioni
Le applicazioni classiche di Internet (tipo mail) sono elastiche, ovvero sono
in grado di adattarsi alla congurazione della rete, e non richiedono QoS al
supporto (possono tuttavia specicare un tempo di latenza per poter eseguire).
In queste applicazioni quindi l'utente non specica dei tempi rigidi per poter
eseguire.
Le applicazioni moderne invece sono non elastiche: questo perché presentano
e
dei vincoli temporali precisi, e quindi richiedono QoS. Di queste, quelle real-time
moderne sono tolleranti rispetto a problemi che si possono vericare, ovvero
possiamo avere che sono:
$\bullet$ Adattative in banda: il servizio ` erogabile ma con una banda minore, e
e
quindi qualit` diminuita: si parla per esempio di un video peggiore.
a
$\bullet$ Adattative per la latenza: il servizio ` erogabile, ma con un ritardo mage
giore, riducendo la QoS: uno streaming audio che perde pacchetti, un video
che perde dei frame.7
Bisogna ricordare che in generale la latenza non ` costante: potrebbe essere
e
conveniente quindi specicare la latenza su ogni frame.
Un servizio per Internet potrebbe quindi richiedere garanzie diverse:
$\bullet$ Il classico best-eort
$\bullet$ Un controlled load, ovvero la gestione di una latenza limitata. Spesso
questa ` la scelta per i servizi elastici, trattandosi di una via di mezzo fra
e
il best-eort e la garanzia di determinati valori.
$\bullet$ Il guaranteed load, per cui si ha un limite temporale stretto al ritardo, ma
non limitato al jitter.
Per poter fornire servizi che si basino sulle ultime due opzioni, ` necessario
e
far evolvere Internet da un sistema best-eort (dovuto all'uso di IP) elastico
(grazie a TCP) ad un sistema con QoS. Si parla quindi di una transizione da
una struttura a basso costo e senza garanzie ad una con costi dierenziati a
seconda delle prestazioni da erogare. Vi sono due proposte, incompatibili fra di
loro:
$\bullet$ Servizi integrati, RFC 2210: si ragiona per singolo servizio, e quindi si
cerca di definire per ogni singolo usso la QoS
necessarie per soddisfare la banda
7 Questo non si può fare con TCP,perché garantisce che si ricevano sempre i frame in ordine:
o
e
trasparente, ma non va bene se abbiamo un alto jitter!
29
$\bullet$ Servizi dierenziati, RFC 2475: si propone di introdurre QoS a livello di
rete, quindi la proposta ` quella di lavorare contemporaneamente su più
e
u
ussi per migliorare in maniera globale il routing.
\subsection{Gestire la QoS}
Come gestire quindi la QoS? Il controllo della qualit` dovrebbe essere fatto dua
rante l'esecuzione, e in generale abbiamo una fase iniziale (prima dell'erogazione,
azioni preventive o statiche), una fase durante il deployment (azioni reattive o
dinamiche). Tuttavia, in Internet non vi ` n` la fase iniziale (detta anche proe e
visioning), e non vi ` soprattutto il controllo della qualit` durante l'esecuzione
e
a
(come controllare i diversi intermediari??), e soprattutto non esistono protocolli
standard! Va valutato caso per caso come strutturare la gestione della QoS.
Nella parte statica quindi client e server si devono mettere d'accordo prima
di erogare il servizio: ` la fase di negoziazione della QoS. Questa fase cone
siste nel definire un Service Level Agreement fra le varie parti, che dovr` essere
a
descritto in una maniera opportuna, e quindi nel definire/riservare le risorse necessarie. La fase che precede
l'erogazione ` senza costo, perché non vi ` ancora
e
e
e
il monitoring ma solo la predisposizione del servizio.
La fase dinamica invece ` caratterizzata dal monitoring dell'erogazione del
e
servizio, che ` strettamente necessario per poter magari fare una rinegoziazione
e
nel caso sia necessaria (introduzione di nuovi intermediari, presenza di nodi
guasti, . . . ) per poter mantenere la QoS stabilitae garantire che ci` avvenga:
o
questa ` la condizione necessaria perché un servizio venga retribuito. Questa `
e
e
e
la fase più costosa, perché i vari nodi si devono adattare alle situazioni che si
u
e
vengono a vericare, oppure devono essere estromessi se non adatti. L'idea `
e
quella di basarsi il più possibile sulla localit` : più le azioni sono locali, senza
u
a
u
dover far intervenire un agente esterno, un fruitore, minore ` il costo; anche per
e
questa fase si deve cercare di progettare dei protocolli ottimizzati che costino
poco, sfruttando il principio della minima intrusione quindi ! Politiche poco
costose quindi, e limitare l'uso delle risorse necessarie al monitoring! In un
ipotetico sistema quindi il piano utente (quello della gestione del servizio) e
quello del management sono accoppiati, ma dovrebbero essere strutturati in
maniera tale da condividere il minor numero di risorse. Il problema di Internet
` che siamo sempre in piano utente, e quindi ` dicile capire se ci sono problemi.
e
e
Il piano del management in realt` può essere scomposto in diverse sottoparti,
a o
a seconda di cosa si vuole gestire: vi ` una parte per l'identicazione di fault
e
e recovery delle risorse, una parte per il controllo della performance (quindi
eventuali aggiustamenti del servizio per poter garantire la QoS). Altri settori
fondamentali riguardano l'accounting e la sicurezza dei servizi.
30
\subsection{Gestione dei sistemi: OSI e SNMP}
OSI ha denito un sistema per poter monitorare/gestire un insieme di risorse
mediante l'uso di risorse astratte 8 : l'idea ` quella di utilizzare delle descrizioni
e
standard per poter definire risorse e azioni, necessarie per la gestione. Le informazioni che descrivono quindi il mondo
sono codicare utilizzando il CMIB,
Common Management Information Base. OSI quindi sarebbe in grado, mediante queste informazioni, di poter gestire i
singoli nodi di una rete (tipo, poter
specicare la banda erogabile presente su un nodo9 , . . . ). OSI struttura il management con l'idea che vi siano manager
in grado di comunicare con gli agenti,i
responsabili delle singole risorse: non vi ` una specica precisa, permettendo
e
quindi di poter realizzare architetture più o meno complesse.
u
In realt`, il protocollo più diuso per la gestione di una rete ` anche uno
a
u
e
dei più semplici, detto Simple Network Management Protocol, sviluppato dall'Iu
ETF, e per questo incompatibile con OSI : inizialmente non teneva conto della
sicurezza, e si trattava di pura e semplice comunicazione.
SNMP denisce (nella sua prima realizzazione) un unico manager centralizzato e diversi agenti non locali, quindi studiati
per un sistema distribuito. Il
manager si preoccupa quindi di fare delle richieste sugli agenti, i quali devono
rispondere, e possono anche avvisare di eventuali problemi/eventi mediante delle
trap. Il protocollo ` molto sincrono, ovvero si attende sempre una risposta!
e
Un agente in realt` gestisce delle variabili standard (non se ne possono
a
introdurre di nuove), che sono descritte nel MIB: le operazioni sono quindi
semplicemente delle GET e SET su queste variabili.
Una prima reingegnerizzazione di SNMP ha portato alla possibilità di poter
a
definire il manager come una struttura gerarchica (sfruttando l'idea di realizzare
degli agenti proxy, una via di mezzo fra un agent e un master), in maniera da
ridurre i rischi di una congestione, suddividendo la responsabilit`. Il costo `
a
e
quindi limitato dal numero di agenti presenti. Solo per` con la terza versione si
o
` introdotto in SNMP anche il concetto di sicurezza.
e
SNMP presenta alcuni problemi: prima di tutto, la perdita/sostituzione di
un agente provoca la ricongurazione di tutto il sistema. Inoltre, si tratta sempre di variabili, che sono solo
rappresentazioni della risorsa: per esempio, con
SNMP non si può specicare la banda di un router, non la può controllare! Il
o
o
manager poi comunica con gli agent, ma sempre esternamente deve essere specicata come avviene la comunicazione (ogni
quanto interroga gli agent?). Inne,
gli agent forniscono informazioni strettamente locali alla risorsa che gestiscono:
per poter fornire delle informazioni più generali sullo stato della rete ` necessario
u
e
aancare a SNMP un sistema di Remote MONitoring, per poter fornire all'utente maggiori possibilità. Si introducono quindi
dei monitor (probe), in grado
a
di lavorare in autonomia e comunicare con il manager, riportando informazioni
8 Non esistono speciche su come implementarle, quindi le varie realizzazioni sono standard
de facto
9 Attenzione, OSI ` solo comunicazione!! La banda dovr` poi essere stabilita dal singolo
e
a
router, la tecnologia utilizzata deve essere indipendente da questa comunicazione!
31
ltrate. Anche RMON rappresenta una derivazione semplicata da OSI, quindi
incompatibile.
OSI permette di definire sistemi molto più complessi, grazie all'uso di un MIB
u
più organizzato. Si possono infatti realizzare gerarchie dinamiche fra manger e
u
agent, questi si possono quindi creare e distruggere a piacimento (senza dover
ricongurare l'intero sistema)! Il MIB ` totalmente cancellabile, come anche le
e
singole operazioni come la GET: si ragiona quindi anche sulla durata dell'operazione, per cui se ` oltre il limite
impostato, ` annullata. Gli oggetti gestiti
e
e
possono essere anche molto complessi (non una singola risorsa come con SNMP).
\subsection{Evoluzione dei router}
L'idea alla base dell'introduzione di QoS in Internet ` che sui nodi intermedi si
e
hanno delle informazioni sullo stato del servizio. Un router semplice prende e
rispedisce i pacchetti, in generale sfruttando la politica FIFO, senza sfruttare
tutte le possibilità per l'instradamento: garantisce best-eort, ma non QoS,
a
poich` i ussi sono limitati da altri ussi!
e
Lo sviluppo sarebbe quindi quello di realizzare un router che ragiona in termini dierenziati : deve essere in grado
quindi di marcare i ussi, e deve riuscire
a trattare la gestione dei ussi in maniera da favorire i ussi più prioritari (magu
ari scartando/ritardando i pacchetti dei ussi meno prioritari). Si ha che quindi
lo stato del router dipende dal singolo pacchetto, che a sua volta dipende dal
traco. In particolare, ` da notare che il costo di una determinata politica
e
viene riesso su ogni usso/messaggio: per questo vuole l'intrusione minima,
per minimizzare il costo.
I router per la QoS si possono modellare mediante due modelli non reali, a
bucket:
$\bullet$ Leaky bucket: corrisponde a un secchio con perdita. L'idea ` quella che
e
un router si comporti come un regolatore del usso in uscita. Si stabilisce
quindi una banda massima, corrispondente alla capacità del bucket: tutto
a
ci` che ` oltre viene scartato dal router, i pacchetti troppo veloci vengono
o
e
rallentati. Ogni router di questo tipo ` quindi pensato per favorire un
e
usso alla volta.
$\bullet$ Token bucket: si prevede la presenza di un token, che garantisce ai pacchetti del usso che lo possiede di
poter essere smistati dal router. Si associa
quindi uno stato al usso, e questo stato dipende proprio dal numero di
token presenti. In questo modello i pacchetti vengono solo ritardati, non
possono essere persi. A seconda della capacità del bucket, si possono avere
a
trasmissioni o rallentamenti. In particolare, un usso potrebbe non aver
sfruttato i token, e trovandosi quindi ad essere l'unico usso con tutti i
token può presentare dei burst. Spesso si attende infatti che un determio
nato usso abbia un numero congruo di token per poter trasmettere tutti
32
assieme un insieme di bit; si tratta quindi di un sistema di buerizzazione,
per cui son necessarie delle apposite risorse. I token vengono generati
mediante un'apposita legge lineare.
Spesso si utilizzano i due bucket in serie, per evitare proprio i burst del token
bucket (quindi prima il token, seguito a cascata dal leaky!).
Le politiche che un router per la QoS può presentare son diverse, tuttavia
o
l'idea ` quella di realizzare delle politiche conservative del lavoro: se arriva un
e
datagramma e non vi sono condizioni per cui il usso ` rallentato e le code son
e
libere, il router lavora alla Internet, reinstradando subito il pacchetto. Infatti,
per la legge di Kleinrock, il router non può essere in una condizione di idle se
o
vi sono dei pacchetti da portare in uscita. La legge di kleinrock stabilisce che,
dati n ussi, con traco $\lambda$n e tempo medio di servizio $\mu$n :
$\bullet$ Il prodotto $\rho$n = $\lambda$n · $\mu$n rappresenta l'utilizzo medio del router
$\bullet$ Denito qn il tempo medio di attesa si ha che
$\rho$n · qn = K
(15)
dove K ` una costante
e
Questo signica che per favorire un usso (aumento della banda, riduzione del
ritardo) in realt` se ne deve per forza sfavorire un altro (diminuzione della bana
da, aumento del ritardo).
Si ` sempre detto che le politiche vengono giudicate dal loro costo, e che
e
politiche più semplici sono meno costose. Tuttavia, nel caso di router, si deve
u
anche tener conto se la politica ` fair o meno (vi sono ussi in condizione di
e
starving?10 ).
Un primo esempio, spesso implementato mediante politiche più semplici
u
perché non ` realmente implementabile ma solo un modello a tendere, ` la
e
e
e
min-max fairness. Si immagini di avere un numero di richieste superiore alle
risorse disponibili, e si devono quindi dividere le risorse in maniera fair. L'idea
` quella di classicare i ussi in base alle loro esigenze, privilegiando i ussi che
e
richiedono meno risorse, per poter cos` lasciare più risorse a chi ne ha maggior\i{}
u
mente bisogno; x1 $<$ x2 $<$ . . . $<$ xn indica quindi la priorit` con cui servire,
a
mentre C indica la capacità massima a disposizione del router. Si possono quina
di definire mn le risorse eettivamente allocate per il usso n-simo, e Mn le
risorse attualmente libere. Si ha quindi che:
mn = min(xn , Mn )
Mn =
n
i=1
C$-$
mi
N $-$n+1
(16)
(17)
10 Osservazione: le politiche dicono come i router possono trattare i ussi, ma tocca poi
all'utente specicare quali ussi debbano essere trattati in quale modo!
33
Un altro modello di scheduling, derivato proprio da come funziona quello del
singolo processore, ` il general scheduling processor : l'idea ` che mediante un
e
e
algoritmo di tipo round-robin si faccia passare un bit per ogni usso alla volta:
tale politica ` sicuramente molto fair, ma non applicabile realmente visto che
e
si lavora a pacchetti e non a bit. Anche questo modello in realt` serve solo per
a
studiare le politiche pensate e confrontarle, per determinarne la fairness.
In realt`, fra le politiche realmente diuse ed implementate in router con
a
QoS vi sono:
1. Priorit` ai ussi : vi sono diversi livelli di priorit` con cui poter etichettare
a
a
un usso. Il router quindi si preoccupa di favorire prima i ussi a massima
priorit`. Questo per` non ` una politica fair ! Se continuano ad arrivare
a
o
e
pacchetti di questi ussi, quelli meno prioritari non verranno mai serviti
(non avranno mai banda a sucienza)!
2. Round robin: ` una politica più fair, che garantisce comunque ad ogni
e
u
usso una propria share della banda, ed ` una politica molto buona se i
e
datagrammi dei vari ussi sono circa delle stesse dimensioni (altrimenti,
si potrebbe usare un weighted round robin, per poter pesare diversamente
i datagrammi. Pi` un datagramma ` pesato, maggiori risorse vi sono
u
e
associate. La normalizzazione ` dicile da realizzare per ussi troppo
e
corti) Il round robin viene spesso implementata in quei router in cui non
si possono specicare delle priorit` speciche, ma in cui comunque i ussi
a
devono competere per delle risorse.
3. Decit round robin: si associa una storia ad ogni usso, perché si impone
e
un limite per ciascuno. Se un usso supera la soglia consentita, non viene
erogato dal router ma si memorizza tale decit. L'erogazione riprender`
a
solo quando gli altri ussi avranno superato tale limite.
4. Fair queueing: si tratta di round-robin fatto bit a bit. Si fa avanzare
sempre il usso con il pacchetto più indietro, ovvero quello che se si fosse
u
realmente fatta una comunicazione bit a bit, avrebbe terminato la comunicazione per primo! Questa ` una delle politiche
maggiormente usate,
e
anche in ambienti Internet, perché si hanno dei calcoli in tempi accettabili.
e
Un problema di tutte le politiche ` in realt` il fatto di non sapere cosa aspettarsi
e
a
all'arrivo, cio` cosa aspettarsi dai ussi che entrano nel router e che devono come
petere per le risorse. Una soluzione possibile ` quindi quella di inviare insieme
e
al usso un'idea dello stato del usso, per vagliare quanto sia pesante o meno!
Perch` un router possa fornire QoS, deve essere dinamicamente ricongurae
bile (cio` deve poter ammettere/spegnere ussi in maniera dinamica). Questo
e
per esempio ` un requisito fondamentale per risolvere il problema della cone
gestione, addirittura in certi casi prevenendolo. Invece che scartare i pacchetti
34
ricevuti in maniera silenziosa (alla Internet)11 , si scartano i pacchetti in maniera
visibile. Questo sistema ` contro la trasparenza, ma ` un'indicazione chiara per
e
e
le applicazioni e gli utenti che vi sono dei problemi. Si possono quindi mettere
in piedi delle politiche preventive, tipo la realizzazione di un'apposita nestra di
trasmissione sul canale.
Una politica sempre implementata, anche nei router a basso costo, ` la Rane
dom Early Detection. Si tabilisce una coda per ciascuno usso, insieme a due
soglie:
$\bullet$ Se il usso fa in modo che la coda sia sempre al di sotto della soglia
minima, non si scarta nessun pacchetto
$\bullet$ Se il usso ` oltre la soglia massima, tutti i nuovi pacchetti vengono
e
scartati.
$\bullet$ Altrimenti, si decide in maniera random su quale usso scartare i pacchetti, basandosi con una probabilit`
crescente con la lunghezza della
a
coda!
Questa politica preventiva evita la congestione.
\subsection{Servizi integrati, RFC 2210}
L'idea alla base dei servizi integrati ` quella di essere in grado di riconoscere i
e
singoli ussi, grazie al router, in modo da poter dierenziare l'uso delle risorse
a seconda del usso che si viene a presentare. Il Service Level Agreement `
e
quindi fatto a livello di singolo usso, e quindi si può decidere la QoS per ogni
o
usso. Si deve quindi stabilire la QoS fra mittente, ricevente e necessaria per
ogni nodo intermedio. Questi protocolli descrivono solo la comunicazione che
le varie parti devono sostenere: la politica locale sar` implementata a livelli
a
inferiori localmente dalle singole entit`.
a
Nonostante il costo, i servizi integrati lavorano proprio al livello applicativo
(OSI), proprio perché a questo livello le risorse sono note e si possono valutare:
e
questo signica che su ogni nodo si lavorer` a livello applicativo, in maniera tale
a
da poter individuare fra i possibili cammini il cammino migliore, che divverr` ata
tivo. Per far ci` si utilizza un protocollo detto Reservation Protocol ; questo proo
tocollo infatti permette di specicare un cammino attivo in grado di rispettare
una determinata SLA, senza considerare il traco corrente, ovvero permette di
riservare delle risorse in maniera attiva per il servizio. L'idea ` che si inviino
e
delle informazione dal ricevente al mittente (e viceversa) per poter valutare le
risorse (ovvero ogni risorsa dovr` provvedere con un opportuno messaggio da
a
inoltrare, per indicare la qualit` di servizio che può orire). Si ha quindi una
a
o
propagazione della gestione, per indicare la disponibilit`!
a
Si tratta di un protocollo con soft state, ovvero il ricevente, una volta accordato il servizio e le modalit`, dovr`
preoccuparsi di rinnovare periodicamente
a
a
11 Vi ` ICMP che prova ad avvertire l'utente che i pacchetti non son stati ricevuti, ma lavora
e
sempre a livello di IP, quindi rischia di essere coinvolto nella congestione!
35
la richiesta del servizio concordato. Si ha che quindi il protocollo ` denito in
e
due passi:
1. Il cliente invia un messaggio di Resv per valutare la disponibilit`
a
2. Un servitore che ` disponibile risponde con un messaggio di tipo Path
e
3. Il cliente conferma il cammino scelto12 rinoltrando con un messaggio di
tipo Resv (solo con questo messaggio riserva le risorse).
Un cliente quindi dovr` rinnovare mediante gli stessi messaggi la richiesta di
a
servizio, tuttavia sono previsiti anche degli appositi messaggi (tear ) sia da parte
del cliente che del servitore, per poter interrompere l'erogazione del servizio,
e permettere una ricongurazione del servizio. Il protocollo stabilisce che si
possono richiedere risorse in esclusiva o in condivisione con altri ussi (particolarmente utile per ottimizzare la
comunicazione). Gli scambi di messaggi
ovviamente avvengono fra nodi vicini, cercando quindi di limitare il costo senza
eseguire un broadcast.
Questo ` un sistema conveniente per reti locali e non globali (si ha un alto nue
mero di messaggi in circolazione): troppi clienti e si avrebbero errori nel riservare
le risorse perché prenotate prima da altri, e deve essere noto alle applicazioni
e
che lavorano che lo scambio di informazioni si basa su tale protocollo. Infatti,
al degradare delle prestazioni si può giungere ad una condizione di best-eort,
o
per cui ` necessaria la rinegoziazione. Ogni ricevente deve quindi mantenere
e
uno stato per avere idea in che situazione si trova. Sicuramente conviene condividere ove possibile. Si possono anche
fare spesso delle supposizioni per limitare
l'overhead (il ricevitore sa a chi mandare per primo le richieste, il servitore sa
chi potrebbe essere interessato al servizio, . . . ).
Il problema di RSVP ` che ` un protocollo con una forte intrusione, perché si
e
e
e
ha una parte statica molto ben denita, ma che potrebbe essere solo ideale (non
funzionerebbe bene in presenza di nodi congestionati). Per questo, a supporto
di questo protocollo per la parte statica, sono stati sviluppati altri protocolli
per il supporto alla QoS a livello applicativo per la parte dinamica. Sono il Real
Time Protocol e il Real Time Control Protocol. Sono entrambi protocolli basati
su UDP, per il singolo usso, che si preoccupano di portare materialmente i
frame, incapsulandoli in maniera opportuna. Proprio per questo motivo non
la garantiscono ma sono solo di supporto! RTP per esempio si preoccupa di
marcare ed ordinare i singoli frame, in maniera di mandarli in ordine13 , mentre
RTCP gestisce la connessione astratta.
RTP non denisce una sincronizzazione verso un tempo assoluto (nel distribuito questo ha dei costi improponibili), ma ha
l'obiettivo di minimizzare il
jitter. Questi primi protocolli ragionano sul cammino attivo, per poter definire
correttamente i nodi intermedi. Sono protocolli IETF, con sempre l'obiettivo di
giungere ad una facile e veloce implementazione.
12 Il protocollo non spiega come scegliere il cammino (problema implementativo), ma solo
quali sono i messaggi di comunicazione che i diversi partecipanti devono scambiare
13 Attenzione: la decisione di come mandare per` non ` a carico del protocollo, che mette a
o
e
disposizione solo meccanismi ma non politiche
36
RTP ` sempre accompagnato da RTCP. Il primo ` un servizio fortemente
e
e
erogato dal servitore verso il ricevente (da chi sa poco a chi sa molto), mentre
il secondo serve per fornire al gestore informazioni di gestione, e quindi naviga
in entrambe le direzioni. Tuttavia, si devono specicare in maniera precisa entrambi perché utilizzano le stesse risorse,
e potrebbero aumentare l'intrusione;
e
si stabilisce per esempio quale ` la banda che RTCP può sfruttare. RTP in
e
o
particolare consente ai singoli intermediari di intervenire sui singoli messaggi,
per poter comunque garantire il raggiungimento della QoS stabilita. RTCP permette, in particolare con il receiver e il
sender report, di poter stabilire lo stato
del cammino, per poter quindi far eseguire eventuali operazioni (tipo recovery
di un nodo); tuttavia, si deve sempre considerare che tutto ci` ` particolarmente
oe
costoso.
Questi protocolli sono anche veicoli di informazioni applicative, cio` si pose
sono specicare nei datagrammi informazioni per le singole applicazioni: sono
protocolli hop-to-hop, che lavorano su tutti i nodi, per cui bisogna garantire che
i nodi intemedi non modichino le informazioni a livello applicativo. Le possono
vedere, ma non modicare.
Questi protocolli purtroppo non sono molto scalabili, e possono essere usati
solo in reti molto limitate. Il lettore RealPlayer per esempio sfrutta un altro
protocollo detto Real Time Streaming Protocol, in cui non si denisce un cammino attivo, ma una volta ottenute le
speciche dello stream, si utilizza UDP
o TCP e un sistema di buering per poter trasferire il usso dalla sorgente al
player. Infatti, inizialmente si parte mediante TCP che riempe il buer, ma se
un frame non arriva si sfrutta UDP proprio perché non garantisce che i messaggi
e
`
arrivino in ordine! E un modello push, in cui le informazioni arrivano dal server. Questo ` un protocollo dal costo
minimo, proprio perché non riserva nulla:
e
e
`
lavora solo sugli end-point. E sempre possibile comunque tornare a RSVP nel
caso non fosse suciente.
\subsection{Servizi differenziati, RFC 2474}
L'approccio a servizi differenziati consiste nel cercare di fornire QoS non a livello
applicativo, ma a livello di rete. Facendo ci`, in realt`, si ha che si sono deniti
o
a
molti meno protocolli rispetto ai servizi integrati (risultando essere inoltre molto
più scalabili). I servizi dierenziati sono studiati per supportare le applicazioni
u
legacy e per domini specici (comunit` di utenti). L'idea ` quella che si devono
a
e
aggreggare i ussi in diverse categorie, e a seconda delle categorie si denisce la
QoS. Un pacchetto viene quindi classicato dal router in base al suo contenuto,
e viene associato ad una possibile classe, e quindi ad un possibile trattamento.
Si ha che quindi l'SLA ` stipulato sulla classicazione dei ussi, e le garanzie
e
vengono fornite dalle politiche implementate dai router (la politica ` concordata
e
solo fra l'utente e il server).
Possibili esempi di servizio sono:
$\bullet$ l'expedited forwarding, per cui ogni router dispone di due diverse code, per
37
cui si garantisce che almeno i pacchetti classicati come expedited saranno
consegnati con la qualit` calcolata. Si possono pesare utilizzando una fair
a
queuing pesata.
$\bullet$ l'assured forwarding, in cui i pacchetti sono marcati a seconda della possibile congestione.
Vi ` per` un problema: come si possono definire queste classi, nel protocollo
e
o
IPv4 non vi ` possibilità. L'idea migliore sarebbe quella di passare ad IPv6, che
e
a
grazie a 128 bit contro 32, garantisce la presenza di ancora molti nomi, ove `
e
presente un apposito campo dove si può classicare il singolo pacchetto!
o
IPv6 ` stato pensato per essere compatibile con IPv4, ma gestisce gli ine
dirizzi in maniera diversa (il broadcast ` stato eliminato, divenendo in realt`
e
a
e
multicast; sono stati aggiunti il P2P e l'anycast14 , ed ` in grado di fornire un
suo supporto alla replicazione! IPv6 in particolare semplica l'header, facendo
in modo di puntare altri header per poterlo estendere! Un'altra caratteristica
` che IPv6 ` stato progettato per essere mobile, ovvero: un indirizzo di questo
e
e
tipo si può spostare senza problema da una rete a quell'altra, grazie al fatto che
o
lo si memorizza in un'apposita struttura. IPv6 in realt` ` stato studiato per
a e
essere di supporto anche ai servizi integrati, quindi potrebbe essere un'ottima
estensione per Internet.
Oltre a questi approcci, si sta cercando di sviluppare dei sistemi in grado
di far convivere (in maniera competitiva) servizi integrati e dierenziati, per
cercare di sfruttare i vantaggi di entrambi.

\section{I middleware}
Un middleware ` un insieme di strumenti di supporto all'utente/sviluppatore
e
per meglio poter arontare la complessit` di un sistema in ambienti aperti
a
(eterogenei ). Un middleware permette quindi di integrare diverse applicazioni,
fornendo un supporto alla comunicazione fra sistemi diversi.
Un middleware mette a disposzione delle risorse per l'utente (ottica B2C),
ma anche componenti reintegrabili in altre applicazioni (ottica B2B).
Qual'` il problema dell'eterogeneit`? Si può risolvere con approcci ad-hoc,
e
a
o
ma ci` risulta in sistemi non portabili. Quello che si vuole quindi realizzare ` un
o
e
supporto per cui un client e un server, di ambienti diversi, riescano comunque
a comunicare!
Un middleware può fornire supporto a livelli diversi, sia a livello sico (replio
cazione per esempio) che applicativo (proxy, . . . ): fornisce degli strumenti per
l'utente in maniera che possa trascurare l'aspetto tecnologico, concentrandosi
solo sul servizio da fornire: ` quindi fondamentale per poter astrarre!
e
Un middleware si pone come uno strato intermedio fra l'applicazione e le
risorse di più basso livello (S.O., dischi, . . . ): si possono inserire diverse funzionu
alit` (non solo comunicazione), come per esempio un supporto alla trasparenza
a
(non importa il livello sottostante, le API del middleware fanno in modo che
il comportamento sia sempre il medesimo!). Quindi, un middleware non solo
semplica l'aspetto dell'applicazione, ma anche quello di supporto del sistema
distribuito!22
Spesso un middleware viene addottato per la sua capacità di gestire uno o più
a
u
sistemi legacy fondamentali per l'azienda, che altrimenti sarebbero intrattabili
(evoluzione dei sistemi, e perdita di conoscenza). Fondamentalmente, nel caso
aziendale, il compito di un middleware ` l'integrazione di risorse aziendali !
e
In ambito accademico, invece, in generale un middleware viene proposto da
una comunit` per risolvere diversi problemi ed essere introdotto come standard.
a
Questo spesso può risultare problematico perché i diversi standard non sono
o
e
interoperabili fra di loro! Esistono diversi dialetti/linguaggi per realizzare la
comunicazione, che sono uno incompatibile con quell'altro.
\subsection{Valutare un middleware}
Un middleware viene giudicato dalla ricchezza di funzionalit` che sono messe a
a
disposizione, e quindi dalle aree in cui riesce ad intervenire. Esistono diverse
aree di gestione (Presentation, Computation, Information [loggin i.e.], Communication, Control [thread i.e.] e System
[sicurezza i.e.]): alcune di queste sono
fondamentali per un middleware (senza, non lo sarebbe), altre rappresentano
un valore aggiunto.
22 Ma in un sistema distribuito, dove si pone il middleware? Dipende! Certi middleware
devono avere risorse su ogni nodo, altri no. . . In ogni caso, ogni nodo dell'architettura possono
essere target
51
In generale si possono dividere in 4 livelli le tipologie possibili di un servizio
per il middleware:
$\bullet$ Host infrastructure middleware: si tratta del livello più basso, il più viciu
u
`
no alla macchina stessa. E quello infatti fondamentale per poter superare
l'eterogeneit`, in grado quindi di fornire una visione trasparente di quela
lo che ` presente a livello inferiore. Deve essere quindi un qualcosa di
e
distribuito su ogni nodo dell'architettura! Un esempio ` la JVM.
e
$\bullet$ Distribution middleware: altro aspetto fondamentale, ` quella parte di un
e
middleware che permette di integrare le risorse distribuite, mediante un
apposito sistema di comunicazione. Si tratta anche questo di un qualcosa che deve essere opportunatamente distribuito su
tutti i nodi. Es`
empi: RMI23 , JMS, CORBA. E quindi questo il livello che congura e
gestisce le risorse distribuite. Introduce quindi API per la comunicazione
e meccanismi di supporto alla comunicazione (per esempio, un sistema di
nomi).
$\bullet$ Common middleware services: questo invece ` un aspetto che ` presente in
e
e
middleware maturi, per cui si possono fornire dei componenti distribuibili,
utili per sviluppare in un'ottica a componenti. Spesso quindi si realizza
una propria visione, ovvero il sistema si basa su un'architettura comune
e un modello di supporto. Sono quindi i servizi trasversali, che spesso in
realt` rappresentano il punto di forza di un mw: ` in base alla loro qualit`
a
e
a
che si decide se sceglierlo o meno.
$\bullet$ Domain middleware services: altro aspetto presente in middleware maturi,
si propongono anche servizi applicativi gi` realizzati, specici per una dea
terminata comunit`. Infatti, spesso il successo di un middleware ` dovuto
a
e
dalla comunit` di utenti che lo utilizzano, e dalle varie sottocomunit` che
a
a
si vengono a formare, che possono addirittura guidarne lo sviluppo! Basta
pensare che CORBA ` uno standard proposto da un consorzio d'azienda,
e
l'OMG.
\subsection{Classicazione dei mw}
I middleware si possono categorizzare in diversi modi, tuttavia la maggior parte
dell'installato consiste in primis dai DOC, Distributed Object Computing (tipo
CORBA, orientati all'approccio ad oggetti), e quindi dai MOM, Message Oriented MW. In realt` per`, il 'mw' più grande
esistente forse ` il Web: non ha
a
o
u
e
tutte le caratteristiche di un Mw (esempio, QoS, replicazione, . . . ), ma ` un
e
esempio di un sistema che permette la comunicazione fra diversi sistemi eterogenei, in generale mediante la
pubblicazione di informazioni su un server e il loro
reperimento da parte di un client. Il grosso problema del Web infatti ` che nato
e
per essere usato a livello di presentazione, e quindi di suo non presentava un
sistema per lo scambio di messaggi : le sue evoluzioni hanno introdotto sistemi
23 Limite
di RMI rispetto ad RPC: lega C/S ad una tecnologia, non ` eterogeneo!
e
52
di comunicazione ed interazione, ma sempre in maniera molto limitata, dovendo
basarsi solo sull'approccio C/S!
Lavorando solo con RPC, che genere di MW si possono ottenere? Il problema
di RPC ` che comunque limita fortemente (per esempio, si hanno operazioni
e
strettamente sincrone bloccanti, quando magari altri modi potrebbero essere
desiderati) e in generale realizza un binding statico e non dinamico. Permette
gi` di fornire dei livelli di trasparenza, e un sottolinguaggio per poter definire
a
fra C e S i servizi, ma resta che il sistema che si otterr` sar` poco scalabile,
a
a
molto rigido (tutto deciso in maniera statica, senza poter quindi intervenire per
ottimizzare il sistema!)
I diversi possibili modelli di mw che si possono trovare sono:
$\bullet$ Distributed Transaction Processing: questi mw nascono per cercare di
ottimizzare l'accesso ai DB. L'ipotesi ` che si abbiano delle operazioni
e
comandate da un C con poche risorse, e si vuole quindi fornire un supporto
per facilitare la realizzazione di operazioni ACID (Atomic, Consistent,
Isolation, Durable), necessarie per avere QoS in sistemi distribuiti basati
su DB.
$\bullet$ DB mw : l'obiettivo di questi mw invece ` quello di migliorare/fornire un
e
supporto per eettuare ricerche su db distribuiti. Si ha quindi una logica
vicina al data-mining. Si vuole quindi superare l'eterogeneit` dei diversi
a
DB, sfruttando sistemi standard come ODBC, per leggere sui DB.
$\bullet$ MOM : l'obiettivo di questi mw ` l'estrema indipendenza fra i vari attori ! I
e
diversi sottoinsiemi infatti comunicano a scambio di messaggi, in maniera
sincrona/asincrona, e fortemente disaccoppiata: si tratta di un sistema di
comunicazione a più basso livello del C/S. Si possono realizzare messaggi
u
tipati o meno, e risulta essere facile la realizzazione di multi/broadcast.
A livello di implementazione si può citare JMS, che venendo dopo gli
o
altri sistemi, sviluppa un sistema basato su interfacce per poter definire i
messaggi ben formati.
$\bullet$ DOC : sono i mw in assoluto più diusi. Si preoccupano di definire un'inu
terazione molto precisa e regolata, astraendo le risorse ad essere oggetti.
Si incapsula il C/S in un universo basato sugli oggetti. Tuttavia, non vi
` mai in generale una comunicazione diretta, per via della presenza di un
e
broker : questo fornisce delle interfacce sia al C che al S, e quindi un supporto alla mediazione fra i due attori.
Questo sistemafacilita l'integrazione
di sistemi, e permette di realizzare operazioni che si possono eseguire in
maniera automatica.
Proprio perché si basa sul modello ad oggetti, i mw di questa tipologia
e
sono molto più variabili, e possono essere estesi molto più facilmente dei
u
u
MOM. Spesso si hanno mw di questo tipo OpenSource, in grado di creare
una comunit` molto vasta ed attiva.
a
53
$\bullet$ Addattativi e Riessivi: un mw addattativo ` un mw che varia i servizi
e
nel tempo, a seconda della situazione, quindi a caldo: deve essere quindi
di fornire nuovi modi di lavorare.
Il fatto che sia riessivo indica invece che un componente del mw deve essere in grado di esporre quello che fa. Un
sistema riessivo ` maggiormente
e
costoso di un sistema statico, ma ` un sistema che viene valutato molto
e
perché permette, in maniera dinamica, di definire via real-time come il
e
componente funzioni!
L'obiettivo ` quindi fornire un sistema per la visibilit` dei livelli sottostanti
e
a
e permettere di adattatare e sistemare in base alle esigenze.
Esistono poi diversi mw nati proprio per risolvere dei problemi specici (mobilità, reti ad-hoc, . . . ).
a
\subsection{TINA-C}
TINA-C rappresenta la proposta di un mw per le TLC. Si vuole realizzare un
sistema dove siano previsti più provider, in grado quindi di lavorare su una
u
rete. L'idea alla base ` la possibilità di definire le varie entit`, i servizi possibili
e
a
a
e fornire quindi un sistema per definire la negoziazione per l'erogazione dei
servizi, e quindi la QoS.
Il modello computazionale di TINA-C ` Distributed Processing Environment.
e
Ogni nodo deve presentare delle funzionalit` che permettono la comunicazione
a
nel distribuito. Questo ` ovviamente il livello di più alto livello, che si basa su
e
u
livelli sottostanti che forniscono astrazionie e trasparenza. Il livello sottostante
` il Native Computer and Compunication Environment, che ovviamente deve
e
essere presente su tutti i nodi, per mascherare l'hw per il mw.
Le applicazioni si possono quindi costruire sopra DPE, sfruttando delle applicazioni TINA-C gi` presenti ! Si hanno
quindi una serie di oggetti presenti su
a
ogni nodo. Queste applicazioni non sono localizzati, e si può trattare di servizi
o
da orire, risorse ed elementi della rete. Il sistema ` quindi trasparente, perché
e
e
non si vede mai dove le risorse sono realmente allocate.
In realt`, TINA-C prevede anche una visione non trasparente! Lo standard
a
del 2000 infatti denisce che l'utente deve esprimere le proprie preferenze, e
quindi per poter sviluppare un modello complesso, si deve tener conto della
locazione: si può progettare il sistema inizialmente come non trasparente, e
o
quindi aggiungere la trasparenza!
\subsection{I MOM}
Si tratta in assoluto dei mw più semplicirealizzabili: sono a basso costo, e i
u
messaggi lavorano a basso livello, garantendo un forte disaccoppiamento fra le
varie entit`. Basandosi sui messaggi, si supera direttamente l'eterogeneit`.
a
a
Il problema ` come fornire QoS ai messaggi? I messaggi devono essere pere
manenti (non ` necessaria la presenza di entrambi gli attori per realizzare la
e
54
comunicazione), ma soprattutto l'interconnessione ` denita assolutamente in
e
maniera statica! Non sono quindi mw dinamici.
Ogni attore interessato presenta una propria coda locale, dove saranno depositati i messaggi: questo ` un supporto
fornito quindi dal MOM, per cui si
e
tratta di gestire delle code orientate (o in ingresso o in uscita). Quello che realizza un MOM ` quindi un'overlay
network, specicando quindi un sistema di
e
nomi, routing, . . .
I messaggi possono o essere P2P oppure forme di multicast. Le API che il
mw prevede sono quindi quelle per poter fare delle send e receive dei messaggi
sulle code locali!Il mw si preoccupa di realizzare l'instradamento, ` un integrae
tore di nodi: spiega come i router si debbano coordinare (si possono avere diversi
intermediari, ed esistono messaggi broker appositi per gestire l'eterogeneit`)!
a
Questi sono mw a basso costo, perché fanno da collante: non si aggiunge
e
molto all'applicazione, ma solo la possibilità di mandare e ricevere messaggi! Il
a
costo limitato facilita infatti l'integrazione di sistemi legacy!
Uno dei MOM più diusi ` MQSeries di IBM: questo realizza uno stub per
u
e
ogni client, e introduce degli agenti che non sono altro che nodi particolari che
fanno da relay. I gestori delle code sono a loro volta degli agenti, ve ne ` quindi
e
uno per coda. Il problema ` che gli agenti gestori dei canali (MCA) devono
e
essere gestiti in fase di congurazione, quindi sono decisi in maniera statica!
$\bullet$ Per ogni nodo si decide il numero e quali MCA
$\bullet$ E quindi si attivano le connessioni
La caratteristica di MQSeries ` che, sfruttando le code, introduce QoS: in partie
colare si possono realizzare dei broker in grado di ricevere/prendere i messaggi e
di trattarli a seconda della QoS richiesta (trasformandoli, ottimizzando il routing gi` basato su tabelle in base al
contenuto del messaggio e quindi aggiungendo
a
un po' di essibilit`, . . . ): introduce quindi un minimo di logica!
a
Questi sistemi statici hanno la caratteristica di avere un'intrusione minima,
ma non permettono molte ottimizzazioni. . .
\subsection{I mw ad oggetti}
Sono i mw più interessanti, in grado di lavorare ad alto livello. Si realizza un
u
contratto fra clienti e servitori, in maniera tale da realizzare anche più impleu
mentazioni dello stesso servizio! In particolare, questi mw si basano su un bus
di interconnessione che si occupa di certe logiche di base, permettendo quindi
all'utente di pensare solo alla business logic! Un mw ad oggetti si preoccupa di
definire le interfacce degli oggetti e le interazioni possibili, realizzando anche un
sistema aperto dove integrare sistemi eterogenei.
`
E quindi un'estensione del C/S: un C richiede un servizio (ovvero un oggetto). L'interfaccia rappresenta il contratto
dell'oggetto, ovvero i servizi richiedibili da parte di un client. In particolare, si possono definire delle operazioni
55
richiedibili sia dagli oggetti che dai clienti per ottenere servizi!
Una caratteristica particolare ed importante dei mw ad oggetti ` che pree
sentano delle soluzioni che si ripetono, e delle possibili strategie da scegliere:
abbiamo dei pattern, meccanismi che si ripetono!
La base per ogni mw ad oggetti sono:
$\bullet$ La possibilità di realizzare un'interazione remota
a
$\bullet$ Possibilit` di comunicare in maniera asincrona
a
Inoltre, si parla di pattern anche per la gestione delle risorse, della QoS, e la
denizione di nuovi servizi.
\subsection{Pattern per l'interazione remota}
Idea di base: un cliente vuole riferirsi ad un oggetto remoto; per cui serve un
sistema per avere dei riferimenti remoti. Gli oggetti remoti si possono creare o
localmente da parte del server, o in maniera remota su richiesta del client. Una
volta istanziato, deve essere fornito il riferimento al client. Questa ` la versione
e
di base, di seguito, i diversi pattern che si possono utilizzare per risolvere questo
problema:
$\bullet$ Proxy: il client riferisce localmente un'altra struttura detta proxy, che si
occupa di gestire le richieste al server remoto. Il proxy potrebbe anche
essere scritto in un altro linguaggio. Il proxy permette di accedere al server
come se fosse presente localmente.
Una sua variazione, il pattern stub, realizza invece un proxy lato server.
Questi oggetti si preoccupano di ricevere le richieste e di ridirigerle direttamente all'oggetto remoto che gestisce.
Ogni stub potrebbe gestire anche
una collezione di oggetti remoti.
Si deve cercare di limitare il numero di questi oggetti, per ridurre l'overhead nel sistema.
$\bullet$ ObjectID: questo pattern si preoccupa di definire un oggetto reale, a cui
`
può accedere un client. E quindi necessario trasferire le informazioni dal C
o
al S. Spesso e volentieri si abbina al proxy (il client può anche fornire l'id
o
al proxy, che si preoccupa di recuperare il riferimento dell'oggetto: si parla
spesso anche di nomi globali unici ), il quale potrebbe tener memorizzato
per comodit` l'id. L'ObjectID deve quindi avere la caratteristica di essere
a
univoco.
Non ` un pattern strettamente necessario, a seconda di come si vuole reale
izzare l'architettura: si potrebbe volere per esempio che l'utente non abbia
conoscenza del riferimento remoto, ma che in maniera trasparente sia il
supporto a fornire l'oggetto con i servizi richiesti dal cliente24 . L'ObjectId potrebbe essere troppo vincolante. Se
non ` necessario uno stato, in
e
24 Questo sistema introduce per` altri problemi: due richieste vicine per esempio riferiscono
o
lo stesso oggetto
56
generale ` più conveniente questo modo di lavorare, perché ` il mw che si
e u
ee
preoccupa di associare gli oggetti in maniera eciente.
$\bullet$ Marshalling/Unmarshalling: nel concentrato in generale o si lavora per
valore o per riferimento. Nel concentrato quest'ultima opzione ` quele
la usata normalmente. Tuttavia, come si fa a passare proprio l'oggetto
(necessario per l'operazione sul server, oppure un oggetto risultante nell'operazione?)? Se ne deve fare proprio una
copia, ed ecco la necessit`
a
di avere un sistema che sia in grado di fare marshalling e unmarshalling,
cio`: si crea una copia dell'oggetto che viene opportunatamente serialize
zata, trasmessa e poi deserializzata da parte del client! In certi casi per`
o
si potrebbe anche volere un oggetto che non sia una copia, ma proprio
l'oggetto unico presente sul server: si deve quindi trovare una maniera per
distinguire fra due diversi tipi di marshalling. In generale, si può peno
sare che la maggior parte delle volte al server si può passare un oggetto
o
by-value.
$\bullet$ Gestione degli errori : deve essere possibile anche trasmettere gli errori
sia da parte del client che da parte del server, e sempre a chiunque possa
risolvere il problema.
$\bullet$ Naming support: si tratta di un pattern molto utile per la gestione dei
riferimenti remoti, ovvero si riferisce un nameserver che mantiene memorizzati gli ObjectID. Si può anche aumentare la
trasparenza, facendo in
o
modo di riferire proxy e stub dal name server! Si presenta per` il problema
o
di capire come il client conosca il name server!
$\bullet$ Singleton: questo pattern si preoccupa di definire che vi sia sempre e solo
`
al massimo un'istanza di un tipo di oggetto. E utile per esempio per
la sopravvivvenza di questo al di fuori della durata dell'applicazione. Un
esempio di singleton per esempio può essere il servizio di nomi: deve essere
o
sempre presente, e possibilmente unico (o magari gerarchizzato in maniera
`
intelligente). E usato sicuramente per congurare certi oggetti complessi
una volta sola.
$\bullet$ Server Application: Come realizzare il deployment nel sistema? In che
ordine attivare i servizi, e i vari servitori (sistema di nomi, come e quando
istanziare l'oggetto remoto, . . . ). Devono essere quindi presenti diverse
strategie d'attivazione, magari denibili in maniera opportuna dai client!
$\bullet$ Holder : questo ` un pattern necessario per risolvere certi problemi d'eteroe
geneit`. Si preoccupa infatti di incapsulare in maniera opportuna gli
a
oggetti per presentarli a certi sistemi in maniera che possano trattarli
mediante le semantiche da loro denite. Un esempio riguarda per esempio linguaggi che permettono parametri di in/out e
quelli che non lo
permettono. Si hanno quindi come possibili operazioni read/write.
57
\subsection{Pattern per la comunicazione}
Di base, i mw ad oggetti tendono ad introdurre come primo modello di comunicazione l'interazione sincrona bloccante.
Tuttavia, questa comunicazione `
e
alquanto pesante, perché lega in maniera pesante il client al server e viceversa.
e
Per questo vi sono dei pattern per introdurre altri modelli.
Per ottenere una comunicazione asincrona, si possono usare:
$\bullet$ Il Fire and Forget: il client richiama l'operazione, e quindi rinuncia ad
avere qualunque informazione sul successo dell'operazione. Si ha quindi
un'attesa minimale, per cui il client ottiene immediatamente il controllo
appena inviata la richiesta per poter eseguire l'operazione. L'idea ` quella
e
di usare un proxy (anche un thread quindi) dal lato del client che si preoccupi di gestire il controllo dell'operazione
remota. Non ` garantito per`
e
o
che l'operazione non sia bloccante: il proxy in generale serve le richieste
usando una coda da cui servirsi, e se la coda fosse piena il client dovrebbe
attendere. Non ` presente in tutti i mw ad oggetti.
e
$\bullet$ Catch and return: il client attende più a lungo rispetto al caso precedente,
u
ma in questo modello deve attendere che sia il server stub a generare un
processo per risolvere la richiesta, e che quindi faccia return. Dipende
quindi anche dal tempo di comunicazione dei nodi! Questo modello `
e
spesso presente, perché permette di realizzare un'operazione asincrona
e
più garantita, ovvero fornisce una maggiore sicurezza sulla consegna della
u
richiesta!
Invece, per realizzare una comunicazione sincrona non bloccante:
$\bullet$ Poll Object: il client non resta in attesa ma vuole comunque il risultato.
Si fa allora attendere un oggetto al suo posto, che viene interrogato di
tanto in tanto dal client (che ` sbloccato, e quindi può proseguire). Una
e
o
volta che il risultato ` disponibile sull'oggetto poll, il client si preoccupa
e
di recuperarlo.
In generale, un oggetto poll ` un oggetto semplice ritagliato su quello
e
specico risultato, e quindi non ` generalizzato. Il mw si preoccupa di
e
crearlo in maniera automatica. Come si potrebbe per` gestire il risultato
o
per più clienti (utilizzo della trasparenza, servizi di multicast?) oppure
u
più interazioni (tanti poll object)?
u
$\bullet$ Call-back Object: ` comunque presente un intermediario, ma si può ine
o
serire logica in questo oggetto! Il client infatti può specicarlo, e una
o
volta che ha ottenuto il risultato ` l'oggetto stesso ad avvertire il client,
e
fornendogli il risultato! Questo sistema ` sicuramente più complesso e non
e
u
gestibile direttamente in maniera automatica da un mw, per` fornisce un
o
disaccoppiamento maggiore rispetto al poll object! Si può infatti inserire
o
un qualunque comportamento in questo oggetto.
Questi ultimi due modelli son presenti in CORBA, .NET e diversi altri mw.
58
\subsection{Pattern per la gestione delle risorse e dei servizi}
Spesso questi pattern rappresentano politiche possibili per il deployment e o la
congurazione dei vari servizi. I mw possono prevederne più di uno, a seconda
u
delle esigenze dell'utenza.
$\bullet$ Il pattern più semplice ` quello delle istanze precongurate: viene deciso
u
e
il deployment presso il server in maniera statica, primache il client possa
`
eseguire delle richieste. E una politica rigida rispetto ad altre, e si deve
considerare il fatto che troppe istanze potrebbero ingolfare il sistema. Si
può gestire uno stato? Tutti i client devono essere trattati in maniera
o
uguale, quindi verrebbe da dire di no. . .
$\bullet$ Attivazione On Demand : esattamente l'opposto, i servitori son dotati di
stato, e si possono realizzare operazioni diverse a seconda del tipo di client
che si collega. I servitori son creati by-need, e quindi solo quando sono
richiesti dal client. Quindi, se una tipologia di servizio non ` richiesta
e
spesso, il suo servitore sar` attivo poco spesso, consumando poche risorse:
a
si ha quindi un costo limitato! Questa ` la politica di default di quasi tutti
e
i mw, visto il suo costo.
Si può anche decidere di introdurre un tempo di vita per limitare ulterio
ormente il costo, per cui un servitore non richiesto per un tot di tempo
viene deallocato.
Come gestire per` il problema del riferimento remoto? Se per esempio
o
un client ha conoscenza di un riferimento remoto di un oggetto, per cui
volesse riferirlo direttamente senza utilizzare la procedura d'attivazione,
ma questo ` stato nel frattempo deallocato? Si avrà un errore, per cui si
e
a
dovr` gestire.
a
$\bullet$ Attivazione a singola richiesta: limite estremo, si ha che l'oggetto ` si
e
creato al presentarsi di una richiesta, ma anche terminato quando questa
`
` stata espletata! E quindi un sistema molto reattivo, che per` ha ancora
e
o
problemi nella rappresentazione dello stato (gli oggetti non sono persistenti!). Questo modello ` quindi utilizzato solo
in situazioni in cui lo stato
e
non sia necessario. Per limitare l'overhead e il consumo delle risorse, `
e
necessario un controllo sul numero d'istanze attivate.
$\bullet$ Pool di istanze sempre pronte: si tratta sempre di creare al deployment
(e quindi in maniera statica) un certo numero di istanze disponibili per
il client, prima che questo possa fare richiesta. Questo modello quindi
non presenta nessun costo d'attivazione e disattivazione, ma necessita che
lo stato sia memorizzato sul client (infatti, sfruttando un meccanismo di
trasparenza, un client potrebbe non riutilizzare la stessa istanza gi` usaa
ta!). Vi sono per` problemi di dimensionamento di cui tener conto (se son
o
troppe istanze rispetto al traco, si consumano inutilmente le risorse, se
invece son poche o si estende il pool, oppure si ` necessaria una coda dove
e
memorizzare le richieste). Si potrebbe ottimizzare per esempio facendo
59
in modo che gni istanza possa gestire più di una richiesta, e vericando
u
(monitoring) il numero di istanze contemporanee per ottimizzare.
`
$\bullet$ Attivazione dal client: E compito invece del client attivare l'istanza, e
`
diventa lui il responsabile e gestore della risorsa remota. E una logica
spesso scelta, che garantisce al client di utilizzare un'entit` a lui riservata.
a
Si ha per` un accoppiamento forte fra C e sessione di lavoro.
o
Esistono poi pattern per gestire la durata della vita degli oggetti, come il passivation:se un C non accede per un
determinato tempo ad una sua risorsa, il
server potrebbe decidere di farne lo store da qualche parte, e liberarne le risorse
per altri oggetti. Alla richiesta dell'oggetto, il server si preoccuper` di riattia
varlo, ricaricando lo stato salvato. Questo pattern ` molto importante per la
e
scalabilit` del sistema.
a
Un pattern simile ` il lease, per cui per` il servitore decide di distruggere le
e
o
istanze non usate. Perch` resti attivo un oggetto, il client deve presentare entro
e
il tempo di lease la richiesta di voler ancora adoperare l'oggetto. Si può quindi
o
realizzare usando il tempo di passivation e il tempo di presentazione del lease,
per far scegliere al server quale politica adottare!
Il pattern Factory ` un pattern di supporto alla creazione di oggetti: si trate
ta di un attivatore delle classi, e si può pensare di realizzarne uno per nodo,
o
in grado di creare tutti gli oggetti considerati necessari. Sfruttando il factory,
si possono realizzare politiche nascoste per ottimizzare quindi il deployment (a
tutto pensa lui!).
Spesso, il tempo di vita di un oggetto ` un qualcosa di molto complesso. Vi
e
sono quindi dei meccanismi comuni nei mw per valutarne il tempo d'esistenza
(sfruttando passivation, lease, reference counting, . . . ).
\subsection{I servizi addizionali}
Si tratta di servizi che possono aiutare l'utente ad esprimere determinate operazioni. I servizi infatti possono
dipendere dal contesto utilizzato, la sessione, o
da una serie di eventi che si sono venuti a vericare.
In particolare, l'Invocation Context ` molto utile: in generale, infatti, i mw
e
vengono sviluppati in maniera tale che l'utente non sia costretto a specicare
nelle sue operazioni parametri di supporto, ma solo quelli necessari per la business logic. Per` può capitare che in
certi casi questi parametri siano proprio
o
o
necessari per l'operazione (tipo per realizzare delle transazioni sicure): questo
pattern si preoccupa di recuperare le informazioni aggiuntive, che formano il
contesto, e vengono aggiunte alla richiesta mediante un proxy. Si va quindi
oltre il C/S primitivo, introducendo una separazione dei compiti (client prepara
la richiesta, proxy aggiunge informazioni di contesto necessarie).
60
La sessione ` un altro pattern per poter fornire un supporto al servitore:
e
si utilizza per mantenere la specica dell'oggetto remoto, permettendo cos` di
\i{}
creare un thin client.
Un altro pattern inne ` il call-chain interception: vi sono diversi gestori
e
di supporto, i quali possono essere inseriti prima dell'invocazione (quindi, a
dierenza dell'invocation context, sono dal lato del server), per poter eseguire
dei compiti specici (per es: in base al tipo della richiesta, decidono il formato
dei dati per la risposta). Questi intercettori possono anche bloccare l'invoke no
a quando non hanno terminato il loro compito, creando appunto una catena di
responsabilit`. Si possono anche combinare (caso tipico: encrypt/decrypt di
a
messaggi, introducendo quindi anche catene sul client!).
\subsection{Servizi per la QoS}
Tutti i mw dispongono di servizi per fornire QoS, tranne i MOM. Anche qui, si
possono riscontrare pattern che si ripetono:
$\bullet$ Broker : si tratta di un gestore unicato per le connessioni. Viene quindi
utilizzato per impedire che tutti i server utilizzino le risorse inutilmente,
`
per esempio. E quindi un front end, in grado di ricevere le richieste dal
client e attivare (mediante i pattern descritti prima) i server necessari.
$\bullet$ Life cycle manager : si tratta di un sistema per poter gestire la vita degli
oggetti ad un livello superiore, applicativo proprio per la QoS (esempio:
gestione dei nodi, per privilegiare certe entit` rispetto ad altre, passivando
a
server meno prioritari!) Si hanno quindi politiche denibili dierenziate!
$\bullet$ Custom marshaller : ` un sistema per fornire sistemi dierenziati per la
e
presentazione dei dati (XML o formato binario: leggibilit` o ecienza
a
. . . ).
$\bullet$ Sistema a plug-in: si tratta della possibilità di estendere il mw, introa
ducendo dei gestori per azioni particolari di determinati protocolli (per
esempio, per eseguire certi compiti prima dell'invoke nale).25
$\bullet$ Il mw può anche gestire insiemi/gruppi di oggetti, fornendo quindi un
o
supporto alla replicazione (gruppi diversi, QoS diversa).
$\bullet$ Presenza di pseudo-oggetti : non sono oggetti veri e propri, ma entit` speca
icate dal mw, quindi oggetti accedibili normalmente ma che non hanno
interesse da un punto di vista applicativo (un esempio di pseudo-object
potrebbe essere il sistema di nomi!).
25 Possono sembrare simili agli interceptor, ma ` dierente il ruolo: questi son presenti per
e
la singola invocazione del singolo oggetto, mentre un plugin ` un componente per la parte di
e
supporto
61
\section{CORBA}
CORBA ` uno standard, specica di un mw, nato dall'idea di mettere a dispoe
sizione di 440 aziende una possibile soluzione per le loro esigenze!
Essendo uno standard, quindi solo una specica cartacea, si ha che esistono
diverse implementazioni (IBM, Java, Orbix, Jacorb, . . . ), ma che rispettando le
speciche possono anche essere interoperabili fra di loro!
Un mw deve avere oggetti remoti, invocabili da diversi client su diverse macchine: il sistema di supporto deve essere
quindi in grado di ottenere tutti i servizi
conosciuti da parte del client. Si ha quindi una forte idea di razionalizzazione,
l'obiettivo ` superare tutti i problemi dell'eterogeneit` (in CORBA: supporto
e
a
per linguaggi ed ambienti diversi, denizione di interfacce per servizi e supporti
per gli oggetti, . . . ).
CORBA in particolare basala sua architettura sulla presenza di un broker,
detto Object Request Broker : ` infatti l'incarnazione di tutta l'architettura,
e
perché fornisce il supporto alla comunicazione, il controllo degli oggetti, facilita
e
la comunicazione, ed alloca gli oggetti. . . ), ovvero ` il bus per l'interconnese
sione!26 Una caratteristica importante degli ORB ` che ` prevista la possibilità
e
e
a
di coordinarli, grazie alla denizione di uno standard preciso (non dipende quindi dalle varie implementazioni!). In
questo modo, tutti i servizi riconosciuti da
un ORB saranno riconosciuti da un altro, magari introdotto in un secondo
momento27
CORBA ` un mw maturo, che presenza diversi servizi: per esempio vi sono
e
le common facilities, che sono dei servizi utili per poter aiutare tutte le possibili
applicazioni, in grado di fornire risposte ad esigenze speciche. Corrisponde in
tutto e per tutto al terzo livello dei mw.
I servizi veramente importanti, necessari e presenti in ogni implementazione
sono gli object (o CORBA) services, che permettono di fornire servizi utili per gli
oggetti (il loro trasporto, la funzione di narrowing, . . . ). Fra quelle fondamentali
vi sono:
$\bullet$ Servizio di nomi : rispetto a quello denito per Java RMI, ` molto più coe
u
ordinato, e presenta anche delle varianti. Infatti, oltre al normale servizio
di nomi (per cui si deve conoscere il nome logico del servizio) vi ` anche la
e
possibilità di definire un servizio di trading, che funziona come le pagine
a
gialle, ricercando servizi e non nomi!
$\bullet$ Event e notication: sono sistemi meno orientati agli oggetti, ma che
quindi aumentano le capacità del sistema! Infatti, oltre alla maniera sina
crona/asincrona bloccante, in questo modo si possono introdurre sistemi
molto più essibili.
u
26 Tuttavia, CORBA resta solo una specica: come debba essere fatto il deployment
dell'ORB ` in realt` a carico delle singole implementazioni
e
a
27 Questo servizio per esempio ` più potente del servizio di nomi dei WS, che ` solo locale
e u
e
62
Altri servizi possono essere specici a determinati domini lavorativi, altri potrebbero invece dipendere dal tipo di
applicazione che si sta sviluppando.
Una caratteristica che ` stata sempre trascurata ` la sicurezza: questa per`
e
e
o
` introducibile, visto che CORBA prevede la possibilità di utilizzare degli intere
a
ceptor !
CORBA ` denito da una serie di componenti: oltre all'ORB (uno dei
e
principali), vi sono:
$\bullet$ L'IDL, ovvero un linguaggio per definire le interfacce dei servizi.
$\bullet$ Il Portable Object Adapater : si tratta di un sistema per incapsulare gli
oggetti e per facilitare il compito del gestore (nel trasporto, nel supporto
`
alla QoS, . . . ). E un sistema che viene aggiunto quindi dal supporto!
$\bullet$ L'Interface Repository, che ` un sistema simile ad un name server, dove si
e
possono ritrovare appunto le interfacce dei servizi disponibili.
$\bullet$ Vi sono quindi dei sistemi per richiamare i servizi in maniera statica e
dinamica
$\bullet$ E inne vi sono degli appositi protocolli per la comunicazione ed integrazione fra ORB diversi.
\subsection{L'ORB}
L'ORB ` il cuore del sistema, per comunicare si usa sempre l'ORB. Si potrebbe
e
quindi pensare che ` un collo di bottiglia, ma in realt` la comunicazione presente
e
a
in CORBA ` sempre a {`}grana grossa' (si passano oggetti, servizi pesanti): le
e
operazioni sono quindi consistenti, e la comunicazione si paga. L'ORB aiuta
fornendo diversi sistemi per facilitare il trasporto della richiesta da parte del
client al server, e la risposta lungo il percorso opposto. Si tratta, quindi, di base
di una comunicazione sempre sincrona.
In particolare, l'ORB gestisce i servitori, preoccupandosi di fare l'allocation
degli oggetti (` lui che deve trovare il server). In particolare, l'ORB permette
e
che un cliente si leghi ad un servizio, non ad un servitore! CORBA ` pensato
e
infatti per essere da supporto ai sistemi legacy: non interessa chi serve, ma
cosa serve! Fornisce quindi un supporto continuo, e sfrutta tutti i sistemi che
verranno descritti in seguito (POA, interface repository, . . . ).
\subsection{L'IDL}
Il linguaggio per le interfacce ` fondamentale per poter definire il contratto che
e
si vuole realizzare (quindi la descrizione di tutti i servizi da orire). Questo
contratto sar` quindi incorporato nei vari proxy, ovvero sar` poi compilato nei
a
a
linguaggi specici di implementazione!
`
E mediante IDL che si stabiliscono tutti i collegamenti necessari, e anche
l'ORB lo sfrutta per individuare il servizio (si lavora quindi ad un livello più
u
63
alto dell'implementazione: l'IDL stesso non ` legato a nessun linguaggio di proe
grammazione (deriva dal C++ come specica, ma ` diverso)). Una connessione
e
statica fa in modo che il proxy del client (lo stub) contenga l'IDL, con cui ci
si interfaccia all'ORB. Questi cerca il servizio descritto dall'IDL, propone la
richiesta in maniera adeguata usando un Object Adapter, e riporta quindi la
risposta al client.
L'IDL ` fondamentale per realizzare le connessioni statiche 28 , che sono molto
e
usate in CORBA (quelle dinamiche, per quanto orano un servizio con maggiore
QoS, sono molto costose). L'IDL denisce (` solo un sistema dichiarativo! un
e
sistema perché il compilatore scelto realizzi quindi uno stub e skeleton statici
e
(si può sfruttare per realizzare uno skeleton dinamico on the y mediante un'ino
vocazione dinamica del servizio, aggiungendolo al servitore!). Senza un servizio
di invocazione dinamico, non si può trovare un servizio se non ` stato denito
o
e
un contratto (ovvero, ` stato denito all'interno dell'interface repository!).
e
IDL resta per` sempre e solo una specica: sar` sfruttato dai compilatori
o
a
delle varie implementazioni per creare realmente gli oggetti e i servitori. Infatti,
serve solo come specica delle operazioni possibili.
Stub e skeleton son necessari per fare le operazioni di marshalling ed unmarshalling. Si ha che si realizza un diverso
proxy (quindi stub e skeleton) per ogni
interfaccia che si denisce.
Da ribadire: ` denito un contratto statico fra client e servizio, ma non un
e
binding statico fra client e servitore!
CORBA non ore altro agli utenti: le interfacce sono gli unici oggetti manipolabili e visibili, e quindi quando si
programma si riferiscono altre interfacce!
L'IDL di CORBA denisce in maniera automatica i metodi di accesso alle
propriet` dell'interfaccia, ed ` in grado di fornire delle informazioni sul coma
e
pletamento corretto o meno dell'operazione. Si possono quindi definire (come
in qualunque altra interfaccia) attributi, operazioni ed eccezioni. Le interfacce
si possono ereditare, anche in maniera multipla, e si possono raggruppare in
moduli logici coerenti.
Di particolare interesse, nei tipi, ` la possibilità di definire attributi di tipo
e
a
ANY : un attributo di tale tipo può essere sia un valore che un riferimento. Fono
damentalmente funziona come da contenitore, in grado di fornire informazioni
su cosa contiene! Nell'ultima versione di CORBA, 3, si ` stabilito che gli
e
oggetti devono essere passati by-value, in maniera da superare correttamente
l'eterogeneit`.
a
Restano comunque problemi nel realizzare un mapping corretto fra l'IDL e
i vari linguaggi di implementazione! Per esempio, Java non prevede parametri
28 IMPORTANTE: per legame statico si intende dire solo l'interfaccia, che viene quindi
denita in maniera statica. Il binding fra client e servitore non ` statico, qui si specica solo
e
che i servizi del servitore devono essere specicati in maniera statica
64
di output. Per ovviare a questi problemi, CORBA realizza delle apposite classi dette holder : ` un wrapper che permette
di leggere e scrivere in maniera
e
coerente al linguaggio utilizzato realmente. Si possono anche determinare automaticamente altre classi d'aiuto dette
helper, in maniera da armonizzare i dati
rispetto a CORBA (narrowing) e di fornire diverse funzioni di varia utilit`.
a
\subsection{Gli Object Adapter}
Gli adattatori sono diventati dei componenti quasi più importanti dell'ORB
u
stesso, visto che sono gli abilitatori del servizio stesso. L'ORB si preoccupa di
crearlo ed abilitarlo, mediante diverse politiche specicabili.
A cosa serve quindi? A superare le disomogeneit` e dierenze che vi sono
a
fra le varie implementazioni degli ORB, dovute appunto all'eterogeneit` (per
a
esempio, riuscendo a far colloquiare linguaggi non tipati con quelli tipati!).
Questo sistema permette di disaccoppiare in maniera corretta l'ORB dall'implementazione del servizio stesso: l'ORB lo
sfrutta, ma ci pensa l'adattatore a
richiamarlo in maniera corretta a seconda della sua implementazione. L'adattatore riesce quindi ad integrare più
componenti scritti in linguaggi diversi! Senza
u
un adattatore, l'ORB non riuscirebbe a raggiungere il proxy del servitore, senza
avere conoscenza della sua logica implementativa.
Inizialmente, lo standard prevedeva dei BOA, che erano delle implementazioni più semplici. Ora gli adattatori sono in
grado di fornire servizi diversi a
u
server diversi!
\subsection{L'Interface repository}
Si tratta del luogo dove vengono depositati gli IDL, e quindi da dove si possono
recuperare le informazioni degli unici servizi utilizzabili nell'architettura!
Questo sistema non ` utilizzato nella gestione statica dell'architettura, ma
e
in quella dinamica. Infatti, ` ricavando l'IDL dall'IR che si può realizzare un
e
o
binding dinamico, e quindi permettere di aggiungere in maniera dinamica dei
servizi ad un servitore/cliente.
Un IR può essere realizzato in diversi modi, tuttavia ` previsto che ogni
o
e
interfaccia correttamente compilata ed inserita, venga depositata in un'apposita
struttura ad albero, in base ai moduli che la contengono.
\subsection{Protocolli per la comunicazione fra ORB}
Inizialmente, CORBA era stato progettato per scambiare dati binari, in maniera
da ottenere un'ottimizzazione della comunicazione. In seguito si sono introdotte
estensioni come la possibilità di lavorare in Internet fra diversi ORB, o anche di
a
realizzare comunicazioni fra ORB diversi con protocolli più generalizzati.
u
Il problema di utilizzare ORB diversi ` per` la gestione di riferimenti remoti
e
o
fra ORB diversi ! Il servizio si sa che non ` legato allo specico servitore, quindi
e
65
si dovr` trovare un sistema di rendere questi riferimenti globalmente unici (e
a
qual è il loro tempo di vita?).
e
\subsection{Cosa ` e cosa non ` CORBA}
e
e
CORBA ` un sistema pesante, quindi non ha senso utilizzarlo per progetti
e
semplici o dove le operazioni son semplici (tipo, settare il valore di una singola
variabile). CORBA infatti sfrutta risorse a grana grossa, che non si muovono!
Il problema di CORBA ` infatti che se l'ORB non funziona (o la macchina che
e
lo contiene non ` raggiungibile) tutta l'architettura ` oine!
e
e
CORBA non ` un ambiente di linguaggio, cio` non crea lui gli oggetti. L'ate
e
tivazione degli oggetti, la loro politica di gestione ` tutta a carico degli Object
e
Adapter, che variano in base all'implementazione! Non vi ` quindi uno stane
dard, ` il POA a decidere come/se salvare lo stato, . . . Infatti, i servant sono
e
delle entit` passive, a cui il POA porta la richiesta del client e da cui richiede
a
la risposta corrispondente!
CORBA fondamentalmente richiede la presenza di un riferimento remoto
per poter lavorare: le funzioni base di CORBA sono quindi quelle di gestione e
comunicazione dei riferimenti remoti (trasformazione da/a stringa).
\subsection{Confronto fra Java e CORBA, e sua evoluzione}
I due sistemi sono abbastanza compatibili, proprio perché hanno obiettivi diversi
e
(Web invece che integrazione di sistemi legacy) e lavorano utilizzando risorse
diverse (a grana ne vs grana grossa).
CORBA ha subito diverse evoluzioni, guidate dalle esigenze delle varie aziende.
Ogni evoluzione ha mantenuto i sistemi e gli oggetti gi` introdotti, cercando di
a
estendere i concetti gi` introdotti (introducendo nuovi linguaggi, aumentando i
a
servizi, . . . ). Per esempio, CORBA 3 introduce altri sistemi di comunicazione
oltre alla maniera sincrona bloccante.
\subsection{Invocazione statica}
`
E il modello base, ed ` anche quello maggiormente utilizzato: permette solo una
e
comunicazione di tipo sincrona bloccante29 . Si basa sull'utilizzo di due diversi
proxy dal lato del client e del server (stub e skeleton). L'attivazione del servitore
per` ` dinamica: se non ` presente, il POA si preoccupa di attivarlo.
oe
e
L'invocazione statica bloccante ` quella che costa di meno (semantica ate
most-once), per` può anche essere molto limitante. Questo perché i client e
o
o
e
i servant devono avere gi` deciso i proxy in maniera statica, e quindi anche i
a
servizi! Tutto prima dell'esecuzione!
Inizialmente si era introdotta anche un altra modalit`, detta one-way, ma `
a
e
deprecata (semantica best-eort, senza possibilità di introdurre QoS).
a
29 Da ricordare che statico non signica che il client ` legato allo specico servant, ma che il
e
contratto ` deciso prima dell'esecuzione
e
66
\subsection{Compiti e politiche di un adattatore}
Non ` un componente CORBA, ma che dipende dalle varie implementazioni:
e
il loro compito ` quello di dialogare con il servant, il quale si registra presso
e
l'adattatore corrispondente. In un certo senso, quindi, fanno le veci di un sistema
di nomi, fornendo ai servant anche le risorse dinamiche necessarie.
La semantica degli adattatori ` sempre sincrona. Vi sono diverse modalit`
e
a
d'attivazione iniziali:
$\bullet$ Thread per request: per ogni richiesta l'adattatore30 si preoccupa di creare
un thread, quindi si ha una creazione by-need. Ha quindi un costo abbastanza elevato.
$\bullet$ Pool di thread : I thread sono pre-creati, in maniera da ridurre il costo
d'attivazione (consumano poche risorse se non lavorano). Si deve quindi
prevedere una coda delle richieste, per poter associare ad ogni richiesta un
suo thread.
Si potrebbe realizzare un pool dinamico, in grado quindi di estendere la
sua dimensione in base all'esigenze che si riscontrano durante l'esecuzione.
Il costo ` più limitato, ma aumenta il tempo d'attesa.
e u
$\bullet$ Thread per sessione: ` un sistema per fornire un maggiore accoppiamene
to. Si trasferisce infatti la responsabilit` sul client, permettendogli quina
di di battere sullo stesso servant rispetto alla sessione. Si hanno quindi delle richieste sequenzializzate. Questo
sistema limita ulteriormente il
parallelismo.
$\bullet$ Thread per servant: ogni oggetto viene incapsulato in un singolo servant,
per cui si limita ulteriormente la parallelizzazione. Prima di poter servire
un'ulteriore richiesta, il servant deve concludere la richiesta precedente.
Si hanno dei problemi da considerare nel caso di ORB distribuiti: infatti, si
immagini che si passi un riferimento remoto ad un client da un ORB diverso,
utilizzando come modello il thread per sessione. CORBA dice che ` possibile
e
mantenere le stesse politiche anche se si passa il riferimento all'esterno, ma
in realt` si potrebbe avere che un client diverso utilizzi delle politiche diverse
a
(potrebbe non essere necessario, per limitare i costi, costringere il client ad utilizzare lo stesso servant). Si hanno
cos` meno garanzie (non mantengo la stessa
\i{}
politica), ma si ottengono anche dei costi limitati. Si potrebbero anche avere
politiche diverse fra ORB, dovuto tutto ad implementazioni diverse!
Gli adattatori devono quindi garantire certte funzionalit`, e nel corso del
a
tempo ` diventato sempre più un componente centrale dell'architettura. Cone
u
trollano l'esecuzione delle operazione, forniscono un sistema per cui l'ORB non
si preoccupi realmente dell'implementazione, ma per cui può semplicemente
o
`
portare la richiesta al servant e riportarne indietro la risposta. E il POA a
30 Sono
gli adattatori che devono fornire le politiche!
67
decidere quindi le politiche d'attivazione e il numero di servant necessari per
l'esecuzione!
Inizialmente si aveva i BOA: questi erano legati a poche interfacce, e ad un
unico ambiente di linguaggio. I POA sono un'estensione, aggiungendo funzionalit`, potendo interagire con servant dotati
di interfacce e linguaggi diversi: da
a
qui la denizione di portable! Non abbiamo infatti una chiara indicazione della
sua locazione.
CORBA ` stato il primo standard che ha cercato di realizzare un sistema
e
mw per gli oggetti attivi: un riferimento ` quindi in grado di puntare potenziale
mente a più oggetti: un POA riceve il riferimento e deve accedere all'oggetto
u
desiderato. In generale, meno POA son presenti e meglio `: infatti, le varie
e
implementazioni forniscono un POA di base, che contiene tutte le politiche di
gestione gi` denite. Un suo glio non eredita direttamente tutte le politiche, ma
a
deve essere specicato quali politiche si vogliono attivate: abbiamo quindi in realt` un gestore per i POA, che
stabilisce per ogni POA quante e quali politiche
a
debba implementare (attiva/disattiva i POA, blocca/scarta le richieste per i
POA). Si potrebbe permettere all'utente di modicare dinamicamente l'active
object map, ma ` fatto di rado.
e
Essendo il responsabile dell'oggetto, il POA ` responsabile anche del suo
e
riferimento. Deve essere in grado quindi di denirlo, identicare gli oggetti in
base all'ID proposto e gestire i servant. In particolare, deve riuscire a distinguere
fra oggetti transienti e quelli persistenti.
Quali sono quindi le politiche d'attivazione per gli oggetti? Possiamo avere:
$\bullet$ Explicit Object Activation: ` tutto a carico del client
e
$\bullet$ Single servant: viene attivato un servant per ogni richiesta, uno solo.
$\bullet$ On demand : sono le politiche per poter scegliere i servant in base alle richieste specicate. Se si tratta di
un singolo metodo non vi ` stato, altrimene
ti si tratta di On-demand per una durata indenita. Una caratteristica
particolare ` che le politiche si possono combinare!
e
\subsection{Binding dinamico}
Avendo a disposizione prima le interfacce, si possono implementare direttamente client e servant. Tuttavia, ` mediante
l'invocazione dinamica con cui
e
si possono aggiungere nuovi servizi durante l'esecuzione. L'alternativa sarebbe
dover spegnere il sistema, e ricongurare il tutto. La dinamicit` si basa sull'uso
a
dell'IR, e permette di introdurre in CORBA altri modelli di comunicazione oltre
al sincrono bloccante.
Si vuole quindi chiedere o fornire un servizio senza avere il proxy/skeleton
`
gi` pronto. E un problema di tutti i mw.
a
Nel caso del client, si parla di Dinamyc Invocation Interface. Si realizza un
oggetto che funziona come il proxy che si avrebbe avuto in maniera statica. Si ha
68
quindi un oggetto Request, che ` uno pseudo-object 31 , che permette di specicare
e
una richiesta dinamica. Si tratta quindi di un contenitore fornito dall'ambiente,
per cui un client eettua una invoke, e l'ORB utilizza il servant giusto per
richiamare l'operazione e fornire il risultato. Si potrebbero realizzare tutte le
operazioni dinamiche, ma hanno un costo molto elevato! Tuttavia, vi sono
diversi modi per ottenere il risultato, non solo in maniera sincrona bloccante
(utilizzando la GetAnswer), realizzando quindi delle operazioni maggiormente
disaccoppiate. Si deniscono quindi la:
$\bullet$ Send-deferred per realizzare un sistema sincrono non bloccante. Si utilizza
un sistema basato su un oggetto poll-response.
$\bullet$ Send-one-way invece per avere una comunicazione asincrona.32
Ma come funziona? L'oggetto Request,opportunatamente costruito dal client
(dati, eccezioni, . . . ), passa per l'IR, sfruttandolo proprio come un name server: lo interroga per sapere quale
servant possiede quel servizio (quindi non si
richiede che il servant sia dinamico!). Quindi, l'oggetto Request deve essere particolarizzato in maniera opportuna
dall'utente, in maniera da ottenere l'oggetto
desiderato (ridotta trasparenza!).
CORBA introduce anche la possibilità di estendere dinamicamente i servizi
a
oerti da un servant (` meno utilizzato). Come fare ci` in realt` non ` spiegato
e
o
a
e
(si potrebbero attivare in maniera dinamica): CORBA si preoccupa di standardizzare le interfacce. Se si avesse un
sistema solo statico, si avrebbe che si
dovrebbe spegnere il sistema e aggiornare staticamente i servant.
Nel modello dinamico (Dinamyc Skeleton Interface) si ha invece che ` pree
sente un altro tipo di pseudo-object detto ServerRequest, mediante il quale si può
o
specicare le operazioni, parametri e contesti da aggiungere! L'idea ` che queste
e
informazioni si debbano agganciare ad un'interfaccia che esiste gi`. Quindi, ci
a
si collega all'IR per ottenere un'implementazione gi` presente, e ci si registra
a
presso l'IR come sistema in grado di rispondere (il servant si potr` usare sia in
a
richieste statiche che dinamiche!).
\subsection{Politiche dei riferimenti di CORBA}
CORBA si basa totalmente sull'uso degli ObjRef. CORBA fornisce quindi dei
sistemi/funzionalit` di base (per realizzare un primo supporto, da estendere a
a
seconda della QoS desiderata) per trattare in maniera opportuna i riferimenti
(da string a riferimento o viceversa, funzioni di narrowing, duplicazione/release
dell'oggetto). Gli ObjRef sono opachi e gestibili solo dall'ORB.
La politica per` che persegue CORBA ` che il riferimento punti al servizio,
o
e
non al servitore: tuttavia, questa logica potrebbe non essere quella desiderata dal programmatore (si vorrebbe poter
accedere sempre allo stesso servant
31 Si tratta di facilitatori, connati solo nell'ORB. Non si possono quindi riferire da CORBA,
e non possiedono helper o holder
32 Qual'` il problema di lavorare in maniera dinamica? E che si possono avere errori a
`
e
run-time, che sono più dicili da gestire!
u
69
sico). Ma quindi questi riferimenti non sono univoci: localmente si potrebbe
anche puntare ad oggetti diversi, realizzando quindi incomprensioni e problemi
(specialmente lato server)!
In CORBA 2 si ` quindi introdotta la possibilità di puntare ad uno servant
e
a
specico, introducendo quindi un sistema per definire dei nomi univoci !
\subsection{Interoperabilità fra ORB}
a
Per poter realizzare le comunicazioni fra ORB diversi, si ` dovuto quindi reale
izzare degli ObjRef interoperabili : questi sono gli IOR. Hanno un costo pesante
a livello di implementazione, soprattutto perché una volta stabilito, deve essere
e
valido in eterno!
Gli IOR facilitano le gestioni degli ORB: si ha che se si registrano client/server
e si vogliano riferire in remoto attraverso una rete di ORB, si denisce uno IOR
sempre valido. In generale adesso gli oggetti in CORBA non sono mai deallocati
automaticamente (potrebbe farlo), ma ` tutto a carico dell'utente. Se si utilizza
e
uno IOR!`, l'oggetto deve essere sempre presente!
Uno IOR ` costituito da una serie di informazioni per renderlo univoco: il
e
nome/indirizzo del nodo su cui risiede, un timestamp, il nome del POA che lo ha
creato ed altre informazioni. Si realizza quindi in generale uno IOR incapsulando
in maniera opportuna un ObjRef.
Caratteristica importante degli IOR ` che non ` detto che puntino direte
e
tamente ad un adattatore, ma possono anche riferire invece un altro repository, ovvero quello degli oggetti
implementati! Si ha quindi la possibilità di
a
definire un legame indiretto oltre a quello diretto: la dierenza sostanziale `
e
che l'oggetto riferito indirettamente ` veramente permanente, mentre riferene
dolo direttamente si hanno più gradi di libert`, un collegamento maggiormente
u
a
lasco. L'ObjId di uno IOR riferisce quindi il servizio sicuramente, ma non `
e
detto l'oggetto.
\subsection{Gli interceptor in CORBA}
Sono deniti come negli altri mw, ovvero ` un sistema per poter definire dei come
ponenti che devono essere attivati prima o dopo l'esecuzione di una determinata
richiesta (per introdurre per esempio un sistema di sicurezza). Gli interceptor
son pensati per poter lavorare a diversi livelli (applicativo, trasporto, . . . ).
\subsection{Estensibilità di CORBA}
a
CORBA ` pensato per essere facilmente estensibile. In particolare, CORBA
e
3 introduce l'uso di componenti, la possibilità di definire QoS, e un supporto
a
anche ad Internet come ambiente di lavoro.
I componenti non sono altro che degli oggetti inseriti in un apposito contenitore, ed inseriti in un apposito ambiente
d'esecuzione, detto engine. Il servizio
di questi componenti ` quindi fornito soltanto nell'ambito del container stesso,
e
70
sfruttando delle politiche di default denite proprio dal contenitore. Un esempio
di componente di questo genere sono gli EJB.
I componenti sono un fattore trainante per ottenere una base d'utenza sempre più ampia: aumenta la possibilità di
adattare il sistema alle proprie esigenze.
u
a
Con CORBA 3 in particolare si ` intodotto il sistema dell'Asinchronous
e
Method Invocation, che ` un ulteriore modo per definire una comunicazione
e
sincrona non bloccante: il cliente non deve attendere quindi per il risultato.
Si ottiene cambiando solo l'interfaccia, per cui si delega un altro oggetto per
attendere la risposta, separando la fase di richiesta da quella callback. Tuttavia,
` necessario che sia il cliente a specicare il codice della callback da eseguire.
e
Inoltre, si può anche definire che il client recuperi il risultato usando un pollo
object. Nel caso di call-back quindi si utilizza un sistema di re and forget. In
entrambi i casi si lavora solo dal lato del client, per estendere la funzionalit`.
a
Il servant continua a lavorare in maniera sincrona bloccante! Ci` che cambia
o
oltre a chi richiama il metodo (nel primo caso ` l'ORB, nel secondo ` il client),
e
e
l'interfaccia ` leggermente diversa: nel poll i parametri necessari sono di out!
e
Questo genere di interazione ` molto diusa, perché permette di richiedere
e
e
contemporaneamente molte {`}istruzioni'.
\subsection{Servizi già presenti in CORBA}
a
Come gi` detto, CORBA fornisce diversi servizi gi` utilizzabili.
a
a
Per esempio, per realizzare un servizio di nomi si possono usare il naming
service gi` presente, oppure addirittura un trading service. La dierenza fra
a
i 2 sistemi ` che il name service permette di categorizzare i servizi in base ad
e
un nome logico (si fornisce il nome logico, si ottiene il riferimento al servizio),
mentre il trading service fornisce un sistema simile a quello delle pagine gialle,
per cui i servizi sono catalogati in base al loro contenuto. In questo caso si
ricerca quindi per chiavi: a default vengono forniti tutti i servizi, ma vi ` la
e
possibilità di ltrare i risultati, per ridurne il numero.33
a
In entrambi i casi si può pensare (a dierenza di Java RMI) di realizzare
o
dei sistemi federati, ovvero una gerarchia di name o trader server federati, in
maniera di essere coordinati!
Un altro servizio che viene fornito ` quello di poter lavorare ad eventi e
e
notiche: questi infatti non sono strumenti propriamente tipici del modello ad
oggetti, che possono essere sfruttati per realizzare facilmente architetture con
molti clienti e produttori; non ` quindi P2P, ma una comunicazione molti a
e
molti.
CORBA stabilisce delle apposite interfacce, denendo mediante ognuna il
modo di comunicare (push dal produttore, pull dal consumatore, . . . ). Si
denisce un canale come oggetto di delega, per poter inviare i messaggi ai
33 Non
si ricercano ovviamente interfacce, perché presenti sull'IR
e
71
client, o fare polling ai supplier. Un client si registra quindi al canale, e da
quel momento comincia a ricevere gli eventi.
Di solito, non ` noto chi ` che genera l'evento, ` trasparente al consumatore.
e
e
e
Gli eventi sono non persistenti, senza qualit`, e senza possibilità di ltraggio: si
a
a
ha che quindi la maniera più comoda per lavorare ` il sistema push, e per avere
u
e
QoS conviene utilizzare il notication service, che ` in grado di fornire qualit`
e
a
e persistenza!
\section{COM, DCOM e .NET}
Nell'architettura Microsoft, la GUI ` sempre stata fondamentale (la nestra non
e
` solo un elemento graco, ma ` tutto ci` a cui ` costruito attorno il sistema;
e
e
o
e
`
l'interazione fra i processi ` guidata dalle nestre!). E da loro che ` nata l'idea
e
e
di dinamyc library, cio` di una libreria che si potesse caricare solo su bisogno:
e
idea molto dinamica, che per` richiede il costo del caricamento.
o
Ma quindi, visto che le DLL si possono caricare/scaricare a piacimento, i
processi non possono avere uno stato, specialmente se condividono codice, cos`
\i{}
da aumentare al massimo la condivisibilit`. Il kernel Microsoft ` un microa
e
kernel, proprio sfruttando le DLL (si caricano sempre e solo quelle necessarie).
Si utilizza un sistema di conteggio dei riferimenti per decidere se deallocare una
DLL.
Le DLL sono quindi ascrivibili in 3 diversi gruppi: kernel, utente (windowing) e GUI. Il sistema ` per` facilmente
estendibile, potendo introdurre nuove
e
o
DLL (es, WinSocket).
Nei sistemi operativi Microsoft tutti i tipi di oggetti (sia utente che kernel)
possiedono degli appositi handler per riferirli ed identicarli, in maniera tale da
poterli utilizzare anche con le apposite API di Windows. A dierenza di Unix,
l'interfaccia per richiamare gli oggetti non ` molto compatta, risultando essere
e
molto complessa.
Windows fa un uso pesante del modello ad eventi (il sistema graco fa un
buon match con ci`). Si tratta di un modello fortemente push (all'epoca era
o
anche l'unico modello esistente per lavorare quando non si avevano ancora i
processi). Gli eventi vengono usati ancora anche a livello applicativo: a livelli
inferiori risultano essere molto più essibili, sfruttando il modello a call-back:
u
l'applicazione fornisce un handler/funzione da richiamare nel caso si presenti
l'evento alla DLL opportuna34 . L'evento ` lanciato da una qualunque intere
azione dell'utente o presso una periferica esterna, e viene lanciato a tutti quelli
che lo necessitano (ogni programma ha una sua coda per gli eventi).
Un'altra tecnologia importante introdotta dalla Microsoft ` il cosidetto Obe
ject Linking and Embedding, per cui si vuole gestire le applicazioni in maniera
34 Quindi
ogni nestra registra per ogni evento un possibile handler!
72
integrata. L'idea ` quella di suddividere correttamente i compiti fra il docue
mento ed il gestore del documento. Ogni tipologia di documento, infatti, ha un
proprio gestore che viene richiamato all'atto del caricamento del documento.
Tuttavia, un documento può essere fatto di diverse parti, ovvero di altri
o
documenti: si deve quindi anche caricare il gestore degli altri documenti di cui
` composto. In particolare si può avere che:
e
o
$\bullet$ Il documento contiene un riferimento all'altra tipologia di documento,
ovvero si fa linking
$\bullet$ Il documento contiene proprio una copia dell'altro documento, ovvero si
fa embedding. Quest'ultimo caso non ` realizzabile direttamente con il
e
modello ad oggetti!
Mediante questa tecnologia si può quindi attivare un'applicazione all'interno
o
dell'altra: vi possono essere problemi di duplicazione dell'oggetto o la presenza
di riferimenti multipli e di molteplici gestori della stessa tipologia di documento
(quanti ne attiviamo?). Tuttavia, nel concentrato non presenta grossi problemi
e funziona bene.
L'idea della Microsoft era per` quella di estendere il concetto di OLE anche
o
al distribuito, da qui la tecnologia COM. Nel concentrato era tutto più semplice
u
perché si sfruttava il registry di Windows per identicare in maniera univoca un
e
oggetto35 , e per poter registrare quindi i vari gestori.
\subsection{Architettura COM}
COM ` stato il sistema standard per la Microsoft per poter descrivere l'intere
azione fra processi diversi, utilizzando come base i componenti e una comunicazione C/S sincrona. Si può notare la
dierenza con i precedenti modelli: nei
o
sistemi precedenti la comunicazione si basava soprattutto sul modello ad eventi,
che ` molto lontano dalla comunicazione sincrona!
e
Lo standard denisce delle speciche per cui i componenti siano in grado
di comunicare fra di loro, in maniera indipendente dal linguaggio utilizzato e
dalle applicazioni che li usano. L'idea ` quella di introdurre una uniformit` nel
e
a
comportamento: dll, componenti su macchine diverse, . . . Si ottiene cos` omo\i{}
geneit` a livello di comportamento fra oggetto locale e remoto, introducendo
a
cos` trasparenza. In particolare, si utilizzano metodi standard per la comuni\i{}
cazione remota, come RPC di DCE.
Alla base di COM vi ` l'uso delle interfacce: un componente, per poter
e
essere usato, deve fornire un'interfaccia comune e conosciuta da tutti gli attori. L'interfaccia infatti denisce la
visione logica. Tutte le interfacce COM
derivano da una stessa interfaccia detta IUnknown. In COM ogni oggetto e ogni
interfaccia possono essere identicati in maniera univoca da dei GUID, che per`
o
distinguono anche fra componenti ed interfacce.
35 Sfruttando il GUID, derivato dall'UUID descritto dal DCE. In Microsoft, i diversi GUID
son classicati in base al tipo di oggetti che riferiscono (interfacce, classi, . . . )
73
L'interfaccia funziona semplicemente come un puntatore alle funzioni che descrive, contenute in una virtual method
table: ogni entry di questa tabella punta
al codice che i metodi devono implementare. In COM non esiste l'ereditariet`
a
a livello di classe ma solo (anche multipla) a livello di interfacce. Si ha quindi
un grafo che rappresenta l'ereditariet`, che spesso ` dicile da navigare! I nomi
a
e
univoci sono infatti tutti registrati nel registry, a seconda della loro applicazione.
L'interfaccia IUnknown presenta solo 3 metodi (presenti sempre nei primi
3 slot di ogni VMT di ogni componente): uno per aggiungere un riferimento
all'oggetto, uno per farne il release, e inne un QueryInterface. Quest'ultimo `
e
fondamentale per poter interagire con l'oggetto stesso: prende infatti il GUID e
verica se esiste un oggetto che implementi quell'interfaccia. In caso aermativo,
si preoccupa di restituire un puntatore all'interfaccia corrispondente. Questo `
e
un metodo pervasivo, ` l'unico modo con cui accedere ai diversi metodi. Gli
e
altri infatti sono utilizzati per gestire le risorse in maniera dinamica.
La deallocazione degli oggetti può essere decisa: o si utilizza un garbage colo
lector, oppure si utilizza il sistema del reference counting, oppure si può anche
o
non gestire! Si può quindi osservare una dierenza rispetto a CORBA: qui `
o
e
necessario vedere come avviene l'interazione di basso livello! Si deve per forza
passare per il metodo QueryInterface.
In COM vi ` quindi solo l'ereditariet` in base alle interfacce: questo perché
e
a
e
l'ereditariet` all'epoca era vista come un sistema troppo accoppiante, e quindi da
a
limitare. Infatti, ereditando solo le interfacce non si eredita l'implementazione
ed eventuali comportamenti non desiderati. Fondamentalmente, l'ereditariet`
a
rompeva il principio dell'incapsulamento (la classe derivata infatti può accedere
o
alla classe base)!
COM quindi introduce due metodi alternativi per poter estendere una classe:
aggregazione o delegazione. In ogni modo, un oggetto non implementa tutti i
metodi che la sua interfaccia espone, ma {`}ridirige' la richiesta di controllo ad
oggetti che implementano quei metodi (in un qualche modo li incapsula).
La delegazione indica che fra gli oggetti vi deve essere una condivisione
del comportamento, ma non dell'implementazione (non vi ` l'obbligo di usare
e
la stessa implementazione). La delegazione fondamentalmente corrisponde ad
esplicitare il fatto che vi ` un altro oggetto che si preoccupa di rispondere
e
alla richiesta in maniera corretta. Questo ` un oggetto interno, che deve esere
e
sempre attivo, e puntato in maniera opportuna dalla VMT dell'oggetto esterno!
Si tratta sicuramente di uno dei fattori di maggiore complessit` dell'architettura
a
COM.
L'aggregazione invece gestisce il problema in maniera implicita, realizzando
quindi una serie di oggetti aggregati. Non ` come prima, per cui l'interfaccia
e
esterna funzionava come un passacarte, ma si realizza come una copia dell'interfaccia dell'oggetto aggregato nella VMT
dell'oggetto esterno! Fondamentalmente, quindi, l'oggetto aggregato fornisce i propri metodi all'esterno, direttamente
nell'interfaccia dell'oggetto esterno! Anche questa maniera ` complessa,
e
più dell'ereditariet`. L'aggregazione ` consigliata per una gestione a parti (a
u
a
e
74
dierenza della delegazione, ogni oggetto si preoccupa di fare da gestore delle
richieste ai metodi che implementa).
\subsection{Interazione C/S in COM}
L'idea base ` che vi sia uniformit` di comportamento fra ogni tipologia d'oggete
a
to: non interessa quindi come ` fatto, ma la possibilità di poterci interagire in
e
a
maniera C/S trasparente. Il problema ` che il costo ` molto diverso in realt` a
e
e
a
seconda del tipo di oggetto con cui si prova a colloquiare (accedere ad una DLL
in maniera C/S ` molto più ottimizzato che accedere ad un oggetto remoto).
e
u
Quindi, a dierenza di CORBA36 , l'implementazione sottostante ` diversa a
e
seconda di quale tipo di oggetto si acceda
Un oggetto in COM, perché si possa riconoscere come server, deve fornire
e
la capacità di istanziare degli oggetti : in generale questo viene realizzato utiliza
zando delle Factory, che non son classi ma gestori d'entit`. Ogni Factory ha
a
una sua politica per l'attivazione (potrebbe per esempio realizzare un singleton,
fornendo il riferimento sempre alla sola copia attiva), ma i diversi meccanismi
devono restare nascosti.
Un server quindi implementa o l'interfaccia IClassFactory (oppure la sua
seconda versione, che permette di lavorare anche sfruttando un'apposita licenza dell'oggetto stesso). Queste interfacce
infatti deniscono un metodo per
creare un'istanza dell'oggetto, oppure di ottenere un riferimento all'oggetto gi`
a
esistente (CreateInstance). Questo metodo (e le sue varianti) devono quindi
esplorare il registry alla ricerca di un oggetto che implementa l'interfaccia ricercata; si può anche specicare un
contesto, ovvero spiegare dove si potrebbe
o
ricercare l'oggetto.
Esistono 3 tipi possibili di server in COM:
$\bullet$ In-process: lavora nello stesso spazio di lavoro del client, mediante un'apposita DLL.
$\bullet$ Locale: lavora in un processo diverso, ma sulla stessa macchina.
$\bullet$ Remoto altrimenti.
Il problema di COM ` che, volendo garantire un'alta trasparenza, richiedeche
e
vengano denite tantissime interfacce. Un'altra interfaccia ` per esempio COe
MOBJ, che si preoccupa di cercare nel registry l'esistenza delle DLL necessarie,
ne fornisce il riferimento o le carica in memoria. Questo comporta che l'utente debba conoscere i meccanismi presenti in
COM ! Fortunatamente, gli stessi
meccanismi funzionano anche lavorando out-of-process.
L'unica cosa che si aggiunge lavorando out-of-process ` la presenza di proxy
e
e stub per facilitare la comunicazione e realizzare la trasparenza alla comunicazione. Fra proxy e stub si stabilisce
quindi in maniera automatica un canale,
che permette ai due processi di comunicare fra di loro: ` comunque un'astrazione
e
36 Uso
perenne dell'ORB
75
(in locale si lavorerebbe utilizzando la memoria comune!). Per definire questi
componenti, si ` sviluppato un apposito IDL, MIDL. Questo deriva e rispetta
e
le speciche di DCE, ma risulta comunque essere incompatibile con altri IDL.
Come funziona quindi la comunicazione in COM? Si lavora per sequenza: si
tenta inizialmente di accedere alla risorsa in process, poi in locale, ed inne si
tenta in remoto sfruttando come meccanismo RPC. In certi casi, essendo poco
costosa, si utilizza RPC anche in locale, di tipo diverso e più leggera.
u
Per la gestione remota, vi ` anche la presenza di un ulteriore attore al livello
e
più basso detto Service Control Manager, che si comporta proprio come un mw!
u
Infatti, un proxy che volesse comunicare, si riferisce al SCMper ottenere un
riferimento all'oggetto remoto, e quindi può realizzare una RPC remota.Questa
o
architettura comporta quindi che SCM debba essere presente su ogni nodo, e
che proxy e stub debbano essere stabiliti prima, in maniera da poter conoscere
la posizione del SCM! Si potrebbe anche avere, tuttavia, che non vengano mai
usati se la risorsa ` disponibile in-process!
e
\subsection{DCOM}
DCOM nasce negli anni 90 come esigenza si introdurre anche in COM (come
in CORBA) l'interazione dinamica. In particolare, ci` che si introduce ` il
o
e
concetto di automation, ovvero la possibilità di fornire ad un client di poter
a
gestire oggetti per cui non aveva previsto l'interazione. Si tratta anche di un
modello realizzato per cercare di andare oltre al classico modello a code di eventi.
Inizialmente, automation nasce come possibilità per linguaggi dinamici (tipo
a
quelli di scripting per il Web) di poter accedere all'architettura COM. Questo
genere di linguaggi infatti spesso sono loosely-typed e studiati in maniera tale
da avere poco controllo. Prima di automation risultava dicile realizzare proxy
anche per questi linguaggi.
Quello che fa automation ` semplicemente la realizzazione in automatico di
e
una DLL che funzioni come intermediario fra i due mondi, fra COM e qualsiasi
altro lingaggio, se tale interazione non era gi` stata prevista in maniera statica.
a
Automation permette quindi di esplorare, in maniera automatica, un oggetto
la cui interfaccia ` sconosciuta a tempo di esecuzione. Automation incorpora
e
concetti gi` visti in OLE, come la in-place activation, per cui un gestore viene
a
attivato solo se ` necessario, cio` se ` richiesto da un sottocomponente. DCOM
e
e e
introduce anche altre tecnologie, come lo structured storage (tutto ` all'interno
e
di un singolo le) e un sistema di scambio dei dati unicato. DCOM introduce
soprattutto diversi strumenti proprietari Microsoft per il web, spesso incompatibili con altri strumenti.
Per introdurre la dinamicit`, un oggetto deve implementare anche l'interfaca
cia IDispatch, che ` riessiva, la base stessa di automation. Infatti, a dierenza
e
di CORBA, in COM-DCOM non vi ` un IR per registrare le interfacce: si tratta
e
quindi di interrogare ed invocare in maniera dinamica i componenti! Si tratta
di un sistema del tutto analogo alla Request di CORBA.
76
Quindi, alcuni metodi riportano informazioni sul componente (GetTypeInfo,
GetTypeInfoCount), altri preparano il client a richiedere l'invocazione (GetIDsOfNames) e inne vi ` un metodo per
invocare in maniera dinamica l'oggetto
e
stesso. IDispatch, essendo un'interfaccia COM, eredita direttamente da IUnknown. Possiamo cos` sostituire questa ed
altre interfacce, permettendo un'ese\i{}
cuzione sempre dinamica (ma costosa).
Si può quindi iniziare a parlare di componenti veri, che rappresentano un'esteno
sione degli oggetti: sono più pervasivi, garantendo di non avere limiti alla riusu
abilit` e possibilità di essere usati in un qualunque contesto, senza dover dipena
a
dere come gli oggetti da un determinato linguaggio.
A dierenza per` di CORBA, essendo la VMT ssa, non ` possibile realizzare
o
e
un server dinamico!.
\subsection{Interazione in DCOM}
COM era stato pensato per fornire una visione di alto livello uniforme (sempre
C/S), per cercare anche di rendere un'ottimizzazione molto forte a seconda
della comunicazione che si andava a realizzare. A basso livello invece si ha un
comportamento molto variegato, con un'alta idea di delegazione.
A sua volta, DCOM prevede di definire dei riferimenti diretti fra C e S,
facendo in modo quindi che si conoscano comunque, nonostante l'uso di un'interfaccia. Questi riferimenti quindi non son
persistenti.37 . DCOM si preoccupa
di aumentare la dinamicit`, cercando anche di andare oltre al C/S, ma fornendo
a
strumenti per trovare in maniera automatica la soluzione, fornendo supporto
alla portabilit`, cercando di dare una visione semplicata. Purtroppo, per reala
izzare ci` si ` dovuto ripensare l'architettura, mantenendo per` un sistema per
o e
o
integrare il sistema legacy precedente.
Quello che infatti succede ` che in automation le DLL diventano oggetti ade
hoc. Questi oggetti, riassunti ed estensioni, sono i cosidetti ActiveX. Includono
anche idee come OLE, ma restano molto complessi da realizzare, per cui `
e
necessario sfruttare degli appositi wizard. Sono quindi fondamentalmente dei
piccoli server OLE, in grado di attivarsi con il metodo della in-place activation,
ma con un comportamento diverso: infatti, lavorano in maniera inside out,
ovvero son sempre pronti, attivi, no a che l'oggetto contenuto ` presente. Si
e
tratta quindi di un sistema ad aggregazione sempre attiva (il componente interno
` sempre attivo).
e
\subsection{Standardizzazione dei componenti}
Un merito di COM e DCOM ` stato quello di fornire un primo tentativo di stane
dardizzare il concetto di componente. Prima si dovevano definire sempre diverse
37 Vi ` una losoa diversa rispetto a CORBA: qui ` necesario avere anche una visione di
e
e
basso livello, nonostante l'uso delle interfacce come in CORBA
77
interfacce, sempre utilizzabili dagli utenti, ma senza una razionalizzazione alla
loro realizzazione.
DCOM denisce per primo che un sistema a componenti deve definire un'architettura a PEM (Property, Event, Method ), per
poter definire stato, output
e input dei componenti. Questo sistema semplica la realizzazione, permettendo quindi di definire un container che sia
semplicemente un gestore degli oggetti
contenuti, in grado di attivarli attravero un'interfaccia uniforme e al sistema dell'introspezione. Il container deve
solo fornire un'interfaccia IDispatch! Quindi,
il container implementa la dispinterface denita dall'oggetto contenuto (questo
deve solo definire quali eventi sono interessanti per lui); uno ` la sorgente dele
l'interfaccoa, l'altro il pozzo che la realizza. A sua volta, il container sfrutta
degli oggetti intermedi per poter comunicare con l'oggetto contenuto.
DCOM stabilisce anche la possibilità di realizzare una persistenza del coma
ponente, implementando un'apposita interfaccia. (I riferimenti non son ssi in
DCOM).
\subsection{Gestori delle sottoparti: i monikers}
DCOM introduce i monikers come un sistema ad hoc, piuttosto complesso, per
poter gestire in maniera persistente la gestione degli oggetti. Questo sistema
aumenta la essibilit`, memorizzando su disco quindi i riferimenti agli oggetti,
a
categorizzandoli in base a cosa sono, e rendendoli indipendenti dalle applicazioni!
Si ha quindi che ogni moniker viene associato ad un programma, permettendo
anche di lavorare mediante nomi indiretti. Permette anche di moltiplicare i
meccanismi, aggiungendo diversi monikers.
\subsection{Modello a thread di DCOM}
Il modello deriva da quello di Win32. Tuttavia, vi possono essere dei problemi se certi componenti non risultano essere
thread-safe (magari perché sono
e
componenti legacy). Per superare questo problema, in DCOM si ` introdote
to il concetto di Apartment, che consiste ad un ambiente d'esecuzione isolato,
cio` con una politica di threading ssata. Vi sono due diversi modelli, o quello
e
single-threaded (più diuso, un unico componente lavora nell'apartment) opu
pure multi-threaded. Ogni componente può quindi avere più STA, ma sempre
o
u
un solo MTA.
\subsection{Altri strumenti DCOM}
Microsoft ha fornito mediante DCOM tantissimi strumenti, in grado di risolvere
i problemi sempre più nell'ottica di un moderno mw.
u
In particolare, si possono citare MSMQ per realizzare un sistema a scambio di
messaggi, e COM+ per permettere la denizione di componenti solo attraverso
la parte logica. Presenta anche un servizio X.500 di directory standard, detto
Active Directory.
78
\subsection{.NET}
Questa è la nuova architettura Microsoft, sviluppata ripensando totalmente il tutto! Non solo si è progettato pensando
ad un S.O. diverso, ma anche rivoluzione 
nando la stessa macchina virtuale (realizzando il CLR). Si tratta di un sistema
derivato e migliorato (sotto certi aspetti) da Java: Java infatti ormai presenta
dei sistemi legacy con cui deve far conto, per cui non può introdurre direttamente
o
nuovi aspetti senza rompere con il passato (non si può, per esempio, introdurre
o
un controllo dinamico delle risorse occupate da un thread, per denirlo anche a
run-time!). .NET realizza anche lui un compilatore JIT, denisce una serie di
classi base, rintroduce l'ereditariet` dell'implementazione, delle classi, e svilupa
pa un sistema a livelli molto simile a quello di un mw moderno, con diversi
servizi attivabili a basso ed ad alto livello.
In particolare, .NET introduce una forte idea di localit` sfruttando l'idea
a
dell'application domain: i processi non possono comunicare in maniera diretta
fra di loro, ma devono sfruttare dei protocolli DCOM compatibili (` un sistema
e
simile all'apartment), oppure WS o altre nuove tecnologie .NET. WS per esempio ` la tecnologia più costosa, ma anche più
vicina all'applicazione da un punto
e
u
u
di vista logico.
\subsection{.NET remoting}
Si basa comunque sull'idea di realizzare dei proxy per facilitare la comunicazione.
Tuttavia, vi sono due diversi tipi di proxy: quello trasparente (utile per fare
richieste direttamente al supporto .NET e generato automaticamente) e quello
reale (realizzato per facilitare la comunicazione C/S, spesso presente). Si ha
quindi che il secondo proxy ` anche modicabile, per poterlo adattare alle proe
prie esigenze. In particolare, con questo sistema, si riesce a registrare un oggetto remoto all'interno del proprio
application domain, per poterlo utilizzare in
maniera trasparente!
I proxy sono utilizzati per superare l'eterogeneit` fra i sistemi, e per generare
a
un canale come veicolo di trasporto dell'informazione. Questi canali possono essere di diverso tipo (binari, testuali,
http compatibili, . . . i 2 standard sfruttano
o TCP o HTTP), e si possono combinare per realizzare una catena di responsabilit` (formattazione del messaggio,
encoding, . . . )! Sono questi oggetti che
a
permettono la comunicazione fra application domain diversi. Ogni application
domain quindi registra i canali che si possono usare, permettendo alle volte anche una comunicazione bidirezionale.
Di default, le operazioni remote sono sempre sincrone, ma sfruttando opportunatamente i delegati si possono ottenere
anche interazioni sincrone non
bloccanti, sfruttando un meccanismo di call-back. I metodi possono fornire un
passaggio per valore (maggiormente disaccoppiato, ma in presenza di dati grandi, aumenta notevolmente l'overhead) o per
riferimento (mediante la creazione
di un proxy per memorizzare quindi un riferimento remoto), in maniera quindi
79
del tutto simile a CORBA!
L'attivazione a chi tocca? Non son presenti dei POA come in CORBA,
quindi si potrebbe prima di tutto pensare ad un'attivazione da parte del cliente
(esistono meccanismi per fare il lease, e quindi mantenere il collegamento con il
server oltre al tempo specicato38 ). In questa maniera si può anche mantenere
o
uno stato.
Gli oggetti remoti possono anche essere attivati dai server, in due diversi
modi:
$\bullet$ Come singleton (si attiva ora per sempre, ma non si può garantire uno
o
stato permanente: il controllo dell'oggetto resta in mano al supporto che
potrebbe deallocarlo).
$\bullet$ oppure come oggetti di tipo single call, ovvero con durata limitata al tempo
dell'invocazione, e quindi di costo limitato.
Si ha quindi una politica d'attivazione molto più semplice rispetto a quella di
u
CORBA!
\section{I Web Services}
L'idea alla base dei Web Services ` quella di fornire dei servizi B2B invece dei
e
classici servizi Web. La logica ` che il Web ` l'installato più diuso e facilmente
e
e
u
accedibile al mondo, perché non sfruttarlo?
e
Si ha infatti che molti mw richiedono congurazioni che vanno per esempio
contro certi principi delle aziende (aperture di ulteriori porte verso l'esterno),
aggiungendo dei vincoli organizzativi che possono renderne l'applicazione ancora
più complessa.
u
Con i Web Services si vuole sviluppare un sistema assolutamente standard
(basandosi su XML per descrivere i servizi, per fornire le risposte, . . . ), in grado quindi di superare in maniera
facile l'eterogeneit` (utilizzo di sistemi solo
a
standard). Gli obiettivi sono quindi quelli di realizzare delle Service Oriented
Application (mappando l'interfaccia di interazione ad alto livello) o delle Enterprise Application Integration,come SAP,
ovvero un sistema in grado di integrare
anche sistemi legacy.
Perch` allora non usare sempre il web, perché esistono anche altri mw ancoe
e
ra? Il problema ` che il Web ha un costo molto elevato, per cui potrebbe essere
e
utile per sistemi che richiedono una grana molto grossa.
\subsection{Struttura generale de WS}
Un WS funziona mediante l'emissione da parte di un client di una richiesta,
per cui si ricerca attravero un apposito broker (ma ` una struttura diversa
e
38 Server
può anche interrogare il client prima di deallocare la risorsa
o
80
dall'ORB di CORBA: funziona soprattutto come un directory per i servizi ) il
servizio adatto a soddisfare quella determinata richiesta.
L'idea ` che quindi vi siano diversi provider in grado di servire i servizi
e
richiesti. Per realizzare ci`, sono stati realizzati diversi protocolli standard :
o
$\bullet$ SOAP : Simple Object Access Protocol, consiste nel protocollo per poter
eseguire le richieste e ricevere le risposte, ed ` ovviamente XML compatie
bile.
$\bullet$ WSDL: Web Service Description Language ` il linguaggio basato su XML
e
per poter definire dei WS.
$\bullet$ UDDI : Universal Discovery Distribution Integration: questo invece ` il
e
protocollo che specica come i servizi si possano raccogliere in appositi
contenitori, realizzando un apposito sistema di nomi.
I servizi sono deniti one-shot, il che signica che sono eseguiti in maniera unica,
isolata! Per ogni richiesta, si attiva un solo servizio. Siamo quindi in presenza
di un mw senza stato. Questo ` sempre dovuto al fatto che si deve lavorare con
e
dati a grana molto grossa, che auto-contiene l'interazione: non si assume che il
provider abbia stato!
Nelle prime implementazioni dei WS non erano previsti meccanismi per la
sicurezza, il management e la QoS. Si aveva quindi, per esempio, solo crittograa
a livello applicativo, il che per` non era un sistema standard!
o
Perch` si ` deciso di utilizzare XML? Permette di specicare in una maniera
e e
fortemente strutturata (realizzando dati che si possono validare formalmente, e
utilizzando DTD/XSD si possono anche controllare dal punto di vista sintatticosemantico), potendo quindi esprimere le
preferenze in maniera dinamica!
\subsection{SOAP}
`
E il protocollo per la comunicazione, in grado quindi di strutturare l'interazione.
Denisce quindi come si può accedere agli oggetti. Presenta un alto overhead
o
perché si deve specicar tutto: siamo infatti in un'interazione senza stato, per
e
cui si deve specicare URI, . . . Non vi ` quindi nessun supporto semantico, e vi
e
possono essere più interazioni.
u
SOAP quindi permette di definire operazioni, dati e parametri. Sfrutta
HTTP come protocollo per la trasmissione, e XML per poter serializzare i dati.
In questo modo, si possono definire operazioni remote sfruttando l'XML: un
servitore riceve una richiesta standard, e la sua implementazione non interessa i
WS. Un provider dovr` soltanto rispondere rispettando la specica fornita con
a
SOAP!
SOAP quindi permette di descrivere l'interazione ma non solo: possiamo
avere operazioni senza risultati, o in grado emulare il comportamento C/S39 ,
39 Al posto delle RPC, si può definire che la comunicazione avviene con uno stile di tipo
o
documento, per cui non si ha mai risposta, sempre asincrona
81
`
ma possiamo anche quindi definire se si utilizza GET o POST per esempio. E
un protocollo state-less, che non fornisce quindi informazioni semantiche sulla
comunicazione. Non ` vero che si parla di operazioni leggere e essibili, ma
e
anche abbastanza pesanti alle volte.
SOAP si basa sull'idea di incapsulare mediante XML le informazioni necessarie alla comunicazione, come se fosse
un'envelope:
$\bullet$ Il body contiene le informazioni richieste per la comunicazione, cio` il
e
contenuto vero e proprio del messaggio, e le corrispondenti risposte.
$\bullet$ L'header specica altre informazioni utili per la comunicazione (es, per la
sicurezza)
$\bullet$ Si può anche definire una sezione di fault, nel caso che l'operazione non
o
avesse avuto successo.
La comunicazione non ` necessariamente P2P ma anche molti a molti. Il problee
ma di SOAP ` che ` altamente costoso (e poco eciente), perché siamo costretti
e
e
e
a lavorare a livello applicativo.
\subsection{WSDL}
`
E il linguaggio per descrivere sia in maniera astratta che in maniera concreta
quali servizi un provider può fornire. Descrive quindi l'interfaccia, indicando le
o
`
operazioni disponibili presso un certo provider. E una sorta di IDL. Quindi,
WSDL riesce a descrivere in maniera precisa come una richiesta debba essere
strutturata, e come una risposta sar` ritornata. Si può anche specicare dove il
a
o
servizio risieda, e come lo si può invocare.
o
Questo sistema, a dierenza di altri gi` visti, impone che il cliente debba
a
conoscere il servitore: viene a sapere in maniera concreta chi e come realizza
l'operazione desiderata. Si passano quindi i dati per copia con i WS. Si ha quindi che se non si conosce un servizio, si
può richiedere il WSDL corrispondente,
o
analizzarlo, e preparare cos` un'apposita richiesta SOAP! Il tutto nell'ottica di
\i{}
ottimizzare le operazioni eseguibili da un possibile mw.
WSDL ` in grado quindi di definire due parti, una più astratta (in grado
e
u
di definire i messaggi (insieme di elementi tipati), le operazioni (o collezione di
messaggi), e le interfacce del servizio (insieme di operazioni)) e una più concreu
ta, a basso livello (in grado di definire i tipi, come il servizio si lega realmente
ad un sistema, alle sue implementazioni concrete, detto binding (che protocollo
si usa? HTTP, TCP,. . . ), su quali nodi risiede e i service, ovvero le implementazioni delle interfacce disponbili. La
parte astratta ` essibile, generalizzabile
e
e facilmente estendibile.
WSDL prevede diversi modi di interazione! Non solo più modi sincroni (con
u
attesa di messaggio o sollecitazione da parte del client) ma anche asincroni (one-
82
way, o notication: cambia da chi esce il messaggio!).
WSDL ` un linguaggio molto pesante, ma che garantisce un'alta essibilit`
e
a
quindi: permette anche di invertire i ruoli fra C e S! Tuttavia, ` fondamentale
e
per poter generare in maniera automatica proxy e stub, oppure per realizzare
dei wrapper appositi per integrare facilmente sistemi legacy!
\subsection{UDDI e WSIL}
`
E il servizio di nomi presente nei WS. Si tratta di un ulteriore linguaggio con
cui poter descrivere dove risiedono i vari servizi, e come aggregare fra di loro
più servizi. La prima informazione che si necessita ` la possibilità di descrivere
u
e
a
le aziende che forniscono i servizi, per permettere quindi ad un generico utente
di poter navigare.
Con UDDI si può infatti realizzare facilmente un sistema di pagine bianche
o
(name server normale), pagine gialle (ovvero un sistema di trading, si memorizza per categorie) o inne per pagine verdi
(sono pagine tecniche aggiuntive
sui servizi oerti). Fondamentalmente, UDDI ` un {`}name server d'alto livello',
e
globale e condiviso ma non gerarchizzato. Questo aspetto presenta grossi problemi di coordinazione e di sicurezza fra i
diversi gestori dei servizi !
Gli attori possibili quindi per UDDI sono due: i publisher di un servizio e i
loro requester. Vista la struttura degli UDDI, un requester dovr` navigare sina
golarmente gli UDDI, perché appunto non vi ` ridirezione fra questi! In maniera
e
e
particolare, per aggiungere sicurezza si dovrebbe memorizzare e garantire il publisher!
A tale proposito ` stato pensato WSIL, dove si rovesciano le responsabilit`:
e
a
in questo modo ` il provider a dover garantire sicurezza, e non ` più compito di
e
e u
un eventuale server dei servizi vericare l'identit` dei provider. Si tratta quindi
a
di un protocollo alternativo, in grado di realizzare un sistema decentralizzato,
leggero e non focalizzato sul business. In maniera analoga ad UDDI, sfrutta
WSDL per descrivere i servizi!
\subsection{Considerazioni finali sui WS}
I protocolli realizzati dal W3C sono molto apprezzati da diverse organizzazioni,
come le banche in Italia. Tuttavia, i WS presentano un alto overhead rispetto ad
altre tecnologie (` possibile che non sia una comunicazione limitata a due attori,
e
e si lavora sempre a livello applicativo). Attualmente ` una tecnologia ancora
e
molto in fase di sviluppo e studio (nelle prime versione, i protocolli mancavano
molto d'espressivit`: la sicurezza per esempio era fornita solo a basso livello).
a
L'evoluzione che si immagina quindi per i WS ` quella di far evolvere il
e
sistema, come una composizione e coordinazione dei servizi, per poter aprire i
WS ad una categoria di utenti più ampia. L'idea sarebbe quindi quella che, per
u
ottenere un nuovo servizio, si compongano quelli precedenti. Per far ci` sono
o
83
stati introdotti nuovi linguaggi a usso (Business Process Execution Language
4WS: si possono mettere in sequenza, parallelo, in alternativa o in join) per
i WS, che lavorano sempre ad un livello molto alto. L'estensione dei WS in
`
questa direzione ` indicata come WS*. E una visione maggiormente orientata
e
ad perseguire logiche di business.
\section{Gestione delle risorse e sistemi mobili}
Le risorse in un sistema distribuito possono essere o concentrate o distribuite.
L'idea ` comunque quella di cercare di orire un servizio d trasparenza accedene
do alla risorsa.
Si deve quindi avere un sistema per descrivere le risorse, magari sfruttando
l'XML se si sta lavorando ad alto livello. Se inoltre si potesse definire la qualit`
a
sulla risorsa, si potrebbe dimostrare che si ` capito il costo fondamentale nello
e
sviluppo.
Si possono avere due diversi piani per il progetto delle risorse:
$\bullet$ Statico: si progettano le risorse no al deployment, realizzando anche delle
politiche complesse per poter descrivere dove inserirle, come replicarle,. . .
$\bullet$ Dinamico: si realizzano politiche per la gestione e il deployment durante
l'esecuzione dell'applicazione stessa.
Tipicamente, si ha gi` pensato a come realizzare il deployment delle risorse, alla
a
loro allocazione, essendo l'approccio più semplice da gestire: questo per` ` un
u
oe
approccio poco essibile e dinamico.
Un esempio di sistema distribuito coordinato per le risorse potrebbe essere
un File System distribuito: richiederebbe l'introduzione di agenti coordinati per
gestirle (questi dovrebbero introdurre delle fasi di negoziazione, prima di poter
fornire l'accesso alla risorsa). Garantisce trasparenza all'allocazione delle risorse,
mantenendo un comportamento uguale. Un altro modello potrebbe essere quello
basato su una service request, che rappresenta un sistema C/S.
\subsection{Mobilità delle risorse}
a
Nel progetto di un sistema, si deve considerare cosa e come si può muovere. Per
o
esempio, se si pensa allo stack di un programma Java, questo ` legato alla stack
e
della JVM: non si può spostare facilmente su un altro nodo! Altre caratteristiche
o
dicili da muovere sono i riferimenti a risorse strettamente locali (tipo i le40 ).
Se ` presente la possibilità di muovere le risorse, aggiungendo un servizio di
e
a
trasparenza si ha che si lavora senza fornire la possibilità di vedere le risorse
a
locali!
Questi concetti sono utili anche per decidere cosa posizionare su ogni nodo:
se per esempio le risorse dovessero essere allocate tutte sullo stesso nodo, si può
o
40 Si
potrebbero spostare, se si lavorasse su un le system distribuito
84
realizzare un sistema a memoria comune, con operazioni per` solo sequenziali.
o
Potendole distribuire su più nodi, si riescono a fornire operazioni anche in paru
allelo ma molto più costose. Se le risorse son semplici poi, basta semplicemente
u
copiarle, mentre certe risorse con vincoli che le rendono complesse, richiedono
un apposito sistema di trasparenza.
Esistono quindi diversi requisiti per fare un'esecuzione remota: si deve cercare di limitare l'overhead, e di
interferire il meno possibile con l'esecuzione
locale (gradita la non-interferenza), ed ` necessario fornire anche delle infore
mazioni di stato sui singoli processori. Questo ` particolarmente importante,
e
vista l'ampia eterogeneit` presente: non vi ` per esempio un sistema di nomi
a
e
comune, ed ` quindi necessario stipulare delle apposite convenzioni.
e
\subsection{Muovere i processi}
Esistono diversi S.O. che prevedono la possibilità di spostare i processi su altri
a
processori, per cercare di fornire un bilanciamento di carico migliore. Si realizza
cos` uno scheduling distribuito, in grado di fornire sia una politica locale che
\i{}
globale con cui trattare i processi. Un sistema di scheduling globale deve essere
in grado di fornire dei meccanismi con cui i processi possano comunicare in
remoto e quindi la possibilità di realizzare delle politiche per la gestione delle
a
risorse.
In particolare, si possono avere due diversi approcci:
$\bullet$ Load Sharing: si denisce la condivisione del carico come carico globale
del sistema, ovvero ` uno scheduling totale del sistema. L'idea ` quella di
e
e
evitare processi idle, mantenendoli sempre al massimo del lavoro possibile.
Si tratta di una valutazione statica, i processi non si possono muovere su
altri processori
`
$\bullet$ Load Balancing: E una valutazione dinamica, ovvero a tempo d'esecuzione
le risorse si possono muovere. Si vuole quindi mantenere un carico equilibrato su ogni processore, per ottenere
un'ecienza elevata.
Il problema del muovere un processo ` che ` un'operazione particolarmente cose
e
tosa. Utilizzando una politica di load balancing, conviene comunque fare delle
valutazioni dinamiche (quindi non di tutto l'insieme dei processori; spesso sono
valutazioni euristiche, per poter limitare il costo a volte inaccettabile) per approssimare il comportamento, per
limitare il costo. Una possibile strategia, per
esempio, ` quella di ridurre il numero dei processori su cui un processo può ese
o
sere trasferito. Il load balancing deve essere valutato attentamente, perché può
e o
divenire molto intrusivo. Le valutazioni dinamiche, che realizzano politiche di
minima intrusione locali e semplici son sempre da preferire.
Si sono visti diversi modelli per l'esecuzione di processi per ilload sharing:
$\bullet$ Modello a ring logico: un esempio ` V-kernel. Si denisce quindi una
e
struttura ssa, statica, che spiega come i processi possano muoversi. Vi
85
` un token che stabilisce quale processore ` il gestore in quel momento, il
e
e
quale richiede informazioni sul sistema mediante un broadcast. Ottenute
le risposte, si genera il bilanciamento distribuendo il carico (che non si
`
può quindi spostare). E una struttura statica e proattiva, per` semplice
o
o
da gestire anche a fronte di guasti.
$\bullet$ Modello a foresta: un esempio ` Micros. Vi ` una gerarchi di processori, in
e
e
genere rappresentata ad albero, quindi più dinamica. Possibilit` di rappreu
a
sentare anche foreste di processori. Al livello più basso vi sono i processori
u
che lavorano direttamente sulle risorse (worker), e i loro padri sono i manager: la profondit` dell'albero dipende
quindi dal numero delle risorse che
a
si vengono a definire (in generale si cerca di avere un albero binario). L'obiettivo di Micros ` quello di gestire un
elevato numero di risorse ed utenti,
e
non basandosi sulla topologia reale della rete. Il sistema ` dinamico proe
prio perché permette anche di fare un'allocazione dinamica delle risorse,
e
richiedendole al livello superiore. L'architettura ` fault-tolerant.
e
$\bullet$ Modello derivato dai worm d'Internet: si tratta di un buon livello per
la ridistribuzione del carico. Rappresenta un sistema molto dinamico che
richiede pochissime informazioni sull'architettura del sistema. L'idea `
e
quella di ricopiare l'applicazione che si ricerca, valutando i nodi vicini e
scegliendo quelli liberi.
Nel caso di load balancing si parla di migrazione: un processo viene trasferito su
`
un altro nodo. E un'operazione costosa, ma che presenta degli indubbi vantaggi,
perché permette di smistare il carico nel sistema. In questo modo si riescono a
e
far lavorare tutti i processori, aumentando l'ecienza.
`
E ovvio per` che per capire se le politiche addottate sono veramente un aiuo
to, serve un apposito sistema di monitoring: rappresentano dei costi aggiuntivi,
ma necessari per poter valutare istante per istante la situazione del sistema, e
quindi per poter bilanciarlo correttamente! Il monitoring deve tenr conto dei
processori, delle risorse e del tempo di comunicazione, e deve essere studiato per
realizzare una politica di minima intrusione, assumendo un principio di continuità dell'applicazione. Si introduce cos`
una logica di trasparenza, rendendo
a
\i{}
certi dati noti solo al supporto. Si punta quindi all'ecienza del sistema, alla
mobilità e alla realizzazione di un sistema fault-tolerant (crolla un processore,
a
ma il processo migra su un'altra macchina!).
La migrazione deve tener conto di diversi aspetti:
1. Si deve comunque lasciar la precedenza alle computazioni locali.
2. Si deve evitare il fenomeno del trashing, ovvero che un processo si muova
continuamente da un processore all'altro, senza mai essere eseguito.
3. Si deve evitare il fenomeno delle dipendenze residue: un nodo non dovrebbe
mai ridirezionare le richieste verso il nuovo nodo su cui gira il processo.
Vi ` infatti a possibilità di generare dei cicli assolutamente pericolosi.
e
a
86
4. Il sistema deve essere concorrente, in grado di realizzare migrazioni multiple.
Si deve quindi progettare il processo in maniera da poter trasportare quello che
serve: in generale lo stato corrente più eventuali modiche che sono state apporu
tate (magari si può trasportare anche solo un sottoinsieme delle informazioni).
o
Il grosso problema della migrazione ` quello del riuscire, nella maniera più
e
u
eciente e meno costosa, a fornire ai clienti un sistema per accedere al processo
anche se ` stato spostato.
e
Una prima possibilità ` quella di ridirigere i messaggi, sfruttando per esemae
pio un'apposita struttura detta forwarder, in grado di farlo in maniera traspar`
ente. E una strategia pessimistica/pro-attiva. In questo modo il cliente non
viene avvisato! Una prima modica consiste quindi nel riqualicare i messaggi,
avvisando anche il cliente oltre a ridirigerli per un certo tempo.
Tuttavia, la strategia più brusca (ottimista e reattiva) ` quella di far proprio
u
e
fallire il client: in questo modo il client si accorge che vi ` un qualche problema
e
(non ` trasparente!) e si deve preoccupare di ricercare dove ` adesso il processo
e
e
che desidera, per ottenerne un riferimento.
Demos/MP (anni 70) ` stato uno dei primi S.O. a pensare ad un sistema
e
`
di load balancing, in cui ` il supporto che fa migrare i processi. E un sistema
e
basato sullo scambio di messaggi, e i processi si conoscono in base ad appositi
link : queste strutture non sono come le porte, non son legati ai nodi su cui
girano, ed era un sistema univoco per puntare al processo. Si tratta quindi di
sistemi gestiti dall'infrastruttura.
In particolare, Demos/MP si preoccupa di spostare solo processi pesanti, cio`
e
che hanno un tempo d'esecuzione molto lungo (per esempio, processi ciclici).
Non si fanno quindi migrare i processi con un tempo di vita limitato.
Demos/MP ` stato anche il primo ideatore di un forwarder, che può lavorare
e
o
correttamente grazie al sistema a link! Il forwarder tuttavia ` una struttura
e
temporanea, nch` il link al processo non viene riqualicato, ovvero anche i
e
client riescono ad accederci direttamente senza dover passare dal nodo iniziale
(si può comunque anche fare un sistema a scarto di messaggi, per cui la reo
sponsabilit` del trovare il nuovo processore tocchi al cliente). Si deve quindi
a
fermare l'esecuzione del processo sul nodo originale, trasferire lo stato sul nuovo
processore, attivarlo e attivare il forwarder temporaneo. Si ha quindi alla ne
una trasparenza all'allocazione.
Un altro S.O. che prevede la migrazione dei processi ` il V-kernel (sempre
e
a scambio di messaggi), che punta all'ecienza e ad essere fault-tolerant, oltre
alla trasparenza all'allocazione. Questo S.O. lavora in maniera preventiva, per
cui copia le dierenze fra i processori su cui gira (in tempi diversi) per evitare
le dipendenze residue dovute al forwarder! Si ha quindi sempre una riqualicazione dei link.
87
La migrazione ` un modo molto buono per poter separare meccanismi e
e
politiche. Le politiche per la migrazione dipendono da diverse considerazioni:
1. Vale la pena migrare?
2. Chi e quando trasferisce il processo?
3. Su quale processore si allocher` il nuovo processo?
a
In generale possiamo osservare che vi sono dei meccanismi/caratteristiche comuni, per cui vi sono solo certe categorie
di processi che si possono spostare, ed
` necessario un gestore per la migrazione per ogni nodo. Si deve quindi essere in
e
grado di definire cosa trasferire, cosa si può migrare, ovvero la costituzione steso
sa della risorsa! Si ha che quindi si blocca il processo, se ne crea una copia sul
nuovo processore, e quindi si avvia un sistema per riqualicare i link, elimando
quelli obsoleti. Nel mentre, si riutano le comunicazioni con il processo.
Quanto costa? Un S.O., Charlotte, stimava il costo in base al numero dei
link presenti, della dimensione del processo da trasferire e da una parte costante
di comunicazione: al crescere delle dimensioni del processo, il tempo totale per
il trasferimento aumenta notevolmente.
Le politiche di migrazione sono quindi stabilite mediante un sistema di valutazione del carico, e la decisione di chi
trasferire e quando, spesso accomunata
a dove si deve trasferire, ovvero un concetto di locazione. In particolare, si deve
trovare un sistema per valutare qual è l'impatto sullo scheduling locale, potendo
e
integrare quindi politiche di più alta gestione. Le politiche si possono quindi
u
classicare come:
$\bullet$ Statiche: sono molto facili da valutare, e risulta facile definire come trasferire
(tipo, si decide che sono i processi nuovi a muoversi, fornendo per` un rio
schio di trashing). La locazione ` statica, e anche se non risulta essere
e
essibile, presenta un costo molto basso.
$\bullet$ Semi-dinamiche: sono politiche più costose, perché dipendono dalla situu
e
azione attuale. Si realizza una scelta ciclica dei processi e dei destinatari.
Il carico ` quindi dinamico.
e
$\bullet$ Dinamiche: Si intende di lavorare per un sistema di vicinato, ovvero si
cerca di spostare il carico su processi vicini. Si deve quindi valutare il
carico del vicinato, e trovare sistemi poco costosi per determinarlo.
Le politiche possono essere più o meno complesse, realizzando magari politiche
u
incondizionate (meccanismi random) o condizionate: queste ultime sonopiù cosu
tose, presentando un overhead dovuto ad una comuncaizione per fare delle negoziazioni ! Questo sistema ` detto probing,
perché ovviamente si cerca nel
e
e
vicinato, per limitare il costo (non ha senso cercare nella globalit` !). Si possono
a
anche realizzare politiche di bidding, per ricercare un processore disponibile ad
eseguire il processo, e scegliendo la migliore oerta proposta.
88
Non esiste una politica migliore in assoluto: in generale, conviene avere
un'inziativa da parte di un sender (da chi possiede il processo e che lo vorrebbe
spostare) se si ha un sistema con carichi bassi, altrimenti da parte del receiver
(un processore che potrebbe fornire risorse per un altro processo). Un approccio
misto risulta quindi essere il migliore.
La migrazione ` un sistema che deve essere studiato attentamente: può
e
o
infatti ridurre notevolmente i tempi dell'applicazione, sfruttando politiche semplici. Si ha quindi un'intrusione
limitata per ottenere i risultati desiderati. Si
deve quindi puntare all'ecienza, tendere all'ottimalit` e realizzare un sistema
a
stabile.
\subsection{Sistemi ad agenti mobili}
I sistemi ad agenti mobili si mappa molto bene con il problema della migrazione.
Tuttavia, l'approccio ` diverso: non si navigano i nodi per ottimizzare il bilane
ciamento del carico, ma per ottenere informazioni dai diversi nodi. Si ha quindi
un movimento dovuto all'applicazione, e non da esigenze di ecienze per la
computazione e diretto dal supporto!
Il movimento ` quindi una caratteristica base degli agenti mobili, per cui si
e
deve cercare di determinare dei sistemi ecienti. Nulla per esempio impedisce
ad un agente di ritornare su nodi gi` visitati.
a
Per gli agenti si parla quindi di mobilità del codice (modello che va oltre
a
al normale approccio C/S, per cui si passano solo dati. Sono sistemi utili per
esempio per aggiornare i diversi router). Prima degli agenti mobili, per mobilità
a
del codice si parla di:
$\bullet$ Remote EValuation: ` un'operazione singola, one-hop, per cui si invia il
e
codice al server, che ne diventa parte integrante!
$\bullet$ Code On Demand : processo inverso, ovvero il client scarica codice proveniente dal server (un esempio classico
sono le applet Java!)
Questi sistemi per` non prevedono ancora la possibilità che il codice, mentre si
o
a
muove, esegua! Questo si ha solo con l'introduzione degli agenti mobili. Sono infatti sistemi a multi-hop, in grado di
cambiare l'allocazione durante l'esecuzione
e mantenere comunque uno stato coeso. Si può pensare a varie ottimizzazioni,
o
magari trasportando solo le dierenze rispetto ad uno stato iniziale o una sintesi
dei risultati ottenuti.
\subsection{Classicazione della mobilità}
a
Per gli agenti mobili, si può classicare in diversi gradi la mobilità:
o
a
$\bullet$ Forte: In ogni punto del codice ` possibile specicare la mobilità. Tali
e
a
sistemi sono in realt` dicilmente realizzabili, perché presentano grossi
a
e
problemi di supporto.
89
$\bullet$ Debole: Si vincola invece la posizione in cui si può mettere la {`}move': tale
o
sistema ` meno essibile, ma maggiormente e facilmente gestibile.
e
La dierenza quindi ` nella continuità della mobilità (o avviene sempre, oppure
e
a
a
solo in certi momenti prestabiliti). Come risolvere la mobilità forte? L'idea `
a
e
quella di realizzare un sistema a codice intermedio, potendo cos` fornire su ogni
\i{}
nodo degli interpreti del codice intermedio (per poter superare cos` i diversi
\i{}
problemi dovuti all'eterogeneità).
\subsection{Servono gli agenti mobili?}
In generale, un progetto giustica la scelta della tecnologia. Tuttavia, se i vincoli
risultano essere sbagliati, si usa a sproposito la tecnologia.
Attualmente, per gli agenti mobili si ` ancora alla ricerca di una killer applie
cation; in certi casi conviene ancora usare sistemi come REV o COD. La mobilità
a
attualmente ` vista come il sistema migliore per poter accedere a risorse vine
colate, cercando di ottimizzare il sistema utilizzando delle operazioni locali. Vi
sono diversi tipi di mobilità:
a
$\bullet$ Utente nomade: non ha senso utilizzare gli agenti, ma conviene invece
gestire un sistema a repository centrale. L'utente vuole eseguire le proprie
applicazioni indipendentemente da quale macchina stia utilizzando.
$\bullet$ Terminali mobili : potrebbe aver senso utilizzare gli agenti. Si tratta infatti
dell'idea di realizzare terminali in grado di lavorare comunque ed ovunque
si trovino.
$\bullet$ Codice mobile: denitivamente utile utilizzare gli agenti.
\subsection{Gli agenti mobili}
Sono delle entit` che si devono muovere per eseguire i propri compiti, operando
a
per conto di un principal. Si tratta quindi di sistemi in cui il programmatore stabilisce la mobilità, e in cui si
realizza una programmazione location-awareness,
a
cio` dipendente dal posto in cui si esegue. Possono essere utili quindi per poter
e
fornire un controllo locale alle risorse, ltrando quindi le richieste da parte di un
gestore centrale! Gli agenti mobili devono essere progettati secondo un'ottica di
leggerezza: essere semplici, single-threaded (Java sembra un'ottima tecnologia
per realizzarli). Sono in corso di sviluppo mw, orientati alla weak mobility:
studio quindi di strutture dati apposite per la mobilità, permettendo soltanto
a
delle richieste esplicite alla migrazione.
Vi possono essere diverse implementazioni: con connessione o connectionless,
comunicazioni sincrone o meno, possibilità di realizzare un sistema sincronizzato
a
di agenti o meno, e cos` via. Tuttavia, tutti i sistemi ad agenti introducono un
\i{}
enorme problema per la sicurezza (codice che naviga ed agisce in una rete. . . ). Si
potrebbe infatti avere del codice maligno che gira. Tuttavia, i controlli potrebbero anche impedire ad un nodo di
eseguire codice non maligno, scartando
90
via l'agente! Si deve quindi vericare mediante l'uso di diversi agenti se per
vericare il comportamento del nodo.
Un altro problema ` sul fatto che il codice può essere letto senza problemi
e
o
dal nodo su cui esegue: si devono quindi anche garantire certe propriet` di
a
incapsulamento, perché non sia un nodo a modicare il codice contenuto da un
e
agente!
A cosa può essere utile tutto ci`? A realizzare mobile computing (utenti in
o
o
grado di muoversi e di mantenere uno stato/sessione costante, anche cambiando
terminale, ottenendo cos` la massima accessibilit`) ottenendo per esempio la
\i{}
a
generazione di reti spontanee (utili per esempio per creare reti per giochi, solo su
disponibilit`), possibilità di coordinare utenti mobili in ambienti civili e militari,
a
a
sistemi location awareness. . .
91
\end{document}
